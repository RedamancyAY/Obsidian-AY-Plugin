{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4af0257f-bd72-4fd2-b2a4-5c58b2c05a0f",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-07-19T12:58:33.181940Z",
     "iopub.status.busy": "2023-07-19T12:58:33.180699Z",
     "iopub.status.idle": "2023-07-19T12:58:33.211978Z",
     "shell.execute_reply": "2023-07-19T12:58:33.210772Z",
     "shell.execute_reply.started": "2023-07-19T12:58:33.181888Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d60531e2-eae4-4b27-a340-6901b7765234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T12:58:34.684334Z",
     "iopub.status.busy": "2023-07-19T12:58:34.683305Z",
     "iopub.status.idle": "2023-07-19T12:58:35.905681Z",
     "shell.execute_reply": "2023-07-19T12:58:35.904781Z",
     "shell.execute_reply.started": "2023-07-19T12:58:34.684285Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ay.torch.nn import Conv2p1D, LayerNorm, PositionEmbedding\n",
    "from einops import rearrange\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "from torch import einsum, nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fda5223-e06d-42b3-979c-b4b383a904e0",
   "metadata": {},
   "source": [
    "## AdaptiveConv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dd8a918-bf8b-4325-9c79-43c69f8afe9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T13:09:40.300239Z",
     "iopub.status.busy": "2023-07-19T13:09:40.299770Z",
     "iopub.status.idle": "2023-07-19T13:09:40.340097Z",
     "shell.execute_reply": "2023-07-19T13:09:40.339479Z",
     "shell.execute_reply.started": "2023-07-19T13:09:40.300191Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdaptiveConv1d(nn.Module):\n",
    "    \"\"\"\n",
    "        Given the channel numbers, kernel size, stride, the reduction percentage of the feature length,\n",
    "        this module can adaptively calcuate the padding size,\n",
    "            and in the transpose conv, calcuate the output_padding size,\n",
    "\n",
    "    Args:\n",
    "        n_dim: channel number\n",
    "        kernel_size: kernel size for conv\n",
    "        stride: stride for conv\n",
    "        reduction: the reduction percentage (>1) of the feature length, `1` denotes not change.\n",
    "        conv_transpose: whether add the weights and bias for transpose conv\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_dim,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        reduction,\n",
    "        reverse_conv='upsample',\n",
    "        groups=1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.register_parameter(\n",
    "            param=nn.Parameter(torch.randn(n_dim, n_dim // groups, kernel_size)),\n",
    "            name=\"weights1\",\n",
    "        )\n",
    "        self.register_parameter(param=nn.Parameter(torch.randn(n_dim)), name=\"bias1\")\n",
    "\n",
    "        self.post_conv = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n_dim, n_dim, 3, stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.reverse_type = reverse_conv\n",
    "        if reverse_conv is not None:\n",
    "            if reverse_conv == 'convT':\n",
    "                self.register_parameter(\n",
    "                    param=nn.Parameter(torch.randn(n_dim, n_dim // groups, kernel_size)),\n",
    "                    name=\"weights2\",\n",
    "                )\n",
    "                self.register_parameter(\n",
    "                    param=nn.Parameter(torch.randn(n_dim)), name=\"bias2\"\n",
    "                )\n",
    "            else:\n",
    "                self.upsample = nn.Sequential(\n",
    "                    nn.Upsample(scale_factor=reduction),\n",
    "                    nn.Conv1d(n_dim, n_dim, kernel_size=5, stride=1, padding=2)\n",
    "                )\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.reduction = reduction\n",
    "        self.groups = groups\n",
    "\n",
    "    def conv(self, x, reduction=None, **kwargs):\n",
    "        length = x.shape[-1]\n",
    "        out_length = length // self.reduction\n",
    "\n",
    "        p = 0\n",
    "        _out_length = math.floor((length - self.kernel_size + 2 * p) / self.stride + 1)\n",
    "        while _out_length != out_length:\n",
    "            p += 1\n",
    "            _out_length = math.floor(\n",
    "                (length - self.kernel_size + 2 * p) / self.stride + 1\n",
    "            )\n",
    "            # print(_out_length, out_length, p)\n",
    "        self.p = p\n",
    "        y = F.conv1d(\n",
    "            x,\n",
    "            self.weights1,\n",
    "            bias=self.bias1,\n",
    "            stride=self.stride,\n",
    "            padding=p,\n",
    "            groups=self.groups,\n",
    "        )\n",
    "        y = self.post_conv(y)\n",
    "        return y\n",
    "\n",
    "    def conv_transpose(self, y):\n",
    "        length = y.shape[-1]\n",
    "        out_length = length * self.reduction\n",
    "\n",
    "        out_padding = 0\n",
    "        _out_length = (\n",
    "            (length - 1) * self.stride - 2 * self.p + self.kernel_size + out_padding\n",
    "        )\n",
    "        while _out_length != out_length:\n",
    "            out_padding += 1\n",
    "            _out_length = (\n",
    "                (length - 1) * self.stride - 2 * self.p + self.kernel_size + out_padding\n",
    "            )\n",
    "        x = F.conv_transpose1d(\n",
    "            y,\n",
    "            self.weights2,\n",
    "            bias=self.bias2,\n",
    "            stride=self.stride,\n",
    "            padding=self.p,\n",
    "            output_padding=out_padding,\n",
    "            groups=self.groups,\n",
    "        )\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "    def reverse(self, x):\n",
    "        if self.reverse_type == 'convT':\n",
    "            return self.conv_transpose(x)\n",
    "        else:\n",
    "            return self.upsample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b89b026f-0a3d-4c6d-8f42-9b6ba60b4e32",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-07-19T13:09:52.865747Z",
     "iopub.status.busy": "2023-07-19T13:09:52.865272Z",
     "iopub.status.idle": "2023-07-19T13:09:53.065183Z",
     "shell.execute_reply": "2023-07-19T13:09:53.064759Z",
     "shell.execute_reply.started": "2023-07-19T13:09:52.865699Z"
    },
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "active-ipynb",
     "style-activity"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128, 2560])\n",
      "torch.Size([2, 128, 64000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 128, 64000)\n",
    "\n",
    "model = AdaptiveConv1d(n_dim=128, kernel_size=25, stride=25, reduction=25, groups=1, conv_transpose='convT')\n",
    "y = model(x)\n",
    "print(y.shape)\n",
    "\n",
    "z = model.reverse(y)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbf047fc-0b2b-4905-8147-3474c8b7269e",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-07-19T13:10:11.653328Z",
     "iopub.status.busy": "2023-07-19T13:10:11.652832Z",
     "iopub.status.idle": "2023-07-19T13:10:11.774982Z",
     "shell.execute_reply": "2023-07-19T13:10:11.774479Z",
     "shell.execute_reply.started": "2023-07-19T13:10:11.653280Z"
    },
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "active-ipynb",
     "style-activity"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128, 2560])\n",
      "torch.Size([2, 128, 64000])\n"
     ]
    }
   ],
   "source": [
    "model = AdaptiveConv1d(n_dim=128, kernel_size=25, stride=25, reduction=25, groups=1, conv_transpose='upsample')\n",
    "y = model(x)\n",
    "print(y.shape)\n",
    "z = model.upsample(y)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80215cc1-d909-4559-b5e6-bd9d8abc74c1",
   "metadata": {},
   "source": [
    "## Self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e82bd70e-ddb4-4f85-b01e-d6ad9697a6a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T08:23:56.544103Z",
     "iopub.status.busy": "2023-07-19T08:23:56.543326Z",
     "iopub.status.idle": "2023-07-19T08:23:56.558324Z",
     "shell.execute_reply": "2023-07-19T08:23:56.557146Z",
     "shell.execute_reply.started": "2023-07-19T08:23:56.544051Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_relative_position(q_seq_len, seq_len, k):\n",
    "    Q = torch.arange(q_seq_len)[:, None]  # q_seq_len, 1\n",
    "    # it might be key or value\n",
    "    S = torch.arange(seq_len)[None, :]  # 1, seq_len\n",
    "    # max(-k,min(j-i,k)) - j is seq_len of key/value and i is seq_len of query\n",
    "    rp = torch.clip(S - Q, -k, k)  # q_seq_len, seq_len\n",
    "    # + k\n",
    "    out = rp + k\n",
    "    return out\n",
    "\n",
    "\n",
    "# batch, h와는 무관\n",
    "class RelativePositionEmbedding(nn.Module):\n",
    "    def __init__(self, max_k, embed_dim, n_head):\n",
    "        super().__init__()\n",
    "        self.max_k = max_k\n",
    "        self.d_k = embed_dim // n_head\n",
    "        self.emb = nn.Embedding(2 * max_k + 1, self.d_k)\n",
    "\n",
    "        self.cache_pos = {}\n",
    "    \n",
    "    def _make_relative_postion(self, seq_len):\n",
    "        if not seq_len in self.cache_pos:\n",
    "            self.cache_pos[seq_len] = make_relative_position(seq_len, seq_len, self.max_k)\n",
    "        return self.cache_pos[seq_len].to(self.emb.weight.device)\n",
    "    \n",
    "    def forward(self, seq_len):\n",
    "        # relative_position\n",
    "        \"\"\"\n",
    "        relative position\n",
    "        shape : seq_len(query), seq_len(key or value)\n",
    "        \"\"\"\n",
    "        out = self._make_relative_postion(seq_len)\n",
    "        out = self.emb.forward(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbef4449-4c95-49e4-aac5-8e8a3e713dfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T08:22:35.414483Z",
     "iopub.status.busy": "2023-07-19T08:22:35.413445Z",
     "iopub.status.idle": "2023-07-19T08:22:35.425418Z",
     "shell.execute_reply": "2023-07-19T08:22:35.424723Z",
     "shell.execute_reply.started": "2023-07-19T08:22:35.414437Z"
    }
   },
   "outputs": [],
   "source": [
    "class Multi_Head_Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_k,\n",
    "        embed_dim,\n",
    "        num_heads=1,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.PE = RelativePositionEmbedding(max_k, embed_dim, num_heads)\n",
    "        self.num_heads = num_heads\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim, bias=False), nn.Dropout(dropout)\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _multi_head_attention(self, q, k, v):\n",
    "        q, k, v = map(\n",
    "            lambda mat: rearrange(mat, \"b n (h d) -> (b h) n d\", h=self.num_heads),\n",
    "            (q, k, v),\n",
    "        )\n",
    "        scale = q.shape[-1] ** -0.5\n",
    "        qkT = einsum(\"b n d, b m d->b n m\", q, k) * scale\n",
    "\n",
    "        # relative positive embedding\n",
    "        rpe = self.PE(q.shape[1])\n",
    "        qkT2 = torch.matmul(q.transpose(0, 1), rpe.transpose(1, 2)).transpose(0, 1)\n",
    "        qkT += qkT2 * scale\n",
    "\n",
    "        attention = self.dropout(qkT.softmax(dim=-1))\n",
    "        attention = einsum(\"b n m, b m d->b n d\", attention, v)\n",
    "        attention = rearrange(attention, \"(b h) n d -> b n (h d)\", h=self.num_heads)\n",
    "        return attention\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        # (q, k, v) = map(lambda x: self.PE(x), (q, k, v))\n",
    "        v = self.norm(v)\n",
    "        x = self._multi_head_attention(q, k, v)\n",
    "        x = self.proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84922510-2c3b-4a2e-8364-dff6da11c59f",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-07-19T08:23:58.050768Z",
     "iopub.status.busy": "2023-07-19T08:23:58.049656Z",
     "iopub.status.idle": "2023-07-19T08:23:58.069786Z",
     "shell.execute_reply": "2023-07-19T08:23:58.068751Z",
     "shell.execute_reply.started": "2023-07-19T08:23:58.050721Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "style-activity",
     "active-ipynb"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 128])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 64, 128)\n",
    "model = Multi_Head_Attention(max_k=5, embed_dim=128)\n",
    "model(x, x, x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fb23aa3-c558-460b-8351-dfcecb93472c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T07:08:58.617699Z",
     "iopub.status.busy": "2023-07-19T07:08:58.616992Z",
     "iopub.status.idle": "2023-07-19T07:08:58.627630Z",
     "shell.execute_reply": "2023-07-19T07:08:58.626531Z",
     "shell.execute_reply.started": "2023-07-19T07:08:58.617651Z"
    }
   },
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv1d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_dim_in,\n",
    "        n_dim_out,\n",
    "        kernel_size=5,\n",
    "        stride=1,\n",
    "        padding=\"same\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depthwise_conv = nn.Conv1d(\n",
    "            n_dim_in,\n",
    "            n_dim_out,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            groups=n_dim_in,\n",
    "        )\n",
    "        self.pointwise_conv = nn.Conv1d(\n",
    "            n_dim_out,\n",
    "            n_dim_out,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=padding,\n",
    "            groups=1,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise_conv(self.depthwise_conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da6d7d8d-7edf-4c78-b623-dc3cb71ed5d3",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-07-19T07:17:04.653982Z",
     "iopub.status.busy": "2023-07-19T07:17:04.653123Z",
     "iopub.status.idle": "2023-07-19T07:17:05.448785Z",
     "shell.execute_reply": "2023-07-19T07:17:05.448011Z",
     "shell.execute_reply.started": "2023-07-19T07:17:04.653935Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "active-ipynb",
     "style-activity"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 48000])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DepthwiseSeparableConv1d(32, 128)\n",
    "x = torch.randn(32, 32, 48000)\n",
    "model(x).shape"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
