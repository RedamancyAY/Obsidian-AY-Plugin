{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65fba2f3-cb3d-455d-bf82-4a9b856f8452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T06:16:58.112466Z",
     "iopub.status.busy": "2023-08-06T06:16:58.111878Z",
     "iopub.status.idle": "2023-08-06T06:16:58.140014Z",
     "shell.execute_reply": "2023-08-06T06:16:58.138850Z",
     "shell.execute_reply.started": "2023-08-06T06:16:58.112410Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd394889-8930-4d9b-936b-da2f90ae2b29",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7525fb3-889a-4da1-9790-8a5077a24d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T06:16:59.464396Z",
     "iopub.status.busy": "2023-08-06T06:16:59.463910Z",
     "iopub.status.idle": "2023-08-06T06:17:00.439397Z",
     "shell.execute_reply": "2023-08-06T06:17:00.438156Z",
     "shell.execute_reply.started": "2023-08-06T06:16:59.464351Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ay2.torch.nn import LambdaFunctionModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626a826f-0ac5-447b-b51c-0966b5159c7f",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-08-08T08:20:08.368816Z",
     "iopub.status.busy": "2023-08-08T08:20:08.368280Z",
     "iopub.status.idle": "2023-08-08T08:20:08.705111Z",
     "shell.execute_reply": "2023-08-08T08:20:08.704238Z",
     "shell.execute_reply.started": "2023-08-08T08:20:08.368789Z"
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdaptiveConv1d, DepthwiseSeparableConv1d, Multi_Head_Attention\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Attention, MLP\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from .conv_attention import MLP, Attention\n",
    "    from .utils import AdaptiveConv1d, DepthwiseSeparableConv1d, Multi_Head_Attention\n",
    "except ImportError:\n",
    "    from conv_attention import MLP, Attention\n",
    "    from utils import AdaptiveConv1d, DepthwiseSeparableConv1d, Multi_Head_Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff2b0b2-a2d9-48d6-a703-2a3540209933",
   "metadata": {},
   "source": [
    "\n",
    "## Multi-Scale Fusion Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d829f78e-017f-44d3-abed-ac14cf145d98",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-08-02T06:13:41.122043Z",
     "iopub.status.busy": "2023-08-02T06:13:41.121589Z",
     "iopub.status.idle": "2023-08-02T06:13:41.146206Z",
     "shell.execute_reply": "2023-08-02T06:13:41.145483Z",
     "shell.execute_reply.started": "2023-08-02T06:13:41.122024Z"
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "class MultiScaleFusion(nn.Module):\n",
    "    def __init__(self, n_dim, n_head=1, scales=[1, 5, 10], samples_per_frame=400):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_dim = n_dim\n",
    "        self.samples_per_frame = samples_per_frame\n",
    "        self.norm = nn.BatchNorm1d(n_dim)\n",
    "\n",
    "        scales = [1, 5, 10]\n",
    "        assert samples_per_frame % scales[-1] == 0, samples_per_frame\n",
    "\n",
    "        self.down_samples = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    nn.AvgPool1d(scales[i] * 3, stride=scales[i], padding=scales[i])\n",
    "                    if i > 0\n",
    "                    else nn.Identity(),\n",
    "                    nn.Conv1d(n_dim, n_dim, 3, stride=1, padding=1),\n",
    "                    # nn.LeakyReLU(negative_slope=0.3),\n",
    "                    # nn.Conv1d(n_dim, n_dim, 3, stride=1, padding=1),\n",
    "                )\n",
    "                for i in range(3)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.up_samples = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    nn.Upsample(scale_factor=scales[i]) if i > 0 else nn.Identity(),\n",
    "                    nn.Conv1d(n_dim, n_dim, 3, stride=1, padding=1),\n",
    "                    # nn.LeakyReLU(negative_slope=0.3),\n",
    "                    # nn.Conv1d(n_dim, n_dim, 3, stride=1, padding=1),\n",
    "                )\n",
    "                for i in range(3)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.conv_fusion = nn.Sequential(\n",
    "            nn.Conv1d(n_dim * 3, n_dim, 3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Conv1d(n_dim, n_dim * 3, 3, stride=1, padding=1),\n",
    "        )\n",
    "        self.mha = Multi_Head_Attention(\n",
    "            max_k=80, embed_dim=n_dim, num_heads=n_head, dropout=0.1\n",
    "        )\n",
    "        self.attn_upsamples = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    nn.Upsample(scale_factor=samples_per_frame // scales[i]),\n",
    "                    nn.Conv1d(n_dim, n_dim, 3, stride=1, padding=1),\n",
    "                    # nn.LeakyReLU(negative_slope=0.3),\n",
    "                    # nn.Conv1d(n_dim, n_dim, 3, stride=1, padding=1),\n",
    "                )\n",
    "                for i in range(3)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.register_parameter(\"alpha\", nn.Parameter(torch.ones(1, n_dim, 1)))\n",
    "        self.register_parameter(\"beta\", nn.Parameter(torch.ones(1, n_dim * 3, 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        short_cut = x\n",
    "        x = self.norm(x)\n",
    "        n_frames = x.shape[-1] // self.samples_per_frame\n",
    "        avg_pool = partial(F.adaptive_avg_pool1d, output_size=n_frames)\n",
    "        max_pool = partial(F.adaptive_max_pool1d, output_size=n_frames)\n",
    "\n",
    "        frame_feat = []\n",
    "        ms_feat = []\n",
    "        for i in range(3):\n",
    "            y = self.down_samples[i](x)\n",
    "            print(\"scale %d : \" % i, y.shape)\n",
    "            ms_feat.append(y)\n",
    "            attn = avg_pool(y) + max_pool(y)  # (B, n_dim, n_frames)\n",
    "            frame_feat.append(attn)\n",
    "            # frame_feat.append(attn.transpose(1, 2))  # (B, n_frames, n_dim)\n",
    "\n",
    "        frame_feat = torch.concat(frame_feat, dim=1)  # (B, 3*n_dim, n_frames)\n",
    "        frame_feat = self.conv_fusion(frame_feat)\n",
    "        frame_feat = torch.split(frame_feat, self.n_dim, dim=1)\n",
    "        frame_feat = [x.transpose(1, 2) for x in frame_feat]\n",
    "\n",
    "        v, k, q = frame_feat\n",
    "        attn = self.mha(q, k, v)\n",
    "        attn = attn.transpose(1, 2)  # (B, n_dim, n_frames)\n",
    "        # print(\"attn shape: \", attn.shape)\n",
    "\n",
    "        for i in range(3):\n",
    "            _attn = self.attn_upsamples[i](attn)\n",
    "            ms_feat[i] = ms_feat[i] * _attn\n",
    "            # ms_feat[i] = (\n",
    "            #     ms_feat[i]\n",
    "            #     + self.beta[:, i * self.n_dim : (i + 1) * self.n_dim, :] * _attn\n",
    "            # )\n",
    "\n",
    "        rec_feat = []\n",
    "        for i in range(3):\n",
    "            y = self.up_samples[i](ms_feat[i])\n",
    "            rec_feat.append(y)\n",
    "\n",
    "        rec_feat = rec_feat[0] + rec_feat[1] + rec_feat[2]\n",
    "        x = x + self.alpha * rec_feat\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90bd0d5b-5555-4b55-ae34-ad6605d23407",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-08-02T06:13:42.140642Z",
     "iopub.status.busy": "2023-08-02T06:13:42.140122Z",
     "iopub.status.idle": "2023-08-02T06:13:42.199688Z",
     "shell.execute_reply": "2023-08-02T06:13:42.199107Z",
     "shell.execute_reply.started": "2023-08-02T06:13:42.140598Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "style-activity",
     "active-ipynb"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7555, -0.6272,  0.9750,  ..., -0.2995,  0.8353,  0.4291],\n",
       "         [-0.1354, -0.7936,  0.2231,  ..., -0.7562, -0.5525,  1.4898],\n",
       "         [ 0.1626,  0.1518,  1.1208,  ...,  0.2509, -0.5045,  0.3458],\n",
       "         ...,\n",
       "         [-2.5315, -0.2392, -0.4742,  ...,  1.4658, -0.5670,  0.5073],\n",
       "         [-1.9215,  0.7726,  0.0569,  ...,  0.5763,  0.0100,  2.2050],\n",
       "         [-0.5215,  0.5268, -2.8960,  ...,  0.3329,  2.2136, -1.2991]],\n",
       "\n",
       "        [[ 1.0391, -1.4285,  0.1913,  ..., -0.1417, -0.7822,  1.2220],\n",
       "         [-1.4263, -0.1288,  0.5291,  ..., -0.2794, -2.0096, -2.5121],\n",
       "         [-1.0814, -1.7781, -2.0418,  ...,  0.3363, -1.7723, -0.2150],\n",
       "         ...,\n",
       "         [ 0.5747, -0.1943,  0.6696,  ..., -1.1426,  0.3285, -0.1630],\n",
       "         [ 0.7465, -0.6417,  1.3040,  ...,  0.2831,  1.9883,  1.6042],\n",
       "         [-0.8657, -0.9114,  1.8017,  ..., -0.7329, -0.5312, -1.6505]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiScaleFusion(n_dim=32)\n",
    "x = torch.randn(2, 32, 4000)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6e4b2e-8a13-45e7-85ba-2f8f26bd7b2e",
   "metadata": {},
   "source": [
    "## 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07698912-8d04-49b8-9bcf-a7837497742c",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-08-06T06:44:43.252277Z",
     "iopub.status.busy": "2023-08-06T06:44:43.251201Z",
     "iopub.status.idle": "2023-08-06T06:44:43.305728Z",
     "shell.execute_reply": "2023-08-06T06:44:43.304455Z",
     "shell.execute_reply.started": "2023-08-06T06:44:43.252226Z"
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "class MultiScaleFusion2D(nn.Module):\n",
    "    def __init__(self, n_dim, n_head=1, scales=[1, 5, 10], samples_per_frame=400):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_dim = n_dim\n",
    "        self.norm = nn.BatchNorm2d(n_dim)\n",
    "\n",
    "        scales = [1, 2, 3]\n",
    "\n",
    "        self.down_samples = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    nn.AvgPool2d(scales[i] * 3, stride=scales[i], padding=scales[i])\n",
    "                    if i > 0\n",
    "                    else nn.Identity(),\n",
    "                    nn.Conv2d(\n",
    "                        n_dim, n_dim, 3, stride=1, padding=1, groups=1, bias=False\n",
    "                    ),\n",
    "                )\n",
    "                for i in range(3)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # self.conv_attention = Attention(dim=n_dim)\n",
    "        self.conv_attention = nn.Sequential(\n",
    "            Attention(dim=n_dim), MLP(dim=n_dim, mlp_ratio=2.0)\n",
    "        )\n",
    "\n",
    "        self.up_samples = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    nn.Upsample(\n",
    "                        scale_factor=scales[i], mode=\"bilinear\", align_corners=True\n",
    "                    )\n",
    "                    if i > 0\n",
    "                    else nn.Identity(),\n",
    "                    nn.Conv2d(\n",
    "                        n_dim, n_dim, 3, stride=1, padding=1, groups=1, bias=False\n",
    "                    ),\n",
    "                )\n",
    "                for i in range(3)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # self.final_proj = nn.Sequential(\n",
    "        #     nn.Conv2d(n_dim*3, n_dim, 1, bias=False),\n",
    "        #     nn.BatchNorm2d(n_dim),\n",
    "        #     nn.Dropout(0.1),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Conv2d(n_dim, n_dim, 1, bias=False)\n",
    "        # )\n",
    "        # self.final_proj = nn.Conv2d(n_dim*3, n_dim, 1, bias=False)\n",
    "\n",
    "        self.register_parameter(\"alpha1\", nn.Parameter(torch.ones(1, n_dim, 1, 1)))\n",
    "        self.register_parameter(\"alpha2\", nn.Parameter(torch.ones(1, n_dim, 1, 1)))\n",
    "        self.register_parameter(\"alpha3\", nn.Parameter(torch.ones(1, n_dim, 1, 1)))\n",
    "        self.register_parameter(\"alpha\", nn.Parameter(torch.ones(1, n_dim, 1, 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        short_cut = x\n",
    "        x = self.norm(x)\n",
    "\n",
    "        frame_feat = []\n",
    "        ms_feat = []\n",
    "        for i in range(3):\n",
    "            y = self.down_samples[i](x)\n",
    "            y = self.conv_attention(y)\n",
    "            # print(\"scale %d : \" % i, y.shape)\n",
    "            ms_feat.append(y)\n",
    "\n",
    "        rec_feat = []\n",
    "        for i in range(3):\n",
    "            y = self.up_samples[i](ms_feat[i])\n",
    "            _H, _W = y.shape[-2], y.shape[-1]\n",
    "            y = F.pad(y, (0, W - _W, 0, H - _H))\n",
    "            # print(y.shape)\n",
    "            rec_feat.append(y)\n",
    "\n",
    "        # rec_feat = (rec_feat[0] + rec_feat[1] + rec_feat[2]) / 3\n",
    "        rec_feat = (\n",
    "            self.alpha1 * rec_feat[0]\n",
    "            + self.alpha2 * rec_feat[1]\n",
    "            + self.alpha3 * rec_feat[2]\n",
    "        ) / 3\n",
    "        # rec_feat = self.final_proj(torch.concat(rec_feat, dim=1))\n",
    "        x = x + self.alpha * rec_feat\n",
    "        # x = x + rec_feat\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1086f1-b658-4794-9af3-d4c660b1c7ac",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-08-06T06:44:59.101779Z",
     "iopub.status.busy": "2023-08-06T06:44:59.101298Z",
     "iopub.status.idle": "2023-08-06T06:44:59.279399Z",
     "shell.execute_reply": "2023-08-06T06:44:59.278895Z",
     "shell.execute_reply.started": "2023-08-06T06:44:59.101734Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "module = MultiScaleFusion2D(n_dim=64)\n",
    "x = torch.randn(2, 64, 224, 252)\n",
    "module(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb6fabb2-7993-4cc1-bbfb-434f6ae1545a",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-08-06T07:07:30.809664Z",
     "iopub.status.busy": "2023-08-06T07:07:30.809165Z",
     "iopub.status.idle": "2023-08-06T07:07:30.852076Z",
     "shell.execute_reply": "2023-08-06T07:07:30.850962Z",
     "shell.execute_reply.started": "2023-08-06T07:07:30.809621Z"
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 257, 257])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spectrogram = torchaudio.transforms.Spectrogram(n_fft=512, hop_length=187)\n",
    "# x = torch.randn(2, 1, 48000)\n",
    "# spectrogram(x).shape"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
