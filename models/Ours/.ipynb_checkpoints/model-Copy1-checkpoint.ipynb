{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f183a79-d07e-4e9f-9606-520ada0bedf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T13:59:30.798027Z",
     "iopub.status.busy": "2023-08-09T13:59:30.797438Z",
     "iopub.status.idle": "2023-08-09T13:59:30.941570Z",
     "shell.execute_reply": "2023-08-09T13:59:30.940863Z",
     "shell.execute_reply.started": "2023-08-09T13:59:30.797978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caf9846-a1a5-49b5-b121-fb92bac2868c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ay2.torch.nn import LambdaFunctionModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4a77b-985e-4aac-a4c7-67dad9261ac5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "from .gradient_reversal import GradientReversal\n",
    "from .modules.classifier import Classifier\n",
    "from .modules.feature_extractor import FeatureExtractor, FeatureExtractor2D\n",
    "from .modules.model_RawNet2 import LayerNorm, RawNet_FeatureExtractor, SincConv_fast\n",
    "from .utils import weight_init\n",
    "\n",
    "from .feature_extractor import LCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8486292c-054f-4225-854e-12604b309f8a",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-08-09T13:59:33.978716Z",
     "iopub.status.busy": "2023-08-09T13:59:33.978231Z",
     "iopub.status.idle": "2023-08-09T13:59:34.014060Z",
     "shell.execute_reply": "2023-08-09T13:59:34.013014Z",
     "shell.execute_reply.started": "2023-08-09T13:59:33.978671Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "active-ipynb",
     "style-solution"
    ]
   },
   "outputs": [],
   "source": [
    "from gradient_reversal import GradientReversal\n",
    "from modules.classifier import Classifier\n",
    "from modules.feature_extractor import FeatureExtractor, FeatureExtractor2D\n",
    "from modules.model_RawNet2 import LayerNorm, RawNet_FeatureExtractor, SincConv_fast\n",
    "from utils import weight_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "416b831f-95fd-4320-b30c-7aa01061e40a",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-08-09T14:58:15.556580Z",
     "iopub.status.busy": "2023-08-09T14:58:15.555664Z",
     "iopub.status.idle": "2023-08-09T14:58:16.363719Z",
     "shell.execute_reply": "2023-08-09T14:58:16.361220Z",
     "shell.execute_reply.started": "2023-08-09T14:58:15.556463Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AudioModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dims=[32, 64, 64, 64, 128],\n",
    "        n_blocks=[1, 1, 1, 2, 1],\n",
    "        n_heads=[1, 2, 2, 4, 1, 1],\n",
    "        samples_per_frame=640,\n",
    "        gru_node=128,\n",
    "        gru_layers=3,\n",
    "        fc_node=128,\n",
    "        num_classes=1,\n",
    "        vocoder_classes=8,\n",
    "        adv_vocoder=False,\n",
    "        cfg=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # self.norm = LayerNorm(48000)\n",
    "        self.dims = dims\n",
    "        # self.feature_model = FeatureExtractor2D(\n",
    "        #     dims=dims,\n",
    "        #     n_blocks=n_blocks,\n",
    "        #     n_heads=n_heads,\n",
    "        #     samples_per_frame=samples_per_frame,\n",
    "        #     use_gru_head=False,\n",
    "        #     gru_node=gru_node,\n",
    "        #     gru_layers=gru_layers,\n",
    "        # )\n",
    "\n",
    "        self.feature_model = LCNN()\n",
    "        self.feature_model.copy_final_stage()\n",
    "        \n",
    "        \n",
    "        # self.voc_stage = deepcopy(self.feature_model.stages[-1])\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.cls_content = nn.Linear(dims[-1], 1, bias=False)\n",
    "        self.cls_voc = nn.Linear(dims[-1], vocoder_classes + 1, bias=False)\n",
    "        self.cls_final = nn.Linear(dims[-1] * 2, 1, bias=False)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.normal_(m.weight, mean=1, std=0.02)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # self.apply(weight_init)\n",
    "\n",
    "    \n",
    "    def preprocess(self, x, stage='test'):\n",
    "        x = self.spectrogram(x)\n",
    "        x = torch.log(x + 1e-7)\n",
    "     \n",
    "        \n",
    "        if self.debug:\n",
    "            print('log-scale feature : ', x.shape)\n",
    "        \n",
    "        # if stage=='train':\n",
    "        #     x = self.transform(x)\n",
    "\n",
    "        x = (x - torch.mean(x, dim=(1, 2, 3), keepdim=True)) / (\n",
    "            torch.std(x, dim=(1, 2, 3), keepdim=True) + 1e-9\n",
    "        )\n",
    "        return x\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(self, x, stage=\"test\"):\n",
    "        batch_size = x.shape[0]\n",
    "        res = {}\n",
    "\n",
    "        x = self.preprocess(x)\n",
    "        \n",
    "        stage_id = len(self.dims) - 2\n",
    "        hidden_state = self.feature_model.get_hidden_state(x, stage_id=stage_id, stage=stage)\n",
    "\n",
    "        \n",
    "        res[\"content_feature\"] = self.feature_model.get_final_feature(\n",
    "            hidden_state, stage_id=stage_id\n",
    "        )\n",
    "        res[\"vocoder_feature\"] = self.feature_model.pool_reshape(\n",
    "            self.voc_stage(hidden_state)\n",
    "        )\n",
    "\n",
    "        # print(res[\"content_feature\"].shape)\n",
    "        \n",
    "        res[\"content_logit\"] = self.cls_content(\n",
    "            self.dropout(res[\"content_feature\"])\n",
    "        ).squeeze()\n",
    "        res[\"content_voc_logit\"] = self.cls_voc(self.dropout(res[\"content_feature\"]))\n",
    "\n",
    "        \n",
    "        res[\"vocoder_logit\"] = self.cls_voc(self.dropout(res[\"vocoder_feature\"]))\n",
    "\n",
    "        \n",
    "        res[\"logit\"] = self.cls_final(\n",
    "            self.dropout(\n",
    "                torch.concat([res[\"content_feature\"], res[\"vocoder_feature\"]], dim=-1)\n",
    "            )\n",
    "        ).squeeze()\n",
    "        res[\"aug_logit\"] = self.cls_final(\n",
    "            self.dropout(\n",
    "                torch.concat(\n",
    "                    [\n",
    "                        res[\"content_feature\"],\n",
    "                        res[\"vocoder_feature\"][torch.randperm(batch_size)],\n",
    "                    ],\n",
    "                    dim=-1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48146a05-6034-4d67-b788-45acb6700ffb",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-08-09T14:59:47.738745Z",
     "iopub.status.busy": "2023-08-09T14:59:47.738145Z",
     "iopub.status.idle": "2023-08-09T14:59:50.482245Z",
     "shell.execute_reply": "2023-08-09T14:59:50.481094Z",
     "shell.execute_reply.started": "2023-08-09T14:59:47.738693Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "style-activity",
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "model = AudioModel(vocoder_classes=7)\n",
    "x = torch.randn(32, 1, 48000)\n",
    "_ = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78813c98-620f-4189-adef-6ab216a760bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T14:00:42.856950Z",
     "iopub.status.busy": "2023-08-09T14:00:42.856267Z",
     "iopub.status.idle": "2023-08-09T14:00:42.962920Z",
     "shell.execute_reply": "2023-08-09T14:00:42.961630Z",
     "shell.execute_reply.started": "2023-08-09T14:00:42.856875Z"
    },
    "scrolled": true,
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(\n",
    "    \"/home/ay/data/DATA/1-model_save/0-Audio/Ours/LibriSeVoc_cross_dataset/version_7/checkpoints/best-epoch=3-val-auc=0.99.ckpt\"\n",
    ")\n",
    "\n",
    "state_dict = ckpt[\"state_dict\"]\n",
    "\n",
    "state_dict2 = {key.replace(\"model.\", \"\", 1): state_dict[key] for key in state_dict}\n",
    "\n",
    "model.load_state_dict(state_dict2)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
