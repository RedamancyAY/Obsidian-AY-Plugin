{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fffeb70d-1801-4fe8-a6f9-3f63dd1b2135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T07:40:11.020579Z",
     "iopub.status.busy": "2024-01-05T07:40:11.020257Z",
     "iopub.status.idle": "2024-01-05T07:40:11.040458Z",
     "shell.execute_reply": "2024-01-05T07:40:11.039398Z",
     "shell.execute_reply.started": "2024-01-05T07:40:11.020551Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952afce9-3ad1-417a-a875-6df922c3a45b",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79663f92-2e5d-4a34-973c-0dabba47a0a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T07:40:50.635878Z",
     "iopub.status.busy": "2024-01-05T07:40:50.635537Z",
     "iopub.status.idle": "2024-01-05T07:40:51.172708Z",
     "shell.execute_reply": "2024-01-05T07:40:51.171501Z",
     "shell.execute_reply.started": "2024-01-05T07:40:50.635841Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from ay2.torch.nn import LambdaFunctionModule\n",
    "from ay2.torchaudio.transforms import SpecAugmentBatchTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "300637af-6629-4016-aa0e-197451ab3a5a",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-01-05T07:41:57.486512Z",
     "iopub.status.busy": "2024-01-05T07:41:57.485205Z",
     "iopub.status.idle": "2024-01-05T07:41:58.412936Z",
     "shell.execute_reply": "2024-01-05T07:41:58.412001Z",
     "shell.execute_reply.started": "2024-01-05T07:41:57.486430Z"
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from .gru_head import GRU_Head\n",
    "    from .msfm import  MultiScaleFusion2D\n",
    "except ImportError:\n",
    "    from gru_head import GRU_Head\n",
    "    from msfm import MultiScaleFusion2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8288c-a688-48c9-ba67-280dc043a627",
   "metadata": {},
   "source": [
    "## Build stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c10101a9-2167-476b-9acd-035672858aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T07:42:20.973726Z",
     "iopub.status.busy": "2024-01-05T07:42:20.972470Z",
     "iopub.status.idle": "2024-01-05T07:42:21.033419Z",
     "shell.execute_reply": "2024-01-05T07:42:21.032131Z",
     "shell.execute_reply.started": "2024-01-05T07:42:20.973647Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_stage2D(\n",
    "    n_dim_in, n_dim_out, n_blocks, samples_per_frame, n_head=1, downsample_factor=1\n",
    "):\n",
    "    # print(n_dim_in, n_dim_out)\n",
    "    conv1 = nn.Conv2d(n_dim_in, n_dim_out, 3, stride=1, padding=1, bias=False)\n",
    "    conv_blocks = [\n",
    "        MultiScaleFusion2D(\n",
    "            n_dim=n_dim_out,\n",
    "            n_head=n_head,\n",
    "            samples_per_frame=samples_per_frame,\n",
    "        )\n",
    "        for i in range(n_blocks)\n",
    "    ]\n",
    "    module = nn.Sequential(conv1, *conv_blocks)\n",
    "    if downsample_factor > 1:\n",
    "        module.add_module(\n",
    "            \"down-sample\",\n",
    "            # nn.Conv2d(n_dim_out, n_dim_out, 3, stride=2, padding=2)\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(n_dim_out, n_dim_out, 1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(n_dim_out),\n",
    "            ),\n",
    "        )\n",
    "    return module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5155197a-a36f-46a6-b56c-5088a2901043",
   "metadata": {},
   "source": [
    "## FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7cbcce-12a3-4d7a-b5a5-e9c7f04506a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T14:43:19.467205Z",
     "iopub.status.busy": "2024-01-13T14:43:19.466570Z",
     "iopub.status.idle": "2024-01-13T14:43:19.734798Z",
     "shell.execute_reply": "2024-01-13T14:43:19.733804Z",
     "shell.execute_reply.started": "2024-01-13T14:43:19.467143Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMultiAudioTransforms\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      4\u001b[0m     ):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class MultiAudioTransforms(nn.Module):\n",
    "    def __init__(\n",
    "        self, specaug_policy='ss'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.t1 = torchaudio.transforms.Spectrogram(n_fft=400, hop_length=160)\n",
    "        self.t2 = torchaudio.transforms.LFCC(\n",
    "            n_lfcc=201,\n",
    "            speckwargs={\"n_fft\": 400, \"hop_length\": 160, \"center\": True},\n",
    "        )\n",
    "        self.t3 = torchaudio.transforms.MFCC(\n",
    "            n_mfcc=201,\n",
    "            melkwargs={\n",
    "                \"n_fft\": 400,\n",
    "                \"n_mels\": 201,\n",
    "                \"hop_length\": 160,\n",
    "                \"mel_scale\": \"htk\",\n",
    "            },\n",
    "        )\n",
    "        self.transform = SpecAugmentBatchTransform.from_policy(specaug_policy)\n",
    "        \n",
    "\n",
    "    def norm(self, x):\n",
    "        # return (x - torch.mean(x)) / (torch.std(x) + 1e-9)\n",
    "\n",
    "        return (x - torch.mean(x, dim=(1, 2, 3), keepdim=True)) / (\n",
    "            torch.std(x, dim=(1, 2, 3), keepdim=True) + 1e-9\n",
    "        )\n",
    "\n",
    "    def __call__(self, x, stage='test'):\n",
    "        ## spectrogram\n",
    "        y1 = self.t1(x)\n",
    "        y1 = torch.log(y1 + 1e-7)\n",
    "        y1 = self.norm(y1)\n",
    "\n",
    "        # return y1\n",
    "        \n",
    "        \n",
    "        ## LFCC\n",
    "        y2 = self.t2(x)\n",
    "        # y2 = self.norm(y2)\n",
    "        ## MFCC\n",
    "        # y3 = self.t3(x)\n",
    "\n",
    "        \n",
    "        if stage == 'train':\n",
    "            y1 = self.transform.batch_apply(y1)\n",
    "            y2 = self.transform.batch_apply(y2)\n",
    "            # print(stage, y1.shape, y2.shape)\n",
    "        \n",
    "        res = torch.concat([y1, y2], dim=1)\n",
    "        # res = self.norm(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94bc07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "138506d3-c4a5-41fd-aedf-35589c8fff27",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-01-05T12:41:07.484154Z",
     "iopub.status.busy": "2024-01-05T12:41:07.483776Z",
     "iopub.status.idle": "2024-01-05T12:41:07.548415Z",
     "shell.execute_reply": "2024-01-05T12:41:07.547407Z",
     "shell.execute_reply.started": "2024-01-05T12:41:07.484127Z"
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor2D(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dims=[32, 64, 64, 128],\n",
    "        n_blocks=[1, 1, 2, 1],\n",
    "        n_heads=[1, 2, 2, 4],\n",
    "        samples_per_frame=400,\n",
    "        use_gru_head=False,\n",
    "        gru_node=512,\n",
    "        gru_layers=3,\n",
    "        args=None,\n",
    "        cfg=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dims = dims\n",
    "        self.samples_per_frame = samples_per_frame\n",
    "        self.conv_head = nn.Sequential(\n",
    "            nn.Conv2d(2, dims[0], 3, stride=2, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(dims[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(dims[0], dims[0], 3, stride=2, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(dims[0]), ####\n",
    "        )\n",
    "\n",
    "        # print(dims)\n",
    "        self.stages = nn.ModuleList(\n",
    "            [\n",
    "                build_stage2D(\n",
    "                    n_dim_in=dims[max(i - 1, 0)],\n",
    "                    n_dim_out=dims[i],\n",
    "                    n_blocks=n_blocks[i],\n",
    "                    n_head=n_heads[i],\n",
    "                    samples_per_frame=samples_per_frame // (4 * (2**i)),\n",
    "                    downsample_factor=2 if i < len(dims) - 1 else 1,\n",
    "                    # downsample_factor=2,\n",
    "                )\n",
    "                for i in range(len(dims))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # self.conv_tail = nn.Sequential(\n",
    "        #     nn.Conv2d(dims[-1], dims[-1], 3, stride=1, padding=1),\n",
    "        #     # nn.BatchNorm2d(dims[-1]),\n",
    "        # )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # self.transform = SpecAugmentBatchTransform.from_policy(\"ld\")\n",
    "\n",
    "        self.debug = False\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.normal_(m.weight, mean=1, std=0.02)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # self.spectrogram = torchaudio.transforms.Spectrogram(n_fft=512, hop_length=187)\n",
    "        # self.spectrogram = torchaudio.transforms.LFCC(\n",
    "        #     n_lfcc=60 * 2,\n",
    "        #     speckwargs={\"n_fft\": 400, \"hop_length\": 160, \"center\": False},\n",
    "        # )\n",
    "        self.spectrogram = MultiAudioTransforms(specaug_policy=cfg.aug_policy)\n",
    "\n",
    "    def get_content_stream_modules(self, ):\n",
    "        return [self.conv_head, self.stages[0], self.stages[1], self.stages[2]]\n",
    "    \n",
    "    \n",
    "    def preprocess(self, x, stage='test'):\n",
    "        x = self.spectrogram(x, stage=stage)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def build_final_block(self):\n",
    "        from copy import deepcopy\n",
    "        return deepcopy(self.stages[3])\n",
    "\n",
    "    \n",
    "    def copy_final_stage(self):\n",
    "        self.stage3_copy = self.build_final_block()\n",
    "\n",
    "    def get_final_block_parameters(self):\n",
    "        return self.stages[3].parameters()\n",
    "        \n",
    "    def get_copied_final_block_parameters(self):\n",
    "        return self.stage3_copy.parameters()\n",
    "\n",
    "    \n",
    "    def get_main_stem(self):\n",
    "        return [self.conv_head, self.stages[0], self.stages[1], self.stages[2]]\n",
    "\n",
    "    def get_content_stem(self):\n",
    "        return [self.stages[3]]\n",
    "\n",
    "    def get_vocoder_stem(self):\n",
    "        return [self.stage3_copy]\n",
    "    \n",
    "    def get_hidden_state(self, x):\n",
    "        x = self.conv_head(x)\n",
    "        x = self.stages[0](x)\n",
    "        x = self.stages[1](x)\n",
    "        x = self.stages[2](x)\n",
    "        return x\n",
    "        \n",
    "    def feature_norm(self, code):\n",
    "        code_norm = code.norm(p=2,dim=1, keepdim=True) / 10.\n",
    "        code = torch.div(code, code_norm)\n",
    "        return code\n",
    "        \n",
    "    def pool_reshape(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.feature_norm(x)\n",
    "        return x\n",
    "    \n",
    "    def get_final_feature(self, x):\n",
    "        x = self.stages[3](x)\n",
    "        x = self.pool_reshape(x)\n",
    "        return x\n",
    "\n",
    "    def get_final_feature_copyed(self, x): \n",
    "        x = self.stage3_copy(x)\n",
    "        x = self.pool_reshape(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
