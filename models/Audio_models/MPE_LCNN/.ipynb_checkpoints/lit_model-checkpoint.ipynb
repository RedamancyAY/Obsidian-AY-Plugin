{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c30d50-21ff-47d0-8c32-1edcb9deff59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T07:08:40.639752Z",
     "iopub.status.busy": "2024-08-03T07:08:40.638353Z",
     "iopub.status.idle": "2024-08-03T07:08:40.680417Z",
     "shell.execute_reply": "2024-08-03T07:08:40.678782Z",
     "shell.execute_reply.started": "2024-08-03T07:08:40.639677Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f159518-e012-46c9-a8e4-8ec1f9f21111",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T07:09:12.679170Z",
     "iopub.status.busy": "2024-08-03T07:09:12.678677Z",
     "iopub.status.idle": "2024-08-03T07:09:13.718053Z",
     "shell.execute_reply": "2024-08-03T07:09:13.716688Z",
     "shell.execute_reply.started": "2024-08-03T07:09:12.679115Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ay2.torch.deepfake_detection import DeepfakeAudioClassification\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9613d902-80cd-4e99-a4fa-ff83ae0dddc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T03:45:05.415729Z",
     "iopub.status.busy": "2024-08-01T03:45:05.415411Z",
     "iopub.status.idle": "2024-08-01T03:45:05.436626Z",
     "shell.execute_reply": "2024-08-01T03:45:05.435657Z",
     "shell.execute_reply.started": "2024-08-01T03:45:05.415712Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchaudio.transforms import LFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c2f11c-3b11-4813-b2a7-08217f4414b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T07:08:42.366449Z",
     "iopub.status.busy": "2024-08-03T07:08:42.365180Z",
     "iopub.status.idle": "2024-08-03T07:08:43.732770Z",
     "shell.execute_reply": "2024-08-03T07:08:43.731534Z",
     "shell.execute_reply.started": "2024-08-03T07:08:42.366386Z"
    },
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from .lcnn import LCNN\n",
    "except ImportError:\n",
    "    from lcnn import LCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f90256e-a8b4-4a55-bc0f-99fd8cd1b13c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T07:11:57.807734Z",
     "iopub.status.busy": "2024-08-03T07:11:57.807464Z",
     "iopub.status.idle": "2024-08-03T07:11:57.889588Z",
     "shell.execute_reply": "2024-08-03T07:11:57.888155Z",
     "shell.execute_reply.started": "2024-08-03T07:11:57.807711Z"
    }
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     from senet.se_resnet import se_resnet18\n",
    "# except ImportError:\n",
    "#     from .senet.se_resnet import se_resnet18\n",
    "\n",
    "# model = se_resnet18()\n",
    "\n",
    "# x = torch.randn(2, 3, 224, 224)\n",
    "# model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8859edc-0828-44bc-ae84-985593a8a6bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T03:45:06.099465Z",
     "iopub.status.busy": "2024-08-01T03:45:06.099225Z",
     "iopub.status.idle": "2024-08-01T03:45:06.125108Z",
     "shell.execute_reply": "2024-08-01T03:45:06.124350Z",
     "shell.execute_reply.started": "2024-08-01T03:45:06.099449Z"
    }
   },
   "outputs": [],
   "source": [
    "from ay2.tools import TimerContextManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f23eaee5-6f24-47ee-a299-b962ac07018d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T04:48:36.439307Z",
     "iopub.status.busy": "2024-08-01T04:48:36.438950Z",
     "iopub.status.idle": "2024-08-01T04:48:36.503183Z",
     "shell.execute_reply": "2024-08-01T04:48:36.501533Z",
     "shell.execute_reply.started": "2024-08-01T04:48:36.439279Z"
    }
   },
   "outputs": [],
   "source": [
    "def Permutation_Entropy_torch_batched(x, m, t, debug=False):\n",
    "    \"\"\"计算批量排列熵值\n",
    "    参数:\n",
    "    x: 输入数据，应为二维张量，形状[batch_size, sequence_length]\n",
    "    m: 嵌入维度\n",
    "    t: 时间延迟\n",
    "    \"\"\"\n",
    "    # 获取每批数据的长度\n",
    "    batch_size, seq_len = x.shape\n",
    "    length = seq_len - (m - 1) * t\n",
    "\n",
    "    # 生成索引进行批量操作\n",
    "    indexes = (torch.arange(length, device=x.device).unsqueeze(0) + torch.arange(m, device=x.device).unsqueeze(1) * t)\n",
    "    # 使用高效的张量操作提取需要的序列\n",
    "    sequences_stacked = (\n",
    "        x.unsqueeze(1).expand(-1, m, -1).gather(2, indexes.expand(batch_size, -1, -1)).transpose(1, 2)\n",
    "    )\n",
    "    # print(sequences_stacked.shape)\n",
    "\n",
    "    ####升序排序并获取排序后的排列索引\n",
    "    S = torch.argsort(sequences_stacked, dim=2)\n",
    "\n",
    "    \n",
    "    ####对排列索引进行编码以形成唯一的序列标识\n",
    "    multiplier = torch.pow(10, torch.arange(m)).to(x.device).unsqueeze(0).unsqueeze(0)\n",
    "    S_encoded = (S * multiplier).sum(-1)\n",
    "\n",
    "    # 对每一批次数据计算排列熵\n",
    "    pe_batched = torch.zeros(batch_size, device=x.device)\n",
    "    # with TimerContextManager(f\"sort\", debug=debug):\n",
    "    sorted_S, _ = torch.sort(S_encoded, 1)\n",
    "    org_sorted_S = sorted_S\n",
    "    sorted_S = torch.concat([sorted_S, torch.zeros(batch_size, 1, device=sorted_S.device, dtype=sorted_S.dtype)], 1)\n",
    "    values, counts = torch.unique_consecutive(sorted_S, return_counts=True)\n",
    "    indexs = torch.nonzero(values == 0).squeeze()\n",
    "\n",
    "    freq_list = counts / length\n",
    "    freq_list = -1 * freq_list * torch.log(freq_list)\n",
    "    M = np.log(np.math.factorial(m))\n",
    "\n",
    "    # with TimerContextManager(f\"unique\", debug=debug):\n",
    "    for i in range(batch_size):\n",
    "        # _, _counts = torch.unique(S_encoded[i], return_counts=True)\n",
    "        # _sorted,_ = torch.sort(S_encoded[i])\n",
    "        # _, _counts=torch.unique_consecutive(sorted_S[i], return_counts=True)\n",
    "        s = 0 if i == 0 else (indexs[i - 1] + 1)\n",
    "        e = indexs[i]\n",
    "        _counts = counts[s:e]\n",
    "\n",
    "        # freq_list = _counts.float() / length\n",
    "        # pe_batched[i] = torch.sum(-1 * freq_list * torch.log(freq_list)) / np.log(np.math.factorial(m))\n",
    "        pe_batched[i] = torch.sum(freq_list[s:e]) / M\n",
    "\n",
    "    return pe_batched\n",
    "\n",
    "\n",
    "def batched_MSE_torch(signal, max_scale: int = 20, debug=False):\n",
    "    # 信号形状为[batch_size, seq_len]\n",
    "    batch_size, seq_len = signal.shape\n",
    "    std = torch.std(signal, dim=1, keepdim=True)\n",
    "\n",
    "    # 初始化结果列表\n",
    "    result = torch.zeros(batch_size, max_scale, device=signal.device)\n",
    "\n",
    "    # 对于向量化，我们可能需要在这个处理中保留一些循环，\n",
    "    # 由于需要处理不同尺度下的变换。\n",
    "    for scale in range(1, max_scale + 1):\n",
    "        reshaped = signal[:, : (seq_len // scale * scale)].reshape(batch_size, -1, scale)\n",
    "        signal_new = torch.mean(reshaped, dim=2)\n",
    "        # with TimerContextManager(f\"{scale} PE\", debug=debug):\n",
    "        pe = Permutation_Entropy_torch_batched(signal_new, 10, 2, debug=debug).squeeze()\n",
    "        result[:, scale - 1] = pe\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def batched_compute_mpe(x, debug=False):\n",
    "    # 假设x形状为[batch_size, seq_len]\n",
    "    signal_flu = torch.diff(x, dim=1)\n",
    "    scale = 20\n",
    "    mpe = batched_MSE_torch(signal_flu, scale, debug=debug)  # (batch_size, scale)\n",
    "    return mpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3b694720-38e7-4bce-a453-1f1db83ed0a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T04:47:44.516366Z",
     "iopub.status.busy": "2024-08-01T04:47:44.516044Z",
     "iopub.status.idle": "2024-08-01T04:47:44.570018Z",
     "shell.execute_reply": "2024-08-01T04:47:44.568256Z",
     "shell.execute_reply.started": "2024-08-01T04:47:44.516340Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from ay2.torchaudio.transforms._MPE_LFCC import compute_mpe\n",
    "\n",
    "# x = torch.randint(0, 8, (64, 1, 48000)).float().cuda()\n",
    "\n",
    "# with TimerContextManager(debug=True):\n",
    "#     for i in range(64):\n",
    "#         v = compute_mpe(x[i, 0])\n",
    "#         print(v)\n",
    "\n",
    "# %time batched_compute_mpe(x[:, 0, :], debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cd1e8dec-afa7-4570-9005-12ec9fe17abb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T04:48:49.651368Z",
     "iopub.status.busy": "2024-08-01T04:48:49.651105Z",
     "iopub.status.idle": "2024-08-01T04:48:54.018234Z",
     "shell.execute_reply": "2024-08-01T04:48:54.017367Z",
     "shell.execute_reply.started": "2024-08-01T04:48:49.651348Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2990711/3620087236.py:39: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
      "  M = np.log(np.math.factorial(m))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 176 ms, sys: 2 µs, total: 176 ms\n",
      "Wall time: 175 ms\n",
      "CPU times: user 170 ms, sys: 0 ns, total: 170 ms\n",
      "Wall time: 170 ms\n",
      "CPU times: user 169 ms, sys: 17 µs, total: 169 ms\n",
      "Wall time: 169 ms\n",
      "CPU times: user 169 ms, sys: 14 µs, total: 169 ms\n",
      "Wall time: 168 ms\n",
      "CPU times: user 170 ms, sys: 0 ns, total: 170 ms\n",
      "Wall time: 169 ms\n",
      "CPU times: user 169 ms, sys: 2 µs, total: 169 ms\n",
      "Wall time: 169 ms\n",
      "CPU times: user 169 ms, sys: 26 µs, total: 169 ms\n",
      "Wall time: 168 ms\n",
      "CPU times: user 169 ms, sys: 0 ns, total: 169 ms\n",
      "Wall time: 169 ms\n",
      "CPU times: user 171 ms, sys: 0 ns, total: 171 ms\n",
      "Wall time: 171 ms\n",
      "CPU times: user 169 ms, sys: 11 µs, total: 169 ms\n",
      "Wall time: 169 ms\n",
      "CPU times: user 170 ms, sys: 0 ns, total: 170 ms\n",
      "Wall time: 170 ms\n",
      "CPU times: user 169 ms, sys: 9 µs, total: 169 ms\n",
      "Wall time: 169 ms\n",
      "CPU times: user 170 ms, sys: 0 ns, total: 170 ms\n",
      "Wall time: 170 ms\n",
      "CPU times: user 159 ms, sys: 0 ns, total: 159 ms\n",
      "Wall time: 159 ms\n",
      "CPU times: user 124 ms, sys: 0 ns, total: 124 ms\n",
      "Wall time: 124 ms\n",
      "CPU times: user 121 ms, sys: 12 µs, total: 121 ms\n",
      "Wall time: 121 ms\n",
      "CPU times: user 123 ms, sys: 0 ns, total: 123 ms\n",
      "Wall time: 122 ms\n",
      "CPU times: user 121 ms, sys: 6 µs, total: 121 ms\n",
      "Wall time: 121 ms\n",
      "CPU times: user 122 ms, sys: 0 ns, total: 122 ms\n",
      "Wall time: 122 ms\n",
      "CPU times: user 121 ms, sys: 0 ns, total: 121 ms\n",
      "Wall time: 121 ms\n",
      "CPU times: user 122 ms, sys: 35 µs, total: 122 ms\n",
      "Wall time: 121 ms\n",
      "CPU times: user 122 ms, sys: 0 ns, total: 122 ms\n",
      "Wall time: 122 ms\n",
      "CPU times: user 123 ms, sys: 0 ns, total: 123 ms\n",
      "Wall time: 122 ms\n",
      "CPU times: user 120 ms, sys: 0 ns, total: 120 ms\n",
      "Wall time: 120 ms\n",
      "CPU times: user 123 ms, sys: 0 ns, total: 123 ms\n",
      "Wall time: 123 ms\n",
      "CPU times: user 121 ms, sys: 0 ns, total: 121 ms\n",
      "Wall time: 121 ms\n",
      "CPU times: user 123 ms, sys: 0 ns, total: 123 ms\n",
      "Wall time: 122 ms\n",
      "CPU times: user 120 ms, sys: 0 ns, total: 120 ms\n",
      "Wall time: 120 ms\n",
      "CPU times: user 121 ms, sys: 0 ns, total: 121 ms\n",
      "Wall time: 121 ms\n",
      "CPU times: user 120 ms, sys: 0 ns, total: 120 ms\n",
      "Wall time: 120 ms\n"
     ]
    }
   ],
   "source": [
    "# for i in range(30):\n",
    "#     %time batched_compute_mpe(x[:, 0, :], debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372acf31-95d6-41ff-b958-44c3629976d1",
   "metadata": {},
   "source": [
    "# MPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5455f65b-7352-462d-9cbd-5b2025ca69f0",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MPE_LCNN_lit(DeepfakeAudioClassification):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.model = LCNN(num_class=1)\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lfcc = LFCC(\n",
    "            n_lfcc=60,\n",
    "            speckwargs={\"n_fft\": 400, \"hop_length\": 160, \"center\": False},\n",
    "        )\n",
    "\n",
    "    def calcuate_loss(self, batch_res, batch):\n",
    "        label = batch[\"label\"]\n",
    "        loss = self.loss_fn(batch_res[\"logit\"], label.type(torch.float32))\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "        return [optimizer]\n",
    "\n",
    "    def _shared_pred(self, batch, batch_idx):\n",
    "        audio, sample_rate = batch[\"audio\"], batch[\"sample_rate\"]\n",
    "\n",
    "        # audio, mpe = audio[:, :, :48000], audio[:, :, 48000:]\n",
    "        lfcc = self.lfcc(audio) # (b, 1, h, w)\n",
    "        mpe = batched_compute_mpe(audio[:, 0, :])\n",
    "        # mpe = torch.zeros(lfcc.shape[0], 20, device=lfcc.device)\n",
    "\n",
    "        # mpe = lfcc[:, 0, 0, :20]\n",
    "        \n",
    "        lfcc = rearrange(lfcc, \"b 1 h w -> b 1 (h w)\")\n",
    "        audio = torch.concat([mpe[:, None, :], lfcc], dim=2)\n",
    "\n",
    "        # print(audio.shape, batch[\"label\"].shape)\n",
    "        \n",
    "        audio = self.lfcc(audio)\n",
    "        # audio = lfcc\n",
    "\n",
    "        # batch_out = self.model(audio).squeeze()\n",
    "        feature = self.model.extract_feature(audio)\n",
    "        batch_out = self.model.make_prediction(feature).squeeze(-1)\n",
    "        batch_pred = (torch.sigmoid(batch_out) + 0.5).int()\n",
    "        return {\"logit\": batch_out, \"pred\": batch_pred, \"feature\": feature}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f133a-b03a-438b-8935-2a601db5bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ay2.torchaudio.transforms import MPE_LFCC\n",
    "\n",
    "# x = torch.randn(1, 48000).cuda()\n",
    "# mpe = MPE_LFCC()\n",
    "\n",
    "# lfcc = LFCC(\n",
    "#             n_lfcc=60,\n",
    "#             speckwargs={\"n_fft\": 400, \"hop_length\": 160, \"center\": False},\n",
    "#         ).cuda()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
