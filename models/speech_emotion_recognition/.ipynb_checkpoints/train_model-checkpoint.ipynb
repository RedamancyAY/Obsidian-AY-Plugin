{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8456720-69a9-4c4f-bb7a-7de31210812b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T15:28:35.153137Z",
     "iopub.status.busy": "2023-07-25T15:28:35.152644Z",
     "iopub.status.idle": "2023-07-25T15:28:35.185443Z",
     "shell.execute_reply": "2023-07-25T15:28:35.184157Z",
     "shell.execute_reply.started": "2023-07-25T15:28:35.153090Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5459222d-a773-451b-a1ec-36458e366905",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T15:31:57.070016Z",
     "iopub.status.busy": "2023-07-25T15:31:57.069530Z",
     "iopub.status.idle": "2023-07-25T15:31:57.243374Z",
     "shell.execute_reply": "2023-07-25T15:31:57.241974Z",
     "shell.execute_reply.started": "2023-07-25T15:31:57.069971Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from tqdm import tqdm\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import (\n",
    "    Wav2Vec2Model,\n",
    "    Wav2Vec2PreTrainedModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aa66a1cc-399c-47f6-bf62-3afe3ef40b0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T06:02:29.941953Z",
     "iopub.status.busy": "2023-07-26T06:02:29.941466Z",
     "iopub.status.idle": "2023-07-26T06:02:29.992181Z",
     "shell.execute_reply": "2023-07-26T06:02:29.991238Z",
     "shell.execute_reply.started": "2023-07-26T06:02:29.941908Z"
    }
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from ay.torch.audio_df_detection import BinaryClassification\n",
    "from ay.torch.lightning.callbacks import (\n",
    "    ACC_Callback,\n",
    "    APCallback,\n",
    "    AUC_Callback,\n",
    "    Color_progress_bar,\n",
    "    EER_Callback,\n",
    ")\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from models.WaveLM.wavlm import BaseLine as WaveLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a354a7a2-013d-4688-a0c8-8281ac0cf2cd",
   "metadata": {},
   "source": [
    "## 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77327b6-8cb3-4673-ad3e-327582042d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ._data import get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfaab1c-287c-4e57-aac4-c5db6e09ccd7",
   "metadata": {},
   "source": [
    "## 预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b96718c8-be7e-4bb8-b2fc-f8d789411ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T14:26:19.466733Z",
     "iopub.status.busy": "2023-07-26T14:26:19.466157Z",
     "iopub.status.idle": "2023-07-26T14:26:19.529088Z",
     "shell.execute_reply": "2023-07-26T14:26:19.528311Z",
     "shell.execute_reply.started": "2023-07-26T14:26:19.466676Z"
    }
   },
   "outputs": [],
   "source": [
    "class WaveLM_lit(BinaryClassification):\n",
    "    def __init__(self, num_classes=1, **kwargs):\n",
    "        super().__init__()\n",
    "        self.model = WaveLM(num_classes=13)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def calcuate_loss(self, batch_res, batch):\n",
    "        label = batch[\"label\"]\n",
    "        loss = self.loss_fn(batch_res[\"logit\"], label)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.model.parameters(), lr=0.0001, weight_decay=0.0001\n",
    "        )\n",
    "        return [optimizer]\n",
    "\n",
    "    def _shared_pred(self, batch, batch_idx):\n",
    "        audio, sample_rate = batch[\"audio\"], batch[\"sample_rate\"]\n",
    "        if len(audio.shape) == 3:\n",
    "            audio = audio[:, 0, :]\n",
    "\n",
    "        out = self.model(audio)\n",
    "        return {\"logit\": out}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1e3985-7150-444c-b5ef-d2a014fd0b4b",
   "metadata": {},
   "source": [
    "### callback & trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9220e9be-24aa-4191-9148-eefdcc1da96f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T14:26:21.660866Z",
     "iopub.status.busy": "2023-07-26T14:26:21.659852Z",
     "iopub.status.idle": "2023-07-26T14:26:21.719773Z",
     "shell.execute_reply": "2023-07-26T14:26:21.718784Z",
     "shell.execute_reply.started": "2023-07-26T14:26:21.660818Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "def make_callbacks():\n",
    "    callbacks = [\n",
    "        Color_progress_bar(),\n",
    "        ModelCheckpoint(\n",
    "            dirpath=None,\n",
    "            save_top_k=1,\n",
    "            monitor=\"val-loss\",\n",
    "            mode=\"min\",\n",
    "            save_last=True,\n",
    "            filename=\"best-{epoch}-{val-loss:.2f}\",\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor=\"val-auc\",\n",
    "            min_delta=0.0001,\n",
    "            patience=5,\n",
    "            mode=\"max\",\n",
    "            stopping_threshold=0.999,\n",
    "            verbose=True,\n",
    "        ),\n",
    "        AUC_Callback(batch_key=\"label\", output_key=\"logit\", num_classes=13),\n",
    "    ]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e9180-1f1d-495b-be66-e459e598bf84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T14:26:26.079442Z",
     "iopub.status.busy": "2023-07-26T14:26:26.078884Z",
     "iopub.status.idle": "2023-07-26T15:09:41.611044Z",
     "shell.execute_reply": "2023-07-26T15:09:41.610582Z",
     "shell.execute_reply.started": "2023-07-26T14:26:26.079394Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/home/ay/data/DATA/1-model_save/0-Audio\"\n",
    "\n",
    "def train_SER(gpu=0):\n",
    "    dl = get_data()\n",
    "\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=300,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=[gpu],\n",
    "        logger=pl.loggers.CSVLogger(\n",
    "            ROOT_DIR,\n",
    "            name=\"speech_emotion_recognition\",\n",
    "            version=None,\n",
    "        ),\n",
    "        check_val_every_n_epoch=1,\n",
    "        callbacks=make_callbacks(),\n",
    "        default_root_dir=ROOT_DIR,\n",
    "    )\n",
    "\n",
    "    model = WaveLM_lit(num_classes=13)\n",
    "    trainer.fit(model, dl.train, val_dataloaders=dl.val)\n",
    "    trainer.test(model, dl.test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
