{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb20e1cd-542b-4170-94fc-ba1870f1a77e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T07:13:16.108941Z",
     "iopub.status.busy": "2024-08-10T07:13:16.107622Z",
     "iopub.status.idle": "2024-08-10T07:13:16.151172Z",
     "shell.execute_reply": "2024-08-10T07:13:16.149715Z",
     "shell.execute_reply.started": "2024-08-10T07:13:16.108871Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910a0d69-fffd-4a4b-add2-7485bad0e0ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T07:13:17.172087Z",
     "iopub.status.busy": "2024-08-10T07:13:17.170804Z",
     "iopub.status.idle": "2024-08-10T07:13:18.717210Z",
     "shell.execute_reply": "2024-08-10T07:13:18.716420Z",
     "shell.execute_reply.started": "2024-08-10T07:13:17.172018Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from ay2.tools import freeze_modules\n",
    "from ay2.torch.nn import LambdaFunctionModule\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3806ff31-8724-43a1-9355-950918107dc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T07:13:18.718658Z",
     "iopub.status.busy": "2024-08-10T07:13:18.718402Z",
     "iopub.status.idle": "2024-08-10T07:13:19.350298Z",
     "shell.execute_reply": "2024-08-10T07:13:19.349194Z",
     "shell.execute_reply.started": "2024-08-10T07:13:18.718637Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04ca189f-8b60-4c56-9511-5035ffe56343",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T07:13:38.973589Z",
     "iopub.status.busy": "2024-08-10T07:13:38.972846Z",
     "iopub.status.idle": "2024-08-10T07:13:39.568232Z",
     "shell.execute_reply": "2024-08-10T07:13:39.566956Z",
     "shell.execute_reply.started": "2024-08-10T07:13:38.973553Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from ..Aaasist.Aaasist.load_model import get_model  as load_AASIST\n",
    "    from ..WaveLM.wavlm import BaseLine as WavLM\n",
    "except ImportError:\n",
    "    sys.path.append(\"../Aaasist\")\n",
    "    sys.path.append(\"../WaveLM\")\n",
    "    from Aaasist.load_model import get_model as load_AASIST\n",
    "    from wavlm import BaseLine as WavLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d49c16-fb32-4e46-a208-24db75a27f13",
   "metadata": {},
   "source": [
    "# 1D models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff2d721-98c6-4119-9539-bf146437a93c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T07:13:41.468686Z",
     "iopub.status.busy": "2024-08-10T07:13:41.467780Z",
     "iopub.status.idle": "2024-08-10T07:13:41.505955Z",
     "shell.execute_reply": "2024-08-10T07:13:41.505176Z",
     "shell.execute_reply.started": "2024-08-10T07:13:41.468651Z"
    }
   },
   "outputs": [],
   "source": [
    "class WavLM_1D(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model1D = WavLM()\n",
    "        self.n_dim = 768\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndim == 3:\n",
    "            x = x[:, 0,:]\n",
    "        feature = self.model1D.pretrain_model(x)[self.model1D.pretrain_feat] # (B, T, 768)\n",
    "        return feature.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cf08127-725c-4827-b57c-6e6d0d8c7d9f",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-08-10T07:13:43.572849Z",
     "iopub.status.busy": "2024-08-10T07:13:43.572317Z",
     "iopub.status.idle": "2024-08-10T07:13:45.448810Z",
     "shell.execute_reply": "2024-08-10T07:13:45.448233Z",
     "shell.execute_reply.started": "2024-08-10T07:13:43.572817Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "style-solution",
     "active-ipynb"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ay/anaconda3/envs/torch/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of the model checkpoint at /usr/local/ay_data/0-model_weights/microsoft_wavlm-base were not used when initializing WavLMModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing WavLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing WavLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of WavLMModel were not initialized from the model checkpoint at /usr/local/ay_data/0-model_weights/microsoft_wavlm-base and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WavLM_1D()\n",
    "x = torch.randn(2, 1, 48000)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d901a049-69ed-4f37-b8d5-b4f448ad551f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T07:13:53.285216Z",
     "iopub.status.busy": "2024-08-10T07:13:53.284600Z",
     "iopub.status.idle": "2024-08-10T07:13:53.515614Z",
     "shell.execute_reply": "2024-08-10T07:13:53.514517Z",
     "shell.execute_reply.started": "2024-08-10T07:13:53.285185Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /usr/local/ay_data/0-model_weights/microsoft_wavlm-base were not used when initializing WavLMModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing WavLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing WavLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of WavLMModel were not initialized from the model checkpoint at /usr/local/ay_data/0-model_weights/microsoft_wavlm-base and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model1D = WavLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b85271c-4956-4425-b9bf-b69ceb620733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T07:17:04.040062Z",
     "iopub.status.busy": "2024-08-10T07:17:04.039762Z",
     "iopub.status.idle": "2024-08-10T07:17:04.346942Z",
     "shell.execute_reply": "2024-08-10T07:17:04.346397Z",
     "shell.execute_reply.started": "2024-08-10T07:17:04.040037Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.randn(2, 48000)\n",
    "feat = model1D.pretrain_model.feature_extractor(x)\n",
    "\n",
    "extract_features = model1D.pretrain_model.feature_extractor(x)\n",
    "extract_features = extract_features.transpose(1, 2)\n",
    "\n",
    "# 输出的extract_features其实就是输入的layer norm\n",
    "hidden_states, extract_features = model1D.pretrain_model.feature_projection(extract_features)\n",
    "\n",
    "encoder_outputs = model1D.pretrain_model.encoder(\n",
    "    hidden_states,\n",
    "    attention_mask=None,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    return_dict=False,\n",
    ")\n",
    "hidden_states = encoder_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cd37c7a-698c-41f2-89b4-60a4b85bb26c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T07:17:07.567188Z",
     "iopub.status.busy": "2024-08-10T07:17:07.566182Z",
     "iopub.status.idle": "2024-08-10T07:17:07.621885Z",
     "shell.execute_reply": "2024-08-10T07:17:07.620585Z",
     "shell.execute_reply.started": "2024-08-10T07:17:07.567094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 149, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8e3c3b1-8d0e-40d9-815a-c882c5a5bfd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T07:39:15.017101Z",
     "iopub.status.busy": "2024-08-10T07:39:15.015749Z",
     "iopub.status.idle": "2024-08-10T07:39:15.097751Z",
     "shell.execute_reply": "2024-08-10T07:39:15.096820Z",
     "shell.execute_reply.started": "2024-08-10T07:39:15.017022Z"
    }
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "949de689-5c4d-4c91-a778-07b6d8e71731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T07:55:08.725238Z",
     "iopub.status.busy": "2024-08-10T07:55:08.724694Z",
     "iopub.status.idle": "2024-08-10T07:55:08.782903Z",
     "shell.execute_reply": "2024-08-10T07:55:08.781674Z",
     "shell.execute_reply.started": "2024-08-10T07:55:08.725196Z"
    }
   },
   "outputs": [],
   "source": [
    "class CrossAttention2D(nn.Module): \n",
    "    def __init__(self, time_dim, spec_dim, feature_dim):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=time_dim, out_channels=feature_dim, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=spec_dim, out_channels=feature_dim, kernel_size=1)\n",
    "        self.feature_dim = feature_dim\n",
    "\n",
    "    def forward(self, waveform, spectrogram):\n",
    "        query = self.conv1(waveform).permute(0,2,3,1) \n",
    "        key = self.conv2(spectrogram).permute(0,2,3,1) \n",
    "        value = spectrogram.permute(0,2,3,1)\n",
    "\n",
    "        attn_weights = self.softmax(torch.matmul(query, key.transpose(-2, -1)) / (self.feature_dim ** 0.5))\n",
    "        out = torch.matmul(attn_weights, value).permute(0,3,1,2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe1b1ddc-7bb9-430f-9642-d36bf6a254dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T07:51:04.493227Z",
     "iopub.status.busy": "2024-08-10T07:51:04.492198Z",
     "iopub.status.idle": "2024-08-10T07:51:04.520896Z",
     "shell.execute_reply": "2024-08-10T07:51:04.519931Z",
     "shell.execute_reply.started": "2024-08-10T07:51:04.493197Z"
    }
   },
   "outputs": [],
   "source": [
    "class Expand(nn.Module):\n",
    "    def __init__(self, time_len = 149, time_dim=768, spec_height=56, spec_width=56, spec_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.time_len = time_len\n",
    "        self.time_dim = time_dim\n",
    "        self.spec_height = spec_height\n",
    "        self.spec_width = spec_width\n",
    "        self.spec_dim = spec_dim\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=time_len, out_channels=spec_height*spec_width, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=time_dim, out_channels=spec_dim, kernel_size=3, padding=1)\n",
    "\n",
    "        self.attn = CrossAttention(time_dim=time_dim, spec_dim=spec_dim, feature_dim=spec_dim)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = self.conv1(x) # [B, spec_H * spec_W, time_dim]\n",
    "        x = rearrange(x, 'b (h w) c -> b c h w', h=self.spec_height, w=self.spec_width) ## [B, time_dim, spec_H, spec_W]\n",
    "        res = self.attn(x, y)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c3d79-e076-4557-8ef8-27db5775a0ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T07:51:13.251055Z",
     "iopub.status.busy": "2024-08-10T07:51:13.250298Z",
     "iopub.status.idle": "2024-08-10T07:51:13.298632Z",
     "shell.execute_reply": "2024-08-10T07:51:13.297966Z",
     "shell.execute_reply.started": "2024-08-10T07:51:13.251027Z"
    }
   },
   "outputs": [],
   "source": [
    "module = Expand()\n",
    "\n",
    "B = 3\n",
    "waveform = torch.rand((B, 149, 768))  # Replace with actual input\n",
    "spectrogram = torch.rand((B, 512, 56, 56))  # Replace with actual input\n",
    "\n",
    "\n",
    "module(waveform, spectrogram).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9731782f-7a3d-4e3f-b0ee-1ca87985e667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T08:00:20.445357Z",
     "iopub.status.busy": "2024-08-10T08:00:20.444897Z",
     "iopub.status.idle": "2024-08-10T08:00:20.478617Z",
     "shell.execute_reply": "2024-08-10T08:00:20.477828Z",
     "shell.execute_reply.started": "2024-08-10T08:00:20.445329Z"
    }
   },
   "outputs": [],
   "source": [
    "class CrossAttention1D(nn.Module): \n",
    "    def __init__(self, time_dim, spec_dim, feature_dim):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        self.linear1 = nn.Linear(time_dim, feature_dim)\n",
    "        self.linear2 = nn.Linear(spec_dim, feature_dim)\n",
    "        self.feature_dim = feature_dim\n",
    "\n",
    "    def forward(self, waveform, spectrogram):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            waveform: (B, time_len, time_dim)\n",
    "            spectrogram: (B, time_len, spec_dim)\n",
    "        \n",
    "        \"\"\"\n",
    "        key = self.linear1(waveform) ##  (B, time_len, feature_dim)\n",
    "        query = self.linear2(spectrogram) ##  (B, time_len, feature_dim)\n",
    "        value = waveform\n",
    "\n",
    "        attn_weights = self.softmax(torch.matmul(query, key.transpose(-2, -1)) / (self.feature_dim ** 0.5))\n",
    "        out = torch.matmul(attn_weights, value) ##  (B, time_len, feature_dim)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1700f7b5-ba46-4fd5-95c6-2dfd3f122f9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T08:00:21.103205Z",
     "iopub.status.busy": "2024-08-10T08:00:21.102747Z",
     "iopub.status.idle": "2024-08-10T08:00:21.130939Z",
     "shell.execute_reply": "2024-08-10T08:00:21.130140Z",
     "shell.execute_reply.started": "2024-08-10T08:00:21.103176Z"
    }
   },
   "outputs": [],
   "source": [
    "class Squeeze(nn.Module):\n",
    "    def __init__(self, time_len = 149, time_dim=768, spec_height=56, spec_width=56, spec_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.time_len = time_len\n",
    "        self.time_dim = time_dim\n",
    "        self.spec_height = spec_height\n",
    "        self.spec_width = spec_width\n",
    "        self.spec_dim = spec_dim\n",
    "\n",
    "        ### used to convert spec into waveform\n",
    "        self.linear = nn.Linear(spec_height*spec_width, time_len)\n",
    "\n",
    "        self.attn = CrossAttention1D(time_dim=time_dim, spec_dim=spec_dim, feature_dim=spec_dim)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "\n",
    "        y = rearrange(y, 'b c h w -> b c (h w)')\n",
    "        y = self.linear(y) ### # [B, time_len, spec_dim]\n",
    "        y = rearrange(y, 'b c l -> b l c')\n",
    "        res = self.attn(x, y)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d95e8a60-e151-4f4e-b4ea-55eac59e500b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T08:00:21.808265Z",
     "iopub.status.busy": "2024-08-10T08:00:21.807787Z",
     "iopub.status.idle": "2024-08-10T08:00:22.028548Z",
     "shell.execute_reply": "2024-08-10T08:00:22.027892Z",
     "shell.execute_reply.started": "2024-08-10T08:00:21.808236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 149, 768])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = Squeeze()\n",
    "\n",
    "B = 3\n",
    "waveform = torch.rand((B, 149, 768))  # Replace with actual input\n",
    "spectrogram = torch.rand((B, 512, 56, 56))  # Replace with actual input\n",
    "\n",
    "\n",
    "module(waveform, spectrogram).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
