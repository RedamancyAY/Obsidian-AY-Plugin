{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d911c9f0",
   "metadata": {},
   "source": [
    "# Grad-CAM Heatmap to Spectrogram Conversion for Waveform-Input Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b9d4e0",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55997d56",
   "metadata": {},
   "source": [
    "This notebook was created by [Jupyter AI](https://github.com/jupyterlab/jupyter-ai) with the following prompt:\n",
    "\n",
    "> /generate how to use gard-cam technique to generate heatmap for a waveform-input model, and then convert the heatmap  of waveform into spectrogram using torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539bc4c0",
   "metadata": {},
   "source": [
    "Here is a markdown summary of the Jupyter notebook in a single paragraph:\n",
    "\n",
    "This notebook demonstrates how to apply the Grad-CAM technique to generate a heatmap for a waveform-input model, and subsequently convert the heatmap of the waveform into a spectrogram using Torch. The notebook guides through the process of installing necessary libraries, importing required libraries and loading a dataset of waveforms, defining a PyTorch model that takes waveforms as input, applying Grad-CAM to generate a heatmap, converting the heatmap into a spectrogram with Torch, and finally visualizing the resulting spectrogram using a library like matplotlib or seaborn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1524980",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c46783",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here's the improved version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d397ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T08:24:49.455800Z",
     "iopub.status.busy": "2024-11-18T08:24:49.455329Z",
     "iopub.status.idle": "2024-11-18T08:24:49.463298Z",
     "shell.execute_reply": "2024-11-18T08:24:49.461516Z",
     "shell.execute_reply.started": "2024-11-18T08:24:49.455769Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np  # for numerical computations\n",
    "import matplotlib.pyplot as plt  # for plotting (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd31b115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T08:24:50.205790Z",
     "iopub.status.busy": "2024-11-18T08:24:50.205178Z",
     "iopub.status.idle": "2024-11-18T08:24:50.225395Z",
     "shell.execute_reply": "2024-11-18T08:24:50.223363Z",
     "shell.execute_reply.started": "2024-11-18T08:24:50.205730Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b063dc9f",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-11-18T08:25:24.686669Z",
     "iopub.status.busy": "2024-11-18T08:25:24.685994Z",
     "iopub.status.idle": "2024-11-18T08:25:24.697125Z",
     "shell.execute_reply": "2024-11-18T08:25:24.695083Z",
     "shell.execute_reply.started": "2024-11-18T08:25:24.686594Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ay2.torch.data.audio import WaveDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "194551ec-358d-409b-8d82-0478a2119e5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T08:26:29.331085Z",
     "iopub.status.busy": "2024-11-18T08:26:29.330375Z",
     "iopub.status.idle": "2024-11-18T08:26:29.340203Z",
     "shell.execute_reply": "2024-11-18T08:26:29.338086Z",
     "shell.execute_reply.started": "2024-11-18T08:26:29.331022Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ay/Coding2/0-Deepfake/2-Audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf1bda4-2b9b-47df-a04e-9cbdb5e152be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T08:27:02.091917Z",
     "iopub.status.busy": "2024-11-18T08:27:02.091272Z",
     "iopub.status.idle": "2024-11-18T08:27:02.100830Z",
     "shell.execute_reply": "2024-11-18T08:27:02.099013Z",
     "shell.execute_reply.started": "2024-11-18T08:27:02.091837Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.Aaasist import AASIST_lit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8d6ded",
   "metadata": {},
   "source": [
    "## Define Waveform-Input Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cbe4435-6a7e-4331-b367-80dba6f2c953",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T08:29:09.049763Z",
     "iopub.status.busy": "2024-11-18T08:29:09.049140Z",
     "iopub.status.idle": "2024-11-18T08:29:09.405751Z",
     "shell.execute_reply": "2024-11-18T08:29:09.404216Z",
     "shell.execute_reply.started": "2024-11-18T08:29:09.049699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. model params:297705\n"
     ]
    }
   ],
   "source": [
    "model = AASIST_lit(ckpt_path=\"/home/ay/data/DATA/1-model_save/00-Deepfake/1-df-audio/AASIST/Codecfake/version_0/checkpoints/best-epoch=1-val-auc=0.9999.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecfcf260-a35f-4c2b-bbc6-0e60ada4c065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T08:29:43.926508Z",
     "iopub.status.busy": "2024-11-18T08:29:43.926176Z",
     "iopub.status.idle": "2024-11-18T08:29:44.475826Z",
     "shell.execute_reply": "2024-11-18T08:29:44.474361Z",
     "shell.execute_reply.started": "2024-11-18T08:29:43.926482Z"
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [AASIST_lit] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m48000\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/pytorch_lightning/core/module.py:704\u001b[0m, in \u001b[0;36mLightningModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    694\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Same as :meth:`torch.nn.Module.forward`.\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \n\u001b[1;32m    696\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    702\u001b[0m \n\u001b[1;32m    703\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:372\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] is missing the required \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m function\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Module [AASIST_lit] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 1, 48000)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efe1ff6",
   "metadata": {},
   "source": [
    "## Apply Grad-CAM Technique to Generate Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e5cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pytorch_grad_cam import GradCAM\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70081f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_grad_cam(model, waveform_data):\n",
    "    \"\"\"\n",
    "    Applies Grad-CAM technique to generate a heatmap for each input tensor in the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00b4db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    Args:\n",
    "        model (nn.Module): The PyTorch model to use.\n",
    "        waveform_data (TensorDataset or list of tensors): The waveform data to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b682f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    Returns:\n",
    "        heatmaps (list of numpy arrays): A list of heatmaps, one for each input tensor.\n",
    "    \"\"\"\n",
    "    # Define the Grad-CAM class and initialize it with our model\n",
    "    grad_cam = GradCAM(model=model, target_layers=[model.conv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d6eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create a data loader for the waveform data\n",
    "    data_loader = DataLoader(waveform_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5cb9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Apply Grad-CAM technique to generate heatmap\n",
    "    heatmaps = []\n",
    "    with torch.no_grad():\n",
    "        for i, (input_tensor,) in enumerate(data_loader):\n",
    "            # Compute the output of our model on the input tensor\n",
    "            output = model(input_tensor)\n",
    "            \n",
    "            # Get the predicted class index and its corresponding probability\n",
    "            _, pred_idx = torch.max(output, dim=1)\n",
    "            pred_prob = torch.nn.functional.softmax(output, dim=1)[:, pred_idx]\n",
    "            \n",
    "            # Compute the heatmap using Grad-CAM technique\n",
    "            heatmap = grad_cam(input_tensor=input_tensor, target=pred_idx)\n",
    "            \n",
    "            # Append the computed heatmap to our list\n",
    "            heatmaps.append(heatmap.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbe6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "    return heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "model = our_model  # Replace with your actual model\n",
    "waveform_data = ...  # Replace with your actual waveform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d797cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps = apply_grad_cam(model, waveform_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6db236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the generated heatmap (optional)\n",
    "plt.imshow(heatmaps[0].squeeze(), cmap='hot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c413a1",
   "metadata": {},
   "source": [
    "## Convert Waveform Heatmap into Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba2b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here's an improved version of your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Waveform Heatmap into Spectrogram\n",
    "# ======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbaa826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044df75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_to_spectrogram(heatmap: torch.Tensor,\n",
    "                         n_fft: int = 2048,\n",
    "                         hop_length: int = 512,\n",
    "                         win_length: int = 2048) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a waveform heatmap into a spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f18766",
   "metadata": {},
   "outputs": [],
   "source": [
    "    Args:\n",
    "        heatmap (torch.tensor): Heatmap of shape [1, timesteps]\n",
    "        n_fft (int, optional): Size of FFT window. Defaults to 2048.\n",
    "        hop_length (int, optional): Hop length between successive frames. Defaults to 512.\n",
    "        win_length (int, optional): Window size. Defaults to 2048."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2b5595",
   "metadata": {},
   "outputs": [],
   "source": [
    "    Returns:\n",
    "        spectrogram (torch.tensor): Spectrogram of shape [1, freq_bins, time_steps]\n",
    "    \"\"\"\n",
    "    # Pad the heatmap to ensure it can be divided evenly by hop_length\n",
    "    padded_heatmap = torch.nn.functional.pad(heatmap, (0, -heatmap.shape[-1] % hop_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Compute Short-Time Fourier Transform (STFT)\n",
    "    window = torch.hamming_window(win_length).to(padded_heatmap.device)\n",
    "    stft = torch.stft(padded_heatmap.squeeze(), n_fft=n_fft, hop_length=hop_length,\n",
    "                     win_length=win_length, window=window, onesided=True,\n",
    "                     pad_mode='constant', normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf4d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Get the magnitude of the complex-valued STFT\n",
    "    spectrogram = stft.abs().unsqueeze(0)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf363f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load or generate the heatmap\n",
    "heatmap: torch.Tensor = ...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8fe9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the heatmap to spectrogram\n",
    "spectrogram = heatmap_to_spectrogram(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb7fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spectrogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c113c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Note that I have used type hints for function arguments and returns. The `heatmap` is expected to be of type `torch.Tensor`. The `n_fft`, `hop_length` and `win_length` are optional parameters with default values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856168f8",
   "metadata": {},
   "source": [
    "## Visualize the Resulting Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdbbdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np  # Ensure numpy is imported for array operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaca89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_spectrogram(spectrogram, cmap='inferno'):\n",
    "    \"\"\"\n",
    "    Visualize the resulting spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97425778",
   "metadata": {},
   "outputs": [],
   "source": [
    "    Parameters:\n",
    "    - spectrogram (2D numpy array): The spectrogram data to be visualized.\n",
    "    - cmap (str or matplotlib colormap, optional): Colormap to use for visualization. Defaults to 'inferno'.\n",
    "    \"\"\"\n",
    "    # Create a figure with a single subplot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Use seaborn's heatmap function to create the spectrogram visualization\n",
    "    sns.heatmap(spectrogram, cmap=cmap, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3bbc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Set title and labels for the plot\n",
    "    ax.set_title('Resulting Spectrogram')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d6fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Display the plot\n",
    "    plt.tight_layout()  # Ensure plot fits within figure area\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b8ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "spectrogram_data = np.random.rand(256, 512)  # Replace with actual spectrogram data\n",
    "visualize_spectrogram(spectrogram_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
