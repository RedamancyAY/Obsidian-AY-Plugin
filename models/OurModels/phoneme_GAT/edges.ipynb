{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "99bb1a3d-c6c0-463d-bba5-e00606c64e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:53:15.352314Z",
     "iopub.status.busy": "2024-07-27T04:53:15.351647Z",
     "iopub.status.idle": "2024-07-27T04:53:15.361169Z",
     "shell.execute_reply": "2024-07-27T04:53:15.358990Z",
     "shell.execute_reply.started": "2024-07-27T04:53:15.352254Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2d7d5e-a866-4460-a24e-18ae6ee81dbf",
   "metadata": {},
   "source": [
    "# reduce and combine hidden states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce78abf5-f672-4be0-9ecd-149ac4079662",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "在音素识别时，一个音素可能会跨多个时间帧，因此需要合并连续且相同的音素，构造为一个音素，从而预测整句话的音素，并与ground truth进行比较。\n",
    ":::\n",
    "\n",
    "那使用音素特征识别时，那么也许合并连续且相同的音素特征帧。设音素特征为`(B, T, 768)`，那么合并后的特征为`(B, T', 768)`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c32c3278-4d3b-4a86-a04a-7a08169f81a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T03:34:54.986240Z",
     "iopub.status.busy": "2024-07-27T03:34:54.985838Z",
     "iopub.status.idle": "2024-07-27T03:34:54.996912Z",
     "shell.execute_reply": "2024-07-27T03:34:54.994832Z",
     "shell.execute_reply.started": "2024-07-27T03:34:54.986205Z"
    }
   },
   "outputs": [],
   "source": [
    "def segment_means(tensor, segment_sizes):\n",
    "    assert tensor.size(0) == segment_sizes.sum(), \"Sum of segment sizes must equal the tensor's first dimension size.\"\n",
    "\n",
    "    # Create an indices tensor that maps each row in the tensor to its corresponding segment\n",
    "    indices = torch.repeat_interleave(torch.arange(len(segment_sizes), device=tensor.device), segment_sizes)\n",
    "\n",
    "    # Create a tensor to hold the sum of each segment\n",
    "    segment_sums = torch.zeros(len(segment_sizes), tensor.size(1), device=tensor.device)\n",
    "\n",
    "    # Scatter and sum the inputs into the segment_sums tensor\n",
    "    segment_sums.scatter_add_(0, indices.unsqueeze(1).expand(-1, tensor.size(1)), tensor)\n",
    "\n",
    "    # Calculate the mean of each segment\n",
    "    segment_means = segment_sums / segment_sizes.unsqueeze(1)\n",
    "\n",
    "    return segment_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "93ae7dad-9003-4452-a0a2-64e36fe1b75c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T03:46:26.169560Z",
     "iopub.status.busy": "2024-07-27T03:46:26.168910Z",
     "iopub.status.idle": "2024-07-27T03:46:26.186444Z",
     "shell.execute_reply": "2024-07-27T03:46:26.185051Z",
     "shell.execute_reply.started": "2024-07-27T03:46:26.169500Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reduce_feat(hidden_states, audio_lengths, phoneme_ids):\n",
    "    reduced_hidden_states = []\n",
    "    reduced_audio_lengths = []\n",
    "    reduced_phoneme_ids = []\n",
    "\n",
    "    phoneme_counts = []\n",
    "    print(hidden_states.shape, audio_lengths.shape, phoneme_ids.shape)\n",
    "\n",
    "    for i in range(len(audio_lengths)):\n",
    "        _phoneme_ids = phoneme_ids[i, : audio_lengths[i]]\n",
    "        _h = hidden_states[i, : audio_lengths[i]]\n",
    "\n",
    "        unique_ids, _phoneme_counts = _phoneme_ids.unique_consecutive(return_counts=True)\n",
    "        # segments = torch.split(_h, _phoneme_counts.tolist())\n",
    "        # _h_reduced = torch.stack([seg.mean(dim=0) for seg in segments])\n",
    "        phoneme_counts += _phoneme_counts.tolist()\n",
    "\n",
    "        reduced_audio_lengths.append(len(unique_ids))\n",
    "        reduced_phoneme_ids.append(unique_ids)\n",
    "\n",
    "    reduced_audio_lengths = torch.tensor(reduced_audio_lengths)\n",
    "    reduced_phoneme_ids = torch.nn.utils.rnn.pad_sequence(reduced_phoneme_ids, batch_first=True)\n",
    "    h = torch.concat([hidden_states[i, :_len, :] for i, _len in enumerate(audio_lengths)], dim=0)\n",
    "    reduced_hidden_states = segment_means(h, torch.tensor(phoneme_counts, device=hidden_states.device))\n",
    "\n",
    "    print(reduced_audio_lengths.shape, reduced_phoneme_ids.shape, reduced_hidden_states.shape)\n",
    "    \n",
    "    return reduced_hidden_states, reduced_audio_lengths, reduced_phoneme_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "085c3912-c58a-4bb9-aed1-79077dc0ec78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T03:52:33.868129Z",
     "iopub.status.busy": "2024-07-27T03:52:33.867501Z",
     "iopub.status.idle": "2024-07-27T03:52:33.968997Z",
     "shell.execute_reply": "2024-07-27T03:52:33.967272Z",
     "shell.execute_reply.started": "2024-07-27T03:52:33.868069Z"
    }
   },
   "outputs": [],
   "source": [
    "B = 64\n",
    "T = 149\n",
    "hidden_states = torch.randn(B, T, 768).cuda().requires_grad_(True)\n",
    "phoneme_ids = torch.randint(0, 2, (B, T)).cuda()\n",
    "audio_lengths = torch.randint(140, 149, (B,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "28d896f4-2c8f-4706-b1e4-e9893886fb73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T03:52:35.114892Z",
     "iopub.status.busy": "2024-07-27T03:52:35.114464Z",
     "iopub.status.idle": "2024-07-27T03:52:35.150067Z",
     "shell.execute_reply": "2024-07-27T03:52:35.148049Z",
     "shell.execute_reply.started": "2024-07-27T03:52:35.114854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 149, 768]) torch.Size([64]) torch.Size([64, 149])\n",
      "torch.Size([64]) torch.Size([64, 88]) torch.Size([4694, 768])\n",
      "torch.Size([64]) torch.Size([64, 88]) torch.Size([4694, 768])\n"
     ]
    }
   ],
   "source": [
    "reduced_hidden_states, reduced_audio_lengths, reduced_phoneme_ids = reduce_feat(\n",
    "    hidden_states, audio_lengths, phoneme_ids\n",
    ")\n",
    "print(reduced_audio_lengths.shape, reduced_phoneme_ids.shape, reduced_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833a009d-0d56-4b28-8ae3-3c28a7a94a18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T11:36:20.325882Z",
     "iopub.status.busy": "2024-07-23T11:36:20.325205Z",
     "iopub.status.idle": "2024-07-23T11:36:20.334401Z",
     "shell.execute_reply": "2024-07-23T11:36:20.332216Z",
     "shell.execute_reply.started": "2024-07-23T11:36:20.325819Z"
    }
   },
   "source": [
    "# Generate edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf5dd05-a19e-48ae-938a-619be09a7239",
   "metadata": {},
   "source": [
    "设，一个audio的所有帧（T）对应的phoneme ids是，并给出了audio长度为10：\n",
    "```python　\n",
    "predict_ids = torch.tensor([0, 0, 1, 1, 1, 2, 2, 2, 2, 2])\n",
    "audio_lengths = [10]\n",
    "```\n",
    "\n",
    "那么，建立单项边时，有两个操作：\n",
    "1. 添加所有邻接边：`0->1, 1->2, 2->3, ...`\n",
    "2. 对于一个phoneme，对接下来的N个phoneme都建立边：\n",
    "    - 以第1个node为例（index从0开始），设N=1，那么会新加边：`1->2, 1->3, 1->4`\n",
    "    - 以第3个node为例（index从0开始），设N=1，那么会新加边：`3->5,6,7,8,9`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c490b5ac-a837-4a1c-aca1-0ab408199a1f",
   "metadata": {},
   "source": [
    "### Step 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1342c8-cc43-417b-9a73-578d842c118e",
   "metadata": {},
   "source": [
    "使用arange可以很快地生成所有邻接边。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "83575882-db6c-454f-9466-594de8faa5b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:53:05.210617Z",
     "iopub.status.busy": "2024-07-27T04:53:05.209995Z",
     "iopub.status.idle": "2024-07-27T04:53:05.221423Z",
     "shell.execute_reply": "2024-07-27T04:53:05.219458Z",
     "shell.execute_reply.started": "2024-07-27T04:53:05.210558Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_adj_edges(L: int, use_np=False):\n",
    "    if use_np:\n",
    "        adj_edges = np.stack([np.arange(L - 1), np.arange(1, L)])\n",
    "    else:\n",
    "        adj_edges = torch.stack([torch.arange(L - 1), torch.arange(1, L)])\n",
    "    return adj_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4058df34-0a7c-4a2a-b8a2-f96295fa042f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:54:03.600355Z",
     "iopub.status.busy": "2024-07-27T04:54:03.599720Z",
     "iopub.status.idle": "2024-07-27T04:54:03.616921Z",
     "shell.execute_reply": "2024-07-27T04:54:03.614895Z",
     "shell.execute_reply.started": "2024-07-27T04:54:03.600294Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "         140, 141, 142, 143, 144, 145, 146, 147],\n",
      "        [  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "          15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "          29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "          43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "          57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "          71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "          85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "          99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "         113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "         127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "         141, 142, 143, 144, 145, 146, 147, 148]]) [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "L = 149\n",
    "adj_edges = get_adj_edges(L, use_np=0)\n",
    "adj_edges_np = get_adj_edges(L, use_np=1)\n",
    "print(adj_edges, adj_edges.numpy()-adj_edges_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed5a11a-beaa-44ad-8be5-8a9fae27ef69",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48661dca-4f72-4ce7-9c20-3b8da136956d",
   "metadata": {},
   "source": [
    "使用 `unique_consecutive`可以快速地查找所有不同的phoneme id，并定位其index范围。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d464ea60-29d3-4646-834e-143190a4f48d",
   "metadata": {},
   "source": [
    "### 遍历　"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e70d06e-d8f0-42b7-9421-b9455c9dfe9e",
   "metadata": {},
   "source": [
    "下面这种遍历长度L的方法，耗时太长了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdc396c-5e11-4a99-9329-4d7e0c49fd3e",
   "metadata": {},
   "source": [
    "#### torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d73bc5f9-6c33-4f39-8bee-dfc8dfd60f98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T05:04:37.715538Z",
     "iopub.status.busy": "2024-07-27T05:04:37.714913Z",
     "iopub.status.idle": "2024-07-27T05:04:37.757276Z",
     "shell.execute_reply": "2024-07-27T05:04:37.755289Z",
     "shell.execute_reply.started": "2024-07-27T05:04:37.715479Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict_ids = torch.tensor([0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3])\n",
    "predict_ids = torch.randint(0, 3, (149,))\n",
    "\n",
    "N = 10\n",
    "\n",
    "output, inverse, counts = predict_ids.unique_consecutive(return_inverse=True, return_counts=True)\n",
    "cumsum_counts = torch.cumsum(counts, 0)\n",
    "# output, inverse, conuts, cumsum_counts\n",
    "\n",
    "edges = []\n",
    "for i in range(L):\n",
    "    unique_id = inverse[i]  # 0, 1, 2, 3,\n",
    "    unique_id_end_index = cumsum_counts[unique_id]\n",
    "    if unique_id == len(output) - 1:\n",
    "        break\n",
    "    next_id = min(len(output) - 1, unique_id + N)\n",
    "    next_end_index = cumsum_counts[next_id]\n",
    "    _edges = torch.stack(\n",
    "        [torch.full((next_end_index - unique_id_end_index,), i), torch.arange(unique_id_end_index, next_end_index)]\n",
    "    )\n",
    "    edges.append(_edges)\n",
    "edges = torch.concat(edges, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1c47d5dc-3483-44f9-8449-7b0f1c4da414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:54:31.087485Z",
     "iopub.status.busy": "2024-07-27T04:54:31.086807Z",
     "iopub.status.idle": "2024-07-27T04:54:31.100159Z",
     "shell.execute_reply": "2024-07-27T04:54:31.098144Z",
     "shell.execute_reply.started": "2024-07-27T04:54:31.087423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,\n",
       "          4,  4,  4,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,  9,  9],\n",
       "        [ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11,  2,  3,  4,  5,  6,  7,  8,  9,\n",
       "         10, 11,  5,  6,  7,  8,  9, 10, 11,  5,  6,  7,  8,  9, 10, 11,  5,  6,\n",
       "          7,  8,  9, 10, 11, 10, 11, 10, 11, 10, 11, 10, 11, 10, 11]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eadc840-58c5-4193-8aa3-56dd0190c2ba",
   "metadata": {},
   "source": [
    "#### numpy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f83fab-9ae1-473b-b1a3-209619a1f360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T05:01:22.043568Z",
     "iopub.status.busy": "2024-07-27T05:01:22.042857Z",
     "iopub.status.idle": "2024-07-27T05:01:22.055771Z",
     "shell.execute_reply": "2024-07-27T05:01:22.053283Z",
     "shell.execute_reply.started": "2024-07-27T05:01:22.043505Z"
    }
   },
   "source": [
    "首先，由于numpy中没有unique_consecutive这个函数，因此需要先实现他。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "29bb9221-1cd8-46a5-947f-f416ab079b63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T05:00:52.740479Z",
     "iopub.status.busy": "2024-07-27T05:00:52.739821Z",
     "iopub.status.idle": "2024-07-27T05:00:52.757118Z",
     "shell.execute_reply": "2024-07-27T05:00:52.755130Z",
     "shell.execute_reply.started": "2024-07-27T05:00:52.740416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]),\n",
       " tensor([0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3]),\n",
       " tensor([2, 3, 5, 2]))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ids = torch.tensor([0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3])\n",
    "output, inverse, counts = predict_ids.unique_consecutive(return_inverse=True, return_counts=True)\n",
    "output, inverse, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664f14dd-9e72-4b02-8966-22a3fc70e31f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T05:00:38.453612Z",
     "iopub.status.busy": "2024-07-27T05:00:38.453010Z",
     "iopub.status.idle": "2024-07-27T05:00:38.472297Z",
     "shell.execute_reply": "2024-07-27T05:00:38.470279Z",
     "shell.execute_reply.started": "2024-07-27T05:00:38.453553Z"
    }
   },
   "outputs": [],
   "source": [
    "def unique_consecutive(x: np.ndarray):\n",
    "\n",
    "    output = [x[0]]\n",
    "    inverse = np.zeros_like(x)\n",
    "    counts = [1]\n",
    "\n",
    "    for i in range(1, len(x)):\n",
    "        if x[i] == output[-1]:\n",
    "            counts[-1] += 1\n",
    "        else:\n",
    "            output.append(x[i])\n",
    "            counts.append(1)\n",
    "        inverse[i] = len(output) -1\n",
    "    return np.array(output), inverse, np.array(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951e54f-5bdc-47ed-978d-4006249871ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T05:00:38.453612Z",
     "iopub.status.busy": "2024-07-27T05:00:38.453010Z",
     "iopub.status.idle": "2024-07-27T05:00:38.472297Z",
     "shell.execute_reply": "2024-07-27T05:00:38.470279Z",
     "shell.execute_reply.started": "2024-07-27T05:00:38.453553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]),\n",
       " array([0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3]),\n",
       " array([2, 3, 5, 2]))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 可以看到，和tensor版本的输出结果是一样的\n",
    "unique_consecutive(predict_ids.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f52279cf-c949-40ca-9420-2d493d5711b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T05:12:00.239825Z",
     "iopub.status.busy": "2024-07-27T05:12:00.239554Z",
     "iopub.status.idle": "2024-07-27T05:12:00.393457Z",
     "shell.execute_reply": "2024-07-27T05:12:00.391792Z",
     "shell.execute_reply.started": "2024-07-27T05:12:00.239803Z"
    }
   },
   "outputs": [],
   "source": [
    "L = 149 * 64\n",
    "predict_ids = torch.randint(0, 3, (L,)).numpy()\n",
    "N = 10\n",
    "\n",
    "output, inverse, counts = unique_consecutive(predict_ids)\n",
    "cumsum_counts = np.cumsum(counts, 0)\n",
    "# output, inverse, conuts, cumsum_counts\n",
    "\n",
    "edges = []\n",
    "for i in range(L):\n",
    "    unique_id = inverse[i]  # 0, 1, 2, 3,\n",
    "    unique_id_end_index = cumsum_counts[unique_id]\n",
    "    if unique_id == len(output) - 1:\n",
    "        break\n",
    "    next_id = min(len(output) - 1, unique_id + N)\n",
    "    next_end_index = cumsum_counts[next_id]\n",
    "    _edges = np.stack(\n",
    "        [np.full((next_end_index - unique_id_end_index,), i), np.arange(unique_id_end_index, next_end_index)]\n",
    "    )\n",
    "    edges.append(_edges)\n",
    "edges = np.concatenate(edges, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14089ec-5794-4aec-8f78-7ddac8025fed",
   "metadata": {},
   "source": [
    "### tensor方法　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f2abf8e0-070d-467b-937f-351e1862a088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T03:19:10.790170Z",
     "iopub.status.busy": "2024-07-27T03:19:10.789520Z",
     "iopub.status.idle": "2024-07-27T03:19:10.805164Z",
     "shell.execute_reply": "2024-07-27T03:19:10.802849Z",
     "shell.execute_reply.started": "2024-07-27T03:19:10.790109Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_multple_sequences(ns, as_, bs):\n",
    "    \"\"\"\n",
    "    quickly generate n1 sequences that ranging from a1 to b1,\n",
    "            generate n2 sequences that ranging from a2 to b2,\n",
    "            generate n3 sequences that ranging from a3 to b3,\n",
    "            ....\n",
    "    and finally combine these sequences\n",
    "\n",
    "\n",
    "    ```python\n",
    "    ns = torch.tensor([5, 3, 4])\n",
    "    as_ = torch.tensor([1, 11, 16])\n",
    "    bs = torch.tensor([10, 15, 20])\n",
    "    ```\n",
    "    > tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9,\n",
    "               1,  2,  3,  4,  5,  6,  7,  8,  9,\n",
    "               1,  2,  3,  4,  5,  6,  7,  8,  9,\n",
    "               1,  2,  3,  4,  5,  6,  7,  8,  9,\n",
    "               1,  2,  3,  4,  5,  6,  7,  8,  9,\n",
    "               11, 12, 13, 14,\n",
    "               11, 12, 13, 14,\n",
    "               11, 12, 13, 14,\n",
    "               16, 17, 18, 19,\n",
    "               16, 17, 18, 19,\n",
    "               16, 17, 18, 19,\n",
    "               16, 17, 18, 19])\n",
    "    Args:\n",
    "        ns: the repeat number of sequences\n",
    "        as_: the start number for each seq\n",
    "        bs: the end number for each seq\n",
    "\n",
    "    Returns:\n",
    "        tensor: a 1D tensor for the combined seq.\n",
    "    \"\"\"\n",
    "    # print(ns, as_, bs)\n",
    "    device = ns.device\n",
    "    # The maximum value in bs determines the tensor width for uniformity\n",
    "    max_length = torch.max(bs - as_ + 1)\n",
    "    # Generate a tensor where each row is a sequence from 0 to max_length\n",
    "    seq_tensor = torch.arange(max_length).unsqueeze(0).repeat(ns.sum(), 1).to(device)\n",
    "    seq_tensor = torch.repeat_interleave(as_, ns)[:, None] + seq_tensor\n",
    "    nums = torch.repeat_interleave(bs - as_, ns)\n",
    "    mask = torch.arange(seq_tensor.size(1)).expand_as(seq_tensor).to(device) < nums.unsqueeze(1)\n",
    "\n",
    "    return seq_tensor[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0af85f12-c64e-4189-b48e-6a0efb3d3ac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T03:19:07.748942Z",
     "iopub.status.busy": "2024-07-27T03:19:07.748522Z",
     "iopub.status.idle": "2024-07-27T03:19:07.762950Z",
     "shell.execute_reply": "2024-07-27T03:19:07.760805Z",
     "shell.execute_reply.started": "2024-07-27T03:19:07.748906Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_phoneme_edges2(predict_ids: torch.Tensor, N=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        predict_ids: a tensor with shape of (L,) that represents the phoneme id for each audio frame.\n",
    "        N: the number of looking forward phonemes\n",
    "    Returns:\n",
    "        torch.Tensor: the edges with shape of (2, n_edges)\n",
    "    \"\"\"\n",
    "\n",
    "    device = predict_ids.device\n",
    "    \n",
    "    output, inverse, counts = predict_ids.unique_consecutive(return_inverse=True, return_counts=True)\n",
    "    cumsum_counts = torch.cumsum(counts, 0).to(device)\n",
    "    # print(output, inverse, counts, cumsum_counts)\n",
    "    if len(output) == 1:\n",
    "        return torch.zeros((2, 0))\n",
    "    # both start and end are length L\n",
    "    start_indices = torch.cat([torch.tensor([0], device=device), cumsum_counts[:-1]])\n",
    "    end_indices = cumsum_counts\n",
    "    # print(\"start\", start_indices, \"end\", end_indices)\n",
    "\n",
    "    edge_start_indices = start_indices[1:]\n",
    "    edge_end_indices = end_indices[torch.clamp(torch.arange(len(output) - 1) + N, max=len(end_indices) - 1)]\n",
    "    # print(edge_start_indices, edge_end_indices)\n",
    "\n",
    "    # print(edge_end_indices.device)\n",
    "    x = torch.repeat_interleave(\n",
    "        torch.arange(cumsum_counts[-2]).to(device), (edge_end_indices - edge_start_indices)[inverse[: cumsum_counts[-2]]], dim=0\n",
    "    ).to(device)\n",
    "    y = generate_multple_sequences(ns=counts[:-1], as_=edge_start_indices, bs=edge_end_indices).to(device)\n",
    "    edges = torch.stack([x, y])\n",
    "    # print(x.shape, y.shape, edges.shape)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b1f0a2-87a0-4f32-8e15-e1526dbc96e5",
   "metadata": {},
   "source": [
    "使用一个短的ids进行验证，和上面的遍历方法产生的结果是一样的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e776992-4dd6-44f0-a2da-64203a5aec52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T03:16:09.964579Z",
     "iopub.status.busy": "2024-07-27T03:16:09.963947Z",
     "iopub.status.idle": "2024-07-27T03:16:09.984098Z",
     "shell.execute_reply": "2024-07-27T03:16:09.981958Z",
     "shell.execute_reply.started": "2024-07-27T03:16:09.964520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  1,  1,  1,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  4,  4,\n",
       "          4,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,  9,  9],\n",
       "        [ 2,  3,  4,  2,  3,  4,  5,  6,  7,  8,  9,  5,  6,  7,  8,  9,  5,  6,\n",
       "          7,  8,  9, 10, 11, 10, 11, 10, 11, 10, 11, 10, 11]], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ids = torch.tensor([0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3]).cuda()\n",
    "get_phoneme_edges2(predict_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad7c5c0-bbe3-4ab3-a763-4481496fb0f7",
   "metadata": {},
   "source": [
    "#### numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb49ceee-f091-4f0e-bbca-567474dddf5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "379e26f2-dfdc-417e-8781-c097c9b170f9",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f13d3b9-f8ab-439e-9ff2-7e7e1759d5d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T03:19:13.424684Z",
     "iopub.status.busy": "2024-07-27T03:19:13.424073Z",
     "iopub.status.idle": "2024-07-27T03:19:13.440577Z",
     "shell.execute_reply": "2024-07-27T03:19:13.438502Z",
     "shell.execute_reply.started": "2024-07-27T03:19:13.424624Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_edges(input_audio_lengths: torch.Tensor, input_phoneme_ids: torch.Tensor, N=2):\n",
    "    start_id = 0\n",
    "    edge_index = []\n",
    "\n",
    "    # audio_lengths = input_audio_lengths.cpu()\n",
    "    audio_lengths = input_audio_lengths\n",
    "    # phoneme_ids = input_phoneme_ids.cpu()\n",
    "    phoneme_ids = input_phoneme_ids\n",
    "\n",
    "    cumsum_audio_lengths = torch.cumsum(audio_lengths, 0)\n",
    "\n",
    "    device = audio_lengths.device\n",
    "    \n",
    "    total_edges = []\n",
    "    for i in range(len(audio_lengths)):\n",
    "        _audio_len = audio_lengths[i]\n",
    "        _phoneme_ids = phoneme_ids[i, :_audio_len]\n",
    "        _start_index = cumsum_audio_lengths[i - 1] if i > 0 else 0\n",
    "\n",
    "        adj_edges = get_adj_edges(_audio_len).to(device)\n",
    "        phoneme_edges = get_phoneme_edges2(_phoneme_ids, N=N).to(device)\n",
    "        _edges = torch.concat([adj_edges, phoneme_edges], dim=1) + _start_index\n",
    "        total_edges.append(_edges)\n",
    "    total_edges = torch.concat(total_edges, dim=1)\n",
    "    total_edges = torch.unique(total_edges, dim=1)\n",
    "    return total_edges.type(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "f05a8757-c1f1-45c7-820e-f9d034618587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T06:30:08.657471Z",
     "iopub.status.busy": "2024-07-27T06:30:08.657175Z",
     "iopub.status.idle": "2024-07-27T06:30:08.669979Z",
     "shell.execute_reply": "2024-07-27T06:30:08.667866Z",
     "shell.execute_reply.started": "2024-07-27T06:30:08.657446Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_edges_by_combine_and_split(input_audio_lengths: torch.Tensor, input_phoneme_ids: torch.Tensor, N=2):\n",
    "    edge_index = []\n",
    "\n",
    "    audio_lengths = input_audio_lengths\n",
    "    padding = torch.arange(1, N+1, dtype=input_phoneme_ids.dtype, device=input_phoneme_ids.device) * -1\n",
    "    phoneme_ids = torch.concat([torch.concat([input_phoneme_ids[i, :_audio_len], padding]) for i, _audio_len in enumerate(audio_lengths)])\n",
    "    device = audio_lengths.device\n",
    "    \n",
    "    adj_edges = get_adj_edges(len(phoneme_ids)).to(device)\n",
    "    phoneme_edges = get_phoneme_edges2(phoneme_ids, N=N).to(device)\n",
    "    _edges = torch.concat([adj_edges, phoneme_edges], dim=1)\n",
    "    total_edges = torch.unique(_edges, dim=1)\n",
    "\n",
    "    audio_lengths = audio_lengths.cpu()\n",
    "    actual_id = torch.ones((torch.sum(audio_lengths + N),))\n",
    "    total_len = 0\n",
    "    for i, _len in enumerate(audio_lengths):\n",
    "        x = torch.arange(_len + N) + torch.sum(audio_lengths[:i])\n",
    "        actual_id[total_len: total_len + _len] = x[:_len]\n",
    "        actual_id[total_len +_len : total_len+_len+N] = -1\n",
    "        total_len += _len + N\n",
    "\n",
    "    actual_id= actual_id.to(device)\n",
    "    total_edges = actual_id[total_edges]\n",
    "    mask = ~(total_edges == -1).any(dim=0)\n",
    "    total_edges = total_edges[:, mask]\n",
    "    \n",
    "    return total_edges.type(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "e4bd96f6-acf2-428e-a330-26fdd9be5772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T06:33:33.631876Z",
     "iopub.status.busy": "2024-07-27T06:33:33.631266Z",
     "iopub.status.idle": "2024-07-27T06:33:33.657209Z",
     "shell.execute_reply": "2024-07-27T06:33:33.655055Z",
     "shell.execute_reply.started": "2024-07-27T06:33:33.631816Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[139,  47,  72,  ...,  36, 179, 168],\n",
      "        [148, 171,  81,  ...,  32,  21, 197],\n",
      "        [ 51,  47,  52,  ..., 189, 126,  29],\n",
      "        ...,\n",
      "        [147, 173,   3,  ..., 179,  33,  52],\n",
      "        [105, 126, 147,  ..., 116,  93, 112],\n",
      "        [ 40, 149, 147,  ..., 174, 123, 174]], device='cuda:0') tensor([66, 60, 68, 65, 69, 63, 62, 66, 60, 67, 69, 66, 64, 64, 60, 65, 62, 62,\n",
      "        69, 65, 62, 67, 60, 60, 66, 68, 62, 61, 63, 65, 62, 62, 60, 68, 68, 62,\n",
      "        60, 66, 61, 69, 60, 65, 69, 69, 61, 60, 63, 60, 65, 64, 67, 62, 65, 69,\n",
      "        61, 64, 62, 66, 62, 66, 62, 69, 63, 60], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "B = 64\n",
    "T = 70\n",
    "N = 20\n",
    "phoneme_ids = torch.randint(0, 199, (B, T)).cuda()\n",
    "audio_lengths = torch.randint(T-10, T, (B,)).cuda()\n",
    "print(phoneme_ids, audio_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "7b1b34f1-079a-4fd3-8c27-ae93e0b21c3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T06:30:30.529387Z",
     "iopub.status.busy": "2024-07-27T06:30:30.529012Z",
     "iopub.status.idle": "2024-07-27T06:30:30.661340Z",
     "shell.execute_reply": "2024-07-27T06:30:30.659708Z",
     "shell.execute_reply.started": "2024-07-27T06:30:30.529353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 69040]),\n",
       " tensor([[   0,    0,    0,  ..., 4104, 4104, 4105],\n",
       "         [   1,    2,    3,  ..., 4105, 4106, 4106]], device='cuda:0'))"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2 = generate_edges(audio_lengths, phoneme_ids, N=N)\n",
    "e2.shape, e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "67c885a6-d4a1-47e0-bc3b-3ac900584b36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T06:33:37.793970Z",
     "iopub.status.busy": "2024-07-27T06:33:37.793343Z",
     "iopub.status.idle": "2024-07-27T06:33:37.834996Z",
     "shell.execute_reply": "2024-07-27T06:33:37.832993Z",
     "shell.execute_reply.started": "2024-07-27T06:33:37.793912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 68872]) tensor([[   0,    0,    0,  ..., 4095, 4095, 4096],\n",
      "        [   1,    2,    3,  ..., 4096, 4097, 4097]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    e3 = generate_edges_by_combine_and_split(audio_lengths, phoneme_ids, N=N)\n",
    "print(e3.shape, e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "563b7243-ef64-4e5e-9be7-0a1cd041512e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T06:12:17.915403Z",
     "iopub.status.busy": "2024-07-27T06:12:17.914724Z",
     "iopub.status.idle": "2024-07-27T06:12:17.929151Z",
     "shell.execute_reply": "2024-07-27T06:12:17.927162Z",
     "shell.execute_reply.started": "2024-07-27T06:12:17.915344Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_lengths = audio_lengths.cpu()\n",
    "actual_id = torch.ones((torch.sum(audio_lengths + N),))\n",
    "total_len = 0\n",
    "for i, _len in enumerate(audio_lengths):\n",
    "    x = torch.arange(_len + N) + torch.sum(audio_lengths[:i])\n",
    "    actual_id[total_len: total_len + _len] = x[:_len]\n",
    "    actual_id[total_len +_len : total_len+_len+N] = -1\n",
    "    total_len += _len + N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "1527a721-482f-44dd-8d74-1cd1a28e42df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T06:12:18.893187Z",
     "iopub.status.busy": "2024-07-27T06:12:18.892583Z",
     "iopub.status.idle": "2024-07-27T06:12:18.906824Z",
     "shell.execute_reply": "2024-07-27T06:12:18.904831Z",
     "shell.execute_reply.started": "2024-07-27T06:12:18.893130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 34]),\n",
       " torch.Size([12]),\n",
       " tensor([ 0.,  1., -1., -1., -1.,  2.,  3.,  4.,  5., -1., -1., -1.]))"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e3.shape, actual_id.shape, actual_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "82f59f80-70f7-4f9b-bc0a-b5b87d5f25ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T06:12:20.100646Z",
     "iopub.status.busy": "2024-07-27T06:12:20.100055Z",
     "iopub.status.idle": "2024-07-27T06:12:20.112653Z",
     "shell.execute_reply": "2024-07-27T06:12:20.110565Z",
     "shell.execute_reply.started": "2024-07-27T06:12:20.100589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 34]) torch.Size([2, 7])\n"
     ]
    }
   ],
   "source": [
    "e4 = actual_id[e3.cpu()]\n",
    "mask = ~(e4 == -1).any(dim=0)\n",
    "e5 = e4[:, mask]\n",
    "print(e4.shape, e5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "b2c5c6f4-8d25-4312-b8fe-689da4916405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T06:12:21.076809Z",
     "iopub.status.busy": "2024-07-27T06:12:21.076209Z",
     "iopub.status.idle": "2024-07-27T06:12:21.097553Z",
     "shell.execute_reply": "2024-07-27T06:12:21.095569Z",
     "shell.execute_reply.started": "2024-07-27T06:12:21.076752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 2, 2, 2, 3, 3, 4],\n",
       "         [1, 3, 4, 5, 4, 5, 5]], device='cuda:0'),\n",
       " tensor([[ 0,  0,  0,  1,  1,  1,  2,  2,  2,  3,  3,  3,  3,  4,  4,  4,  4,  5,\n",
       "           5,  5,  5,  6,  6,  6,  6,  7,  7,  7,  8,  8,  8,  9,  9, 10],\n",
       "         [ 1,  2,  3,  2,  3,  4,  3,  4,  5,  4,  5,  6,  7,  5,  6,  7,  8,  6,\n",
       "           7,  8,  9,  7,  8,  9, 10,  8,  9, 10,  9, 10, 11, 10, 11, 11]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.,  0.,  0.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "          -1., -1., -1.,  2.,  2.,  2.,  2.,  3.,  3.,  3.,  3.,  4.,  4.,  4.,\n",
       "           5.,  5.,  5., -1., -1., -1.],\n",
       "         [ 1., -1., -1., -1., -1., -1., -1., -1.,  2., -1.,  2.,  3.,  4.,  2.,\n",
       "           3.,  4.,  5.,  3.,  4.,  5., -1.,  4.,  5., -1., -1.,  5., -1., -1.,\n",
       "          -1., -1., -1., -1., -1., -1.]]),\n",
       " tensor([[0., 2., 2., 2., 3., 3., 4.],\n",
       "         [1., 3., 4., 5., 4., 5., 5.]]))"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2, e3, e4, e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a30a5-5a98-40ae-9137-42fb11d1de3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5b33a31-f1b2-45b3-8d34-425175b83bbd",
   "metadata": {},
   "source": [
    "# Weighted hidden states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc29369-0378-475b-bc08-af3703d27d14",
   "metadata": {},
   "source": [
    "设，一个audio的所有帧（T）的特征为(B, T, C), 而T帧对应的phoneme ids是：\n",
    "```python　\n",
    "predict_ids = torch.tensor([0, 0, 1, 1, 1, 2, 2, 2, 2, 2])\n",
    "```\n",
    "\n",
    "- 正常预测时，会在T帧上进行平均，得到`(B, T, C) -> (B, C)`，\n",
    "- 而weighted加权，会为每一帧分配一个权重，相邻的相同phoneme_id越多，那么权重越大。\n",
    "\n",
    "```python\n",
    "## 根据长度计算权重：　\n",
    "tensor([2, 2, 3, 3, 3, 5, 5, 5, 5, 5])\n",
    "\n",
    "## 归一化权重，使得sum=1.0：　\n",
    "tensor([0.0526, 0.0526, 0.0789, 0.0789, 0.0789, 0.1316, 0.1316, 0.1316, 0.1316,\n",
    "        0.1316])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "5f9129ce-4baa-47f6-b2b3-85127bfbadde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T04:59:47.026685Z",
     "iopub.status.busy": "2024-07-23T04:59:47.025358Z",
     "iopub.status.idle": "2024-07-23T04:59:47.041722Z",
     "shell.execute_reply": "2024-07-23T04:59:47.040364Z",
     "shell.execute_reply.started": "2024-07-23T04:59:47.026620Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_sequence_weights(predict_ids: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Calculate the normalized weights for each position in a sequence based on\n",
    "    the sequence lengths of consecutive identical elements.\n",
    "\n",
    "    ```python\n",
    "        predict_ids = torch.tensor([0, 0, 1, 1, 1, 2, 2, 2, 2, 2])\n",
    "\n",
    "        output: tensor([0.0526, 0.0526, 0.0789, 0.0789, 0.0789, 0.1316, 0.1316, 0.1316, 0.1316,\n",
    "        0.1316])\n",
    "    ```\n",
    "\n",
    "    Args:\n",
    "        predict_ids (torch.Tensor): the ids with shape (L)\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: the normalizad weights.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    output, inverse, counts = predict_ids.unique_consecutive(return_inverse=True, return_counts=True)\n",
    "    sequence_lengths = counts[inverse]\n",
    "    print(sequence_lengths)\n",
    "    normalized_weights = sequence_lengths.float() / sequence_lengths.sum().float()\n",
    "    return normalized_weights.squeeze()\n",
    "\n",
    "\n",
    "def get_weighted_hidden_state(hidden_states, phoneme_logits):\n",
    "    \"\"\"\n",
    "    Computes weighted hidden states efficiently when predict_ids is 1D.\n",
    "    \"\"\"\n",
    "    B, T, C = hidden_states.size()\n",
    "    weighted_hidden_states = torch.zeros(B, C, dtype=hidden_states.dtype, device=hidden_states.device)\n",
    "    for i, (_h, _l) in enumerate(zip(hidden_states, phoneme_logits)):\n",
    "        predict_ids = torch.argmax(_l, dim=1)  # Get most likely phoneme ID sequence from logits\n",
    "        weights = calculate_sequence_weights(predict_ids).unsqueeze(1)\n",
    "        weighted_hidden_states[i, :] = torch.sum(_h * weights, dim=0)\n",
    "\n",
    "    return weighted_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "aef833e4-6ec7-40ad-872e-7c0d4803b9aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T03:50:55.101587Z",
     "iopub.status.busy": "2024-07-23T03:50:55.100987Z",
     "iopub.status.idle": "2024-07-23T03:50:55.130470Z",
     "shell.execute_reply": "2024-07-23T03:50:55.128884Z",
     "shell.execute_reply.started": "2024-07-23T03:50:55.101528Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0385, -0.0323,  0.0318,  ..., -0.1140,  0.0664,  0.0711],\n",
       "        [-0.1164, -0.1143,  0.0586,  ..., -0.0409,  0.0053, -0.0723]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states = torch.randn(2, 149, 768)\n",
    "phoneme_logits = torch.randn(2, 149, 200)\n",
    "get_weighted_hidden_state(hidden_states, phoneme_logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
