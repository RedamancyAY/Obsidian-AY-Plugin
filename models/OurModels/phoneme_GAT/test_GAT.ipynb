{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eeeaccd-aaad-4d00-abc8-d10f42c70313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T04:36:35.577299Z",
     "iopub.status.busy": "2024-08-05T04:36:35.576730Z",
     "iopub.status.idle": "2024-08-05T04:36:35.602507Z",
     "shell.execute_reply": "2024-08-05T04:36:35.601691Z",
     "shell.execute_reply.started": "2024-08-05T04:36:35.577264Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bbd5ee1-b34e-4f9c-9546-c4b695c71378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T04:36:36.402348Z",
     "iopub.status.busy": "2024-08-05T04:36:36.401639Z",
     "iopub.status.idle": "2024-08-05T04:36:38.076801Z",
     "shell.execute_reply": "2024-08-05T04:36:38.075951Z",
     "shell.execute_reply.started": "2024-08-05T04:36:36.402313Z"
    }
   },
   "outputs": [],
   "source": [
    "from gat import GATLayer, GAT, GraphAttentionLayer\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e7b269-9e12-4341-9556-fb2a889b2ede",
   "metadata": {},
   "source": [
    "## GraphAttentionLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e70adc4-efe3-438e-abe5-fc38f58b8df6",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "GraphAttentionLayer来自RawGAT-ST\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c7aefa-0a22-4790-a532-ed679c8c1b73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T04:36:38.151478Z",
     "iopub.status.busy": "2024-08-05T04:36:38.151129Z",
     "iopub.status.idle": "2024-08-05T04:36:38.203811Z",
     "shell.execute_reply": "2024-08-05T04:36:38.203174Z",
     "shell.execute_reply.started": "2024-08-05T04:36:38.151454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 60, 64])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = GraphAttentionLayer(in_dim=128, out_dim=64)\n",
    "x = torch.randn(2, 60, 128)\n",
    "m(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34664930-0dbb-4532-a928-12adc3e9cf5d",
   "metadata": {},
   "source": [
    "## GATLayer and GAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7632f41c-d014-4324-b9f9-879aa31d4a9f",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "GATLayer and GAT 来自[gordicaleksa/pytorch-GAT: My implementation of the original GAT paper (Veličković et al.)](https://github.com/gordicaleksa/pytorch-GAT/tree/main)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e0cd5-57e9-44b1-9851-4f4be74344bb",
   "metadata": {},
   "source": [
    ":::{warning}\n",
    "对于GATLayer，需要注意的是：\n",
    "1. 实际输出的feat大小为`num_out_features * num_of_head`！\n",
    "2. edge_index的大小为`(2, N)`，表示$N$条边\n",
    "3. GATLayer不能处理batch输入，因此必须将batch的大小从`(B, T, C) -> (B*T, C)`　\n",
    "4. 输出的edge_inex和输入的edge_index是一样的，这是为了使得模型的输入和输出都是tuple，从而可以使用torch.Sequential\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f39965af-6e53-4472-8a71-508b20706085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T04:36:44.047250Z",
     "iopub.status.busy": "2024-08-05T04:36:44.046906Z",
     "iopub.status.idle": "2024-08-05T04:36:44.094755Z",
     "shell.execute_reply": "2024-08-05T04:36:44.094097Z",
     "shell.execute_reply.started": "2024-08-05T04:36:44.047222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3600, 512])\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0, 1], [1, 2], [2, 3]]).T\n",
    "\n",
    "m = GATLayer(num_in_features=128, num_out_features=128, num_of_heads=4)\n",
    "x = torch.randn(3600, 128)\n",
    "y, edge_index = m((x,edge_index))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20480684-2a59-4f60-adca-1272c1cc2501",
   "metadata": {},
   "source": [
    "### GAT模型　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfd30f4d-5a73-4edf-9c91-b1f9e68e3d14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T04:37:00.222424Z",
     "iopub.status.busy": "2024-08-05T04:37:00.221318Z",
     "iopub.status.idle": "2024-08-05T04:37:00.247240Z",
     "shell.execute_reply": "2024-08-05T04:37:00.246166Z",
     "shell.execute_reply.started": "2024-08-05T04:37:00.222392Z"
    }
   },
   "outputs": [],
   "source": [
    "gat_config = {\n",
    "    # GNNs, contrary to CNNs, are often shallow (it ultimately depends on the graph properties)\n",
    "    \"num_of_layers\": 3,  # PPI has got 42% of nodes with all 0 features - that's why 3 layers are useful\n",
    "    \"num_heads_per_layer\": [6, 6, 6],  # other values may give even better results from the reported ones\n",
    "    \"num_features_per_layer\": [768, 128, 128, 1],  # the first number is actually input dim\n",
    "    \"add_skip_connection\": True,  # skip connection is very important! (keep it otherwise micro-F1 is almost 0)\n",
    "    \"bias\": True,  # bias doesn't matter that much\n",
    "    \"dropout\": 0.0,  # dropout hurts the performance (best to keep it at 0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64063b18-ee4b-4160-9e5d-b4c31f4070b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T04:37:00.912756Z",
     "iopub.status.busy": "2024-08-05T04:37:00.911554Z",
     "iopub.status.idle": "2024-08-05T04:37:00.996619Z",
     "shell.execute_reply": "2024-08-05T04:37:00.995913Z",
     "shell.execute_reply.started": "2024-08-05T04:37:00.912696Z"
    }
   },
   "outputs": [],
   "source": [
    "model = GAT(**gat_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb60c02a-c884-4263-93c0-2f8b193d437a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T04:37:01.890783Z",
     "iopub.status.busy": "2024-08-05T04:37:01.890118Z",
     "iopub.status.idle": "2024-08-05T04:37:01.948939Z",
     "shell.execute_reply": "2024-08-05T04:37:01.948417Z",
     "shell.execute_reply.started": "2024-08-05T04:37:01.890742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1200, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states = torch.randn(1200, 768)\n",
    "edge_index = torch.randint(0, 1200, (2, 100) )\n",
    "logit, edge_index = model((hidden_states, edge_index))\n",
    "logit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d08ed-c9f3-41f6-aded-50af91185217",
   "metadata": {},
   "source": [
    "# Wav2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73da15f6-cc69-4d25-bb98-e7608378c258",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T13:17:21.815896Z",
     "iopub.status.busy": "2024-07-25T13:17:21.815523Z",
     "iopub.status.idle": "2024-07-25T13:17:21.823583Z",
     "shell.execute_reply": "2024-07-25T13:17:21.821389Z",
     "shell.execute_reply.started": "2024-07-25T13:17:21.815862Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC, WavLMForCTC\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899eef30-2948-43c5-9a29-1436376dd648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T13:17:08.980402Z",
     "iopub.status.busy": "2024-07-25T13:17:08.980138Z",
     "iopub.status.idle": "2024-07-25T13:17:10.098999Z",
     "shell.execute_reply": "2024-07-25T13:17:10.098151Z",
     "shell.execute_reply.started": "2024-07-25T13:17:08.980385Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ay/anaconda3/envs/torch/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "m = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36f8d798-5679-41f5-8d5b-8cd13d4d2c2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T13:17:23.600112Z",
     "iopub.status.busy": "2024-07-25T13:17:23.599461Z",
     "iopub.status.idle": "2024-07-25T13:17:23.667646Z",
     "shell.execute_reply": "2024-07-25T13:17:23.666868Z",
     "shell.execute_reply.started": "2024-07-25T13:17:23.600050Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.randn(2, 48000)\n",
    "feat1 = m.wav2vec2.feature_extractor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a3ccd8-0737-4a8e-aeb8-673414bd7384",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T13:17:24.566290Z",
     "iopub.status.busy": "2024-07-25T13:17:24.565812Z",
     "iopub.status.idle": "2024-07-25T13:17:24.629567Z",
     "shell.execute_reply": "2024-07-25T13:17:24.628812Z",
     "shell.execute_reply.started": "2024-07-25T13:17:24.566263Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.randn(2, 48000)\n",
    "feat1 = m.wav2vec2.feature_extractor(x).transpose(1, 2)\n",
    "hidden_states, extract_features = m.wav2vec2.feature_projection(feat1) # extract_features is the layer norm of feat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e2eb71-68c4-44e3-b08c-cf460f9527d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T13:17:26.878849Z",
     "iopub.status.busy": "2024-07-25T13:17:26.878548Z",
     "iopub.status.idle": "2024-07-25T13:17:26.888663Z",
     "shell.execute_reply": "2024-07-25T13:17:26.887538Z",
     "shell.execute_reply.started": "2024-07-25T13:17:26.878824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 149, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e7f1195-4fef-4644-a6d9-a8de8d66b42b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T13:17:28.802677Z",
     "iopub.status.busy": "2024-07-25T13:17:28.801448Z",
     "iopub.status.idle": "2024-07-25T13:17:28.810408Z",
     "shell.execute_reply": "2024-07-25T13:17:28.809037Z",
     "shell.execute_reply.started": "2024-07-25T13:17:28.802615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 149, 512]) torch.Size([2, 149, 512])\n"
     ]
    }
   ],
   "source": [
    "print(feat1.shape, extract_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98e7bd7e-07b5-4a2f-b535-055525c7079f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T07:10:04.885821Z",
     "iopub.status.busy": "2024-07-26T07:10:04.885237Z",
     "iopub.status.idle": "2024-07-26T07:10:04.991206Z",
     "shell.execute_reply": "2024-07-26T07:10:04.990622Z",
     "shell.execute_reply.started": "2024-07-26T07:10:04.885760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 149, 768]) torch.Size([2, 149, 32])\n"
     ]
    }
   ],
   "source": [
    "final_feat = m.wav2vec2.encoder(hidden_states)[0]\n",
    "\n",
    "logits = m.lm_head(final_feat)\n",
    "print(final_feat.shape, logits.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
