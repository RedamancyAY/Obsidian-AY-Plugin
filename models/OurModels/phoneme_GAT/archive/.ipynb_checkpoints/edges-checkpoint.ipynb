{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99bb1a3d-c6c0-463d-bba5-e00606c64e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T02:30:12.660493Z",
     "iopub.status.busy": "2024-07-27T02:30:12.659861Z",
     "iopub.status.idle": "2024-07-27T02:30:14.271482Z",
     "shell.execute_reply": "2024-07-27T02:30:14.270553Z",
     "shell.execute_reply.started": "2024-07-27T02:30:12.660433Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2d7d5e-a866-4460-a24e-18ae6ee81dbf",
   "metadata": {},
   "source": [
    "# reduce and combine hidden states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce78abf5-f672-4be0-9ecd-149ac4079662",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "在音素识别时，一个音素可能会跨多个时间帧，因此需要合并连续且相同的音素，构造为一个音素，从而预测整句话的音素，并与ground truth进行比较。\n",
    ":::\n",
    "\n",
    "那使用音素特征识别时，那么也许合并连续且相同的音素特征帧。设音素特征为`(B, T, 768)`，那么合并后的特征为`(B, T', 768)`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "085c3912-c58a-4bb9-aed1-79077dc0ec78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T12:34:59.781532Z",
     "iopub.status.busy": "2024-07-23T12:34:59.780869Z",
     "iopub.status.idle": "2024-07-23T12:34:59.895401Z",
     "shell.execute_reply": "2024-07-23T12:34:59.894679Z",
     "shell.execute_reply.started": "2024-07-23T12:34:59.781470Z"
    }
   },
   "outputs": [],
   "source": [
    "B = 64\n",
    "T = 149\n",
    "hidden_states = torch.randn(B, T, 768).cuda()\n",
    "phoneme_ids = torch.randint(0, 3, (B, T)).cuda()\n",
    "audio_lengths = torch.randint(70, 149, (B,)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "c32c3278-4d3b-4a86-a04a-7a08169f81a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T12:29:17.836771Z",
     "iopub.status.busy": "2024-07-23T12:29:17.836080Z",
     "iopub.status.idle": "2024-07-23T12:29:17.851435Z",
     "shell.execute_reply": "2024-07-23T12:29:17.849322Z",
     "shell.execute_reply.started": "2024-07-23T12:29:17.836709Z"
    }
   },
   "outputs": [],
   "source": [
    "def segment_means(tensor, segment_sizes):\n",
    "    assert tensor.size(0) == segment_sizes.sum(), \"Sum of segment sizes must equal the tensor's first dimension size.\"\n",
    "\n",
    "    # Create an indices tensor that maps each row in the tensor to its corresponding segment\n",
    "    indices = torch.repeat_interleave(torch.arange(len(segment_sizes), device=tensor.device), segment_sizes)\n",
    "\n",
    "    # Create a tensor to hold the sum of each segment\n",
    "    segment_sums = torch.zeros(len(segment_sizes), tensor.size(1), device=tensor.device)\n",
    "\n",
    "    # Scatter and sum the inputs into the segment_sums tensor\n",
    "    segment_sums.scatter_add_(0, indices.unsqueeze(1).expand(-1, tensor.size(1)), tensor)\n",
    "\n",
    "    # Calculate the mean of each segment\n",
    "    segment_means = segment_sums / segment_sizes.unsqueeze(1)\n",
    "\n",
    "    return segment_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "93ae7dad-9003-4452-a0a2-64e36fe1b75c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T12:35:51.463644Z",
     "iopub.status.busy": "2024-07-23T12:35:51.462972Z",
     "iopub.status.idle": "2024-07-23T12:35:51.479642Z",
     "shell.execute_reply": "2024-07-23T12:35:51.478050Z",
     "shell.execute_reply.started": "2024-07-23T12:35:51.463581Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reduce_feat(hidden_states, audio_lengths, phoneme_ids):\n",
    "    reduced_hidden_states = []\n",
    "    reduced_audio_lengths = []\n",
    "    reduced_phoneme_ids = []\n",
    "\n",
    "    phoneme_counts = []\n",
    "\n",
    "    for i in range(len(audio_lengths)):\n",
    "        _phoneme_ids = phoneme_ids[i, : audio_lengths[i]]\n",
    "        _h = hidden_states[i, : audio_lengths[i]]\n",
    "\n",
    "        unique_ids, _phoneme_counts = _phoneme_ids.unique_consecutive(return_counts=True)\n",
    "        # segments = torch.split(_h, _phoneme_counts.tolist())\n",
    "        # _h_reduced = torch.stack([seg.mean(dim=0) for seg in segments])\n",
    "        phoneme_counts += _phoneme_counts.tolist()\n",
    "\n",
    "        reduced_audio_lengths.append(len(unique_ids))\n",
    "        reduced_phoneme_ids.append(unique_ids)\n",
    "\n",
    "    reduced_audio_lengths = torch.tensor(reduced_audio_lengths)\n",
    "    reduced_phoneme_ids = torch.nn.utils.rnn.pad_sequence(reduced_phoneme_ids, batch_first=True)\n",
    "    h = torch.concat([hidden_states[i, :_len, :] for i, _len in enumerate(audio_lengths)], dim=0)\n",
    "    reduced_hidden_states = segment_means(h, torch.tensor(phoneme_counts, device=hidden_states.device))\n",
    "    return reduced_hidden_states, reduced_audio_lengths, reduced_phoneme_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "28d896f4-2c8f-4706-b1e4-e9893886fb73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T12:35:52.755955Z",
     "iopub.status.busy": "2024-07-23T12:35:52.755338Z",
     "iopub.status.idle": "2024-07-23T12:35:52.832602Z",
     "shell.execute_reply": "2024-07-23T12:35:52.831943Z",
     "shell.execute_reply.started": "2024-07-23T12:35:52.755895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 102]) torch.Size([4633, 768])\n"
     ]
    }
   ],
   "source": [
    "reduced_hidden_states, reduced_audio_lengths, reduced_phoneme_ids = reduce_feat(\n",
    "    hidden_states, audio_lengths, phoneme_ids\n",
    ")\n",
    "print(reduced_audio_lengths.shape, reduced_phoneme_ids.shape, reduced_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833a009d-0d56-4b28-8ae3-3c28a7a94a18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T11:36:20.325882Z",
     "iopub.status.busy": "2024-07-23T11:36:20.325205Z",
     "iopub.status.idle": "2024-07-23T11:36:20.334401Z",
     "shell.execute_reply": "2024-07-23T11:36:20.332216Z",
     "shell.execute_reply.started": "2024-07-23T11:36:20.325819Z"
    }
   },
   "source": [
    "# Generate edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf5dd05-a19e-48ae-938a-619be09a7239",
   "metadata": {},
   "source": [
    "设，一个audio的所有帧（T）对应的phoneme ids是，并给出了audio长度为10：\n",
    "```python　\n",
    "predict_ids = torch.tensor([0, 0, 1, 1, 1, 2, 2, 2, 2, 2])\n",
    "audio_lengths = [10]\n",
    "```\n",
    "\n",
    "那么，建立单项边时，有两个操作：\n",
    "1. 添加所有邻接边：`0->1, 1->2, 2->3, ...`\n",
    "2. 对于一个phoneme，对接下来的N个phoneme都建立边：\n",
    "    - 以第1个node为例（index从0开始），设N=1，那么会新加边：`1->2, 1->3, 1->4`\n",
    "    - 以第3个node为例（index从0开始），设N=1，那么会新加边：`3->5,6,7,8,9`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c490b5ac-a837-4a1c-aca1-0ab408199a1f",
   "metadata": {},
   "source": [
    "### Step 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1342c8-cc43-417b-9a73-578d842c118e",
   "metadata": {},
   "source": [
    "使用arange可以很快地生成所有邻接边。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4058df34-0a7c-4a2a-b8a2-f96295fa042f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T02:30:32.145714Z",
     "iopub.status.busy": "2024-07-27T02:30:32.145079Z",
     "iopub.status.idle": "2024-07-27T02:30:32.162584Z",
     "shell.execute_reply": "2024-07-27T02:30:32.160564Z",
     "shell.execute_reply.started": "2024-07-27T02:30:32.145653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "         140, 141, 142, 143, 144, 145, 146, 147],\n",
       "        [  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "          15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
       "          29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
       "          43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
       "          57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
       "          71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
       "          85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
       "          99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
       "         113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
       "         127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
       "         141, 142, 143, 144, 145, 146, 147, 148]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 149\n",
    "adj_edges = torch.stack([torch.arange(L - 1), torch.arange(1, L)])\n",
    "adj_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83575882-db6c-454f-9466-594de8faa5b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T02:30:37.263011Z",
     "iopub.status.busy": "2024-07-27T02:30:37.262407Z",
     "iopub.status.idle": "2024-07-27T02:30:37.272025Z",
     "shell.execute_reply": "2024-07-27T02:30:37.270362Z",
     "shell.execute_reply.started": "2024-07-27T02:30:37.262954Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_adj_edges(L: int):\n",
    "    adj_edges = torch.stack([torch.arange(L - 1), torch.arange(1, L)])\n",
    "    return adj_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed5a11a-beaa-44ad-8be5-8a9fae27ef69",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48661dca-4f72-4ce7-9c20-3b8da136956d",
   "metadata": {},
   "source": [
    "使用 `unique_consecutive`可以快速地查找所有不同的phoneme id，并定位其index范围。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d73bc5f9-6c33-4f39-8bee-dfc8dfd60f98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T02:32:37.064151Z",
     "iopub.status.busy": "2024-07-27T02:32:37.063441Z",
     "iopub.status.idle": "2024-07-27T02:32:37.083072Z",
     "shell.execute_reply": "2024-07-27T02:32:37.080944Z",
     "shell.execute_reply.started": "2024-07-27T02:32:37.064090Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_ids = torch.tensor([0, 0, 1, 1, 1, 2, 2, 2, 2, 2])\n",
    "N = 1\n",
    "\n",
    "output, inverse, counts = predict_ids.unique_consecutive(return_inverse=True, return_counts=True)\n",
    "cumsum_counts = torch.cumsum(counts, 0)\n",
    "# output, inverse, conuts, cumsum_counts\n",
    "\n",
    "edges = []\n",
    "for i in range(L):\n",
    "    unique_id = inverse[i]  # 0, 1, 2, 3,\n",
    "    unique_id_end_index = cumsum_counts[unique_id]\n",
    "    if unique_id == len(output) - 1:\n",
    "        break\n",
    "    next_id = min(len(output) - 1, unique_id + N)\n",
    "    next_end_index = cumsum_counts[next_id]\n",
    "    _edges = torch.stack(\n",
    "        [torch.full((next_end_index - unique_id_end_index,), i), torch.arange(unique_id_end_index, next_end_index)]\n",
    "    )\n",
    "    edges.append(_edges)\n",
    "edges = torch.concat(edges, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68820591-e663-44b2-9e18-64097d06609c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T02:32:37.838177Z",
     "iopub.status.busy": "2024-07-27T02:32:37.837570Z",
     "iopub.status.idle": "2024-07-27T02:32:37.850852Z",
     "shell.execute_reply": "2024-07-27T02:32:37.848835Z",
     "shell.execute_reply.started": "2024-07-27T02:32:37.838119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((2, 1), dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8eb285e-74ba-453f-9c3e-ef113ddcab06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T02:32:40.259361Z",
     "iopub.status.busy": "2024-07-27T02:32:40.258668Z",
     "iopub.status.idle": "2024-07-27T02:32:40.277565Z",
     "shell.execute_reply": "2024-07-27T02:32:40.275527Z",
     "shell.execute_reply.started": "2024-07-27T02:32:40.259302Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_phoneme_edges(predict_ids: torch.Tensor, N=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        predict_ids: a tensor with shape of (L,) that represents the phoneme id for each audio frame.\n",
    "        N: the number of looking forward phonemes\n",
    "    Returns:\n",
    "        torch.Tensor: the edges with shape of (2, n_edges)\n",
    "    \"\"\"\n",
    "    output, inverse, counts = predict_ids.unique_consecutive(return_inverse=True, return_counts=True)\n",
    "    cumsum_counts = torch.cumsum(counts, 0)\n",
    "    # output, inverse, conuts, cumsum_counts\n",
    "\n",
    "    if len(output) == 1:\n",
    "        return torch.zeros((2, 0))\n",
    "\n",
    "    s = time.time()\n",
    "    edges = []\n",
    "    for i in range(len(predict_ids)):\n",
    "        unique_id = inverse[i]  # 0, 1, 2, 3,\n",
    "        unique_id_end_index = cumsum_counts[unique_id]\n",
    "        if unique_id == len(output) - 1:\n",
    "            break\n",
    "        next_id = min(len(output) - 1, unique_id + N)\n",
    "        next_end_index = cumsum_counts[next_id]\n",
    "        _edges = torch.stack(\n",
    "            [torch.full((next_end_index - unique_id_end_index,), i), torch.arange(unique_id_end_index, next_end_index)]\n",
    "        )\n",
    "        edges.append(_edges)\n",
    "    edges = torch.concat(edges, 1)\n",
    "\n",
    "    e = time.time()\n",
    "    print(e - s)\n",
    "\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0af85f12-c64e-4189-b48e-6a0efb3d3ac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T02:59:15.907250Z",
     "iopub.status.busy": "2024-07-27T02:59:15.906601Z",
     "iopub.status.idle": "2024-07-27T02:59:15.924922Z",
     "shell.execute_reply": "2024-07-27T02:59:15.922921Z",
     "shell.execute_reply.started": "2024-07-27T02:59:15.907190Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_phoneme_edges2(predict_ids: torch.Tensor, N=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        predict_ids: a tensor with shape of (L,) that represents the phoneme id for each audio frame.\n",
    "        N: the number of looking forward phonemes\n",
    "    Returns:\n",
    "        torch.Tensor: the edges with shape of (2, n_edges)\n",
    "    \"\"\"\n",
    "\n",
    "    device = predict_ids.device\n",
    "    \n",
    "    output, inverse, counts = predict_ids.unique_consecutive(return_inverse=True, return_counts=True)\n",
    "    cumsum_counts = torch.cumsum(counts, 0).to(device)\n",
    "    # print(output, inverse, counts, cumsum_counts)\n",
    "\n",
    "    # both start and end are length L\n",
    "    start_indices = torch.cat([torch.tensor([0], device=device), cumsum_counts[:-1]])\n",
    "    end_indices = cumsum_counts\n",
    "    # print(\"start\", start_indices, \"end\", end_indices)\n",
    "\n",
    "    edge_start_indices = start_indices[1:]\n",
    "    edge_end_indices = end_indices[torch.clamp(torch.arange(len(output) - 1) + N, max=len(end_indices) - 1)]\n",
    "    # print(edge_start_indices, edge_end_indices)\n",
    "\n",
    "    print(edge_end_indices.device)\n",
    "    x = torch.repeat_interleave(\n",
    "        torch.arange(cumsum_counts[-2]).to(device), (edge_end_indices - edge_start_indices)[inverse[: cumsum_counts[-2]]], dim=0\n",
    "    ).to(device)\n",
    "    y = generate_multple_sequences(ns=counts[:-1], as_=edge_start_indices, bs=edge_end_indices).to(device)\n",
    "    edges = torch.stack([x, y])\n",
    "    # print(x.shape, y.shape, edges.shape)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e776992-4dd6-44f0-a2da-64203a5aec52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T03:00:45.416809Z",
     "iopub.status.busy": "2024-07-27T03:00:45.416199Z",
     "iopub.status.idle": "2024-07-27T03:00:45.519250Z",
     "shell.execute_reply": "2024-07-27T03:00:45.517198Z",
     "shell.execute_reply.started": "2024-07-27T03:00:45.416750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m predict_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m])\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mget_phoneme_edges2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 29\u001b[0m, in \u001b[0;36mget_phoneme_edges2\u001b[0;34m(predict_ids, N)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(edge_end_indices\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrepeat_interleave(\n\u001b[1;32m     27\u001b[0m     torch\u001b[38;5;241m.\u001b[39marange(cumsum_counts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device), (edge_end_indices \u001b[38;5;241m-\u001b[39m edge_start_indices)[inverse[: cumsum_counts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     28\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 29\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_multple_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcounts\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_start_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_end_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m edges \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([x, y])\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# print(x.shape, y.shape, edges.shape)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[39], line 43\u001b[0m, in \u001b[0;36mgenerate_multple_sequences\u001b[0;34m(ns, as_, bs)\u001b[0m\n\u001b[1;32m     41\u001b[0m seq_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrepeat_interleave(as_, ns)[:, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m seq_tensor\n\u001b[1;32m     42\u001b[0m nums \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrepeat_interleave(bs \u001b[38;5;241m-\u001b[39m as_, ns)\n\u001b[0;32m---> 43\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_tensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnums\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seq_tensor[mask]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "predict_ids = torch.tensor([0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3]).cuda()\n",
    "get_phoneme_edges2(predict_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2abf8e0-070d-467b-937f-351e1862a088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T03:00:44.365625Z",
     "iopub.status.busy": "2024-07-27T03:00:44.364998Z",
     "iopub.status.idle": "2024-07-27T03:00:44.380364Z",
     "shell.execute_reply": "2024-07-27T03:00:44.378299Z",
     "shell.execute_reply.started": "2024-07-27T03:00:44.365564Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_multple_sequences(ns, as_, bs):\n",
    "    \"\"\"\n",
    "    quickly generate n1 sequences that ranging from a1 to b1,\n",
    "            generate n2 sequences that ranging from a2 to b2,\n",
    "            generate n3 sequences that ranging from a3 to b3,\n",
    "            ....\n",
    "    and finally combine these sequences\n",
    "\n",
    "\n",
    "    ```python\n",
    "    ns = torch.tensor([5, 3, 4])\n",
    "    as_ = torch.tensor([1, 11, 16])\n",
    "    bs = torch.tensor([10, 15, 20])\n",
    "    ```\n",
    "    > tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9,\n",
    "               1,  2,  3,  4,  5,  6,  7,  8,  9,\n",
    "               1,  2,  3,  4,  5,  6,  7,  8,  9,\n",
    "               1,  2,  3,  4,  5,  6,  7,  8,  9,\n",
    "               1,  2,  3,  4,  5,  6,  7,  8,  9,\n",
    "               11, 12, 13, 14,\n",
    "               11, 12, 13, 14,\n",
    "               11, 12, 13, 14,\n",
    "               16, 17, 18, 19,\n",
    "               16, 17, 18, 19,\n",
    "               16, 17, 18, 19,\n",
    "               16, 17, 18, 19])\n",
    "    Args:\n",
    "        ns: the repeat number of sequences\n",
    "        as_: the start number for each seq\n",
    "        bs: the end number for each seq\n",
    "\n",
    "    Returns:\n",
    "        tensor: a 1D tensor for the combined seq.\n",
    "    \"\"\"\n",
    "    # print(ns, as_, bs)\n",
    "    device = ns.device\n",
    "    # The maximum value in bs determines the tensor width for uniformity\n",
    "    max_length = torch.max(bs - as_ + 1)\n",
    "    # Generate a tensor where each row is a sequence from 0 to max_length\n",
    "    seq_tensor = torch.arange(max_length).unsqueeze(0).repeat(ns.sum(), 1).to(device)\n",
    "    seq_tensor = torch.repeat_interleave(as_, ns)[:, None] + seq_tensor\n",
    "    nums = torch.repeat_interleave(bs - as_, ns)\n",
    "    mask = torch.arange(seq_tensor.size(1)).expand_as(seq_tensor) < nums.unsqueeze(1)\n",
    "\n",
    "    return seq_tensor[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379e26f2-dfdc-417e-8781-c097c9b170f9",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f13d3b9-f8ab-439e-9ff2-7e7e1759d5d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T02:34:30.671643Z",
     "iopub.status.busy": "2024-07-27T02:34:30.671312Z",
     "iopub.status.idle": "2024-07-27T02:34:30.681695Z",
     "shell.execute_reply": "2024-07-27T02:34:30.679632Z",
     "shell.execute_reply.started": "2024-07-27T02:34:30.671617Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_edges(input_audio_lengths: torch.Tensor, input_phoneme_ids: torch.Tensor, N=2):\n",
    "    start_id = 0\n",
    "    edge_index = []\n",
    "\n",
    "    # audio_lengths = input_audio_lengths.cpu()\n",
    "    audio_lengths = input_audio_lengths\n",
    "    # phoneme_ids = input_phoneme_ids.cpu()\n",
    "    phoneme_ids = input_phoneme_ids\n",
    "\n",
    "    cumsum_audio_lengths = torch.cumsum(audio_lengths, 0)\n",
    "\n",
    "    device = audio_lengths.device\n",
    "    \n",
    "    total_edges = []\n",
    "    for i in range(len(audio_lengths)):\n",
    "        _audio_len = audio_lengths[i]\n",
    "        _phoneme_ids = phoneme_ids[i, :_audio_len]\n",
    "        _start_index = cumsum_audio_lengths[i - 1] if i > 0 else 0\n",
    "\n",
    "        adj_edges = get_adj_edges(_audio_len).to(device)\n",
    "        phoneme_edges = get_phoneme_edges2(_phoneme_ids, N=N).to(device)\n",
    "        _edges = torch.concat([adj_edges, phoneme_edges], dim=1) + _start_index\n",
    "        total_edges.append(_edges)\n",
    "    total_edges = torch.concat(total_edges, dim=1)\n",
    "    total_edges = torch.unique(total_edges, dim=1)\n",
    "    return total_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "59aa3ec6-6a0d-4eb2-91a8-28a732115364",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T08:18:07.421196Z",
     "iopub.status.busy": "2024-07-23T08:18:07.420620Z",
     "iopub.status.idle": "2024-07-23T08:18:07.430018Z",
     "shell.execute_reply": "2024-07-23T08:18:07.428011Z",
     "shell.execute_reply.started": "2024-07-23T08:18:07.421139Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "audio_lengths = torch.tensor([5, 8])\n",
    "phoneme_ids = torch.randint(0, 3, (2, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "87e2d232-93a2-49ac-ad02-7c523fe05eb5",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-07-23T08:18:08.407984Z",
     "iopub.status.busy": "2024-07-23T08:18:08.407415Z",
     "iopub.status.idle": "2024-07-23T08:18:08.419382Z",
     "shell.execute_reply": "2024-07-23T08:18:08.417423Z",
     "shell.execute_reply.started": "2024-07-23T08:18:08.407927Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 2, 0, 1, 0, 1, 0, 2],\n",
       "        [2, 1, 1, 1, 1, 2, 2, 0, 0, 2]])"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "ed3a9b83-acbc-451c-a631-67cc59f6d651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T08:03:29.057202Z",
     "iopub.status.busy": "2024-07-23T08:03:29.056608Z",
     "iopub.status.idle": "2024-07-23T08:03:29.067189Z",
     "shell.execute_reply": "2024-07-23T08:03:29.065156Z",
     "shell.execute_reply.started": "2024-07-23T08:03:29.057143Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "B = 64\n",
    "T = 149\n",
    "phoneme_ids = torch.randint(0, 199, (B, T))\n",
    "audio_lengths = torch.tensor([T] * B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "991128c6-3366-4b56-8226-54ccd379682d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T08:18:09.923862Z",
     "iopub.status.busy": "2024-07-23T08:18:09.923254Z",
     "iopub.status.idle": "2024-07-23T08:18:09.947543Z",
     "shell.execute_reply": "2024-07-23T08:18:09.945642Z",
     "shell.execute_reply.started": "2024-07-23T08:18:09.923804Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  1,  1,  1,  2,  2,  3,  5,  5,  5,  5,  5,  5,  6,  6,  6,\n",
       "          6,  7,  7,  7,  7,  8,  8,  8,  8,  9,  9,  9, 10, 10, 11],\n",
       "        [ 1,  3,  4,  2,  3,  4,  3,  4,  4,  6,  7,  8,  9, 10, 11,  7, 10, 11,\n",
       "         12,  8, 10, 11, 12,  9, 10, 11, 12, 10, 11, 12, 11, 12, 12]])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumsum_audio_lengths = torch.cumsum(audio_lengths, 0)\n",
    "\n",
    "total_edges = []\n",
    "for i in range(len(audio_lengths)):\n",
    "    _audio_len = audio_lengths[i]\n",
    "    _phoneme_ids = phoneme_ids[i, :_audio_len]\n",
    "    _start_index = cumsum_audio_lengths[i - 1] if i > 0 else 0\n",
    "\n",
    "    adj_edges = get_adj_edges(_audio_len)\n",
    "    phoneme_edges = get_phoneme_edges(_phoneme_ids, N=2)\n",
    "    _edges = torch.concat([adj_edges, phoneme_edges], dim=1) + _start_index\n",
    "    total_edges.append(_edges)\n",
    "total_edges = torch.concat(total_edges, dim=1)\n",
    "total_edges = torch.unique(total_edges, dim=1)\n",
    "\n",
    "total_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f6ed66d-a513-4b9a-b036-7c0073869a4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T02:34:00.978137Z",
     "iopub.status.busy": "2024-07-27T02:34:00.977799Z",
     "iopub.status.idle": "2024-07-27T02:34:00.994264Z",
     "shell.execute_reply": "2024-07-27T02:34:00.992105Z",
     "shell.execute_reply.started": "2024-07-27T02:34:00.978109Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "B = 64\n",
    "T = 149\n",
    "phoneme_ids = torch.randint(0, 199, (B, T)).cuda()\n",
    "audio_lengths = torch.tensor([T] * B).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e339ce4b-0bb6-4906-adf8-cfae5606760d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T02:40:17.505474Z",
     "iopub.status.busy": "2024-07-27T02:40:17.503853Z",
     "iopub.status.idle": "2024-07-27T02:40:17.609710Z",
     "shell.execute_reply": "2024-07-27T02:40:17.607806Z",
     "shell.execute_reply.started": "2024-07-27T02:40:17.505397Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m e2 \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphoneme_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 19\u001b[0m, in \u001b[0;36mgenerate_edges\u001b[0;34m(input_audio_lengths, input_phoneme_ids, N)\u001b[0m\n\u001b[1;32m     16\u001b[0m _start_index \u001b[38;5;241m=\u001b[39m cumsum_audio_lengths[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m adj_edges \u001b[38;5;241m=\u001b[39m get_adj_edges(_audio_len)\n\u001b[0;32m---> 19\u001b[0m phoneme_edges \u001b[38;5;241m=\u001b[39m \u001b[43mget_phoneme_edges2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_phoneme_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m _edges \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([adj_edges, phoneme_edges], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m _start_index\n\u001b[1;32m     21\u001b[0m total_edges\u001b[38;5;241m.\u001b[39mappend(_edges)\n",
      "Cell \u001b[0;32mIn[29], line 28\u001b[0m, in \u001b[0;36mget_phoneme_edges2\u001b[0;34m(predict_ids, N)\u001b[0m\n\u001b[1;32m     25\u001b[0m edge_end_indices \u001b[38;5;241m=\u001b[39m end_indices[torch\u001b[38;5;241m.\u001b[39mclamp(torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(output) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m N, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(end_indices) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# print(edge_start_indices, edge_end_indices)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat_interleave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcumsum_counts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_end_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43medge_start_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43minverse\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcumsum_counts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m y \u001b[38;5;241m=\u001b[39m generate_multple_sequences(ns\u001b[38;5;241m=\u001b[39mcounts[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], as_\u001b[38;5;241m=\u001b[39medge_start_indices, bs\u001b[38;5;241m=\u001b[39medge_end_indices)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     32\u001b[0m edges \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([x, y])\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "e2 = generate_edges(audio_lengths, phoneme_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "280551d1-6bec-43c7-a09b-3946d54982ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T07:32:13.047812Z",
     "iopub.status.busy": "2024-07-24T07:32:13.046496Z",
     "iopub.status.idle": "2024-07-24T07:32:13.656840Z",
     "shell.execute_reply": "2024-07-24T07:32:13.655608Z",
     "shell.execute_reply.started": "2024-07-24T07:32:13.047748Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007739543914794922\n",
      "0.00764155387878418\n",
      "0.008351802825927734\n",
      "0.007665395736694336\n",
      "0.007583141326904297\n",
      "0.007695436477661133\n",
      "0.007594585418701172\n",
      "0.007628440856933594\n",
      "0.0076253414154052734\n",
      "0.00757908821105957\n",
      "0.007592916488647461\n",
      "0.007593870162963867\n",
      "0.007617473602294922\n",
      "0.007589817047119141\n",
      "0.007596731185913086\n",
      "0.0075910091400146484\n",
      "0.0075571537017822266\n",
      "0.0075647830963134766\n",
      "0.00755000114440918\n",
      "0.007582902908325195\n",
      "0.007536888122558594\n",
      "0.00753474235534668\n",
      "0.007597684860229492\n",
      "0.0075991153717041016\n",
      "0.007602214813232422\n",
      "0.007534980773925781\n",
      "0.008611440658569336\n",
      "0.007569313049316406\n",
      "0.0076029300689697266\n",
      "0.008214473724365234\n",
      "0.0077092647552490234\n",
      "0.007634878158569336\n",
      "0.007620096206665039\n",
      "0.0076367855072021484\n",
      "0.007555723190307617\n",
      "0.007611751556396484\n",
      "0.007607936859130859\n",
      "0.00765228271484375\n",
      "0.007688999176025391\n",
      "0.007696866989135742\n",
      "0.007664680480957031\n",
      "0.0076525211334228516\n",
      "0.0075719356536865234\n",
      "0.007580280303955078\n",
      "0.00758671760559082\n",
      "0.007586240768432617\n",
      "0.0075800418853759766\n",
      "0.007592439651489258\n",
      "0.007582664489746094\n",
      "0.007593870162963867\n",
      "0.007600307464599609\n",
      "0.007666826248168945\n",
      "0.010239124298095703\n",
      "0.007612943649291992\n",
      "0.007591724395751953\n",
      "0.007619142532348633\n",
      "0.007624387741088867\n",
      "0.00758814811706543\n",
      "0.007595062255859375\n",
      "0.007567405700683594\n",
      "0.007609128952026367\n",
      "0.007601737976074219\n",
      "0.007573604583740234\n",
      "0.0076143741607666016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = generate_edges(audio_lengths, phoneme_ids)\n",
    "torch.sum(e1 - e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b33a31-f1b2-45b3-8d34-425175b83bbd",
   "metadata": {},
   "source": [
    "# Weighted hidden states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc29369-0378-475b-bc08-af3703d27d14",
   "metadata": {},
   "source": [
    "设，一个audio的所有帧（T）的特征为(B, T, C), 而T帧对应的phoneme ids是：\n",
    "```python　\n",
    "predict_ids = torch.tensor([0, 0, 1, 1, 1, 2, 2, 2, 2, 2])\n",
    "```\n",
    "\n",
    "- 正常预测时，会在T帧上进行平均，得到`(B, T, C) -> (B, C)`，\n",
    "- 而weighted加权，会为每一帧分配一个权重，相邻的相同phoneme_id越多，那么权重越大。\n",
    "\n",
    "```python\n",
    "## 根据长度计算权重：　\n",
    "tensor([2, 2, 3, 3, 3, 5, 5, 5, 5, 5])\n",
    "\n",
    "## 归一化权重，使得sum=1.0：　\n",
    "tensor([0.0526, 0.0526, 0.0789, 0.0789, 0.0789, 0.1316, 0.1316, 0.1316, 0.1316,\n",
    "        0.1316])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "5f9129ce-4baa-47f6-b2b3-85127bfbadde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T04:59:47.026685Z",
     "iopub.status.busy": "2024-07-23T04:59:47.025358Z",
     "iopub.status.idle": "2024-07-23T04:59:47.041722Z",
     "shell.execute_reply": "2024-07-23T04:59:47.040364Z",
     "shell.execute_reply.started": "2024-07-23T04:59:47.026620Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_sequence_weights(predict_ids: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Calculate the normalized weights for each position in a sequence based on\n",
    "    the sequence lengths of consecutive identical elements.\n",
    "\n",
    "    ```python\n",
    "        predict_ids = torch.tensor([0, 0, 1, 1, 1, 2, 2, 2, 2, 2])\n",
    "\n",
    "        output: tensor([0.0526, 0.0526, 0.0789, 0.0789, 0.0789, 0.1316, 0.1316, 0.1316, 0.1316,\n",
    "        0.1316])\n",
    "    ```\n",
    "\n",
    "    Args:\n",
    "        predict_ids (torch.Tensor): the ids with shape (L)\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: the normalizad weights.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    output, inverse, counts = predict_ids.unique_consecutive(return_inverse=True, return_counts=True)\n",
    "    sequence_lengths = counts[inverse]\n",
    "    print(sequence_lengths)\n",
    "    normalized_weights = sequence_lengths.float() / sequence_lengths.sum().float()\n",
    "    return normalized_weights.squeeze()\n",
    "\n",
    "\n",
    "def get_weighted_hidden_state(hidden_states, phoneme_logits):\n",
    "    \"\"\"\n",
    "    Computes weighted hidden states efficiently when predict_ids is 1D.\n",
    "    \"\"\"\n",
    "    B, T, C = hidden_states.size()\n",
    "    weighted_hidden_states = torch.zeros(B, C, dtype=hidden_states.dtype, device=hidden_states.device)\n",
    "    for i, (_h, _l) in enumerate(zip(hidden_states, phoneme_logits)):\n",
    "        predict_ids = torch.argmax(_l, dim=1)  # Get most likely phoneme ID sequence from logits\n",
    "        weights = calculate_sequence_weights(predict_ids).unsqueeze(1)\n",
    "        weighted_hidden_states[i, :] = torch.sum(_h * weights, dim=0)\n",
    "\n",
    "    return weighted_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "aef833e4-6ec7-40ad-872e-7c0d4803b9aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T03:50:55.101587Z",
     "iopub.status.busy": "2024-07-23T03:50:55.100987Z",
     "iopub.status.idle": "2024-07-23T03:50:55.130470Z",
     "shell.execute_reply": "2024-07-23T03:50:55.128884Z",
     "shell.execute_reply.started": "2024-07-23T03:50:55.101528Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0385, -0.0323,  0.0318,  ..., -0.1140,  0.0664,  0.0711],\n",
       "        [-0.1164, -0.1143,  0.0586,  ..., -0.0409,  0.0053, -0.0723]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states = torch.randn(2, 149, 768)\n",
    "phoneme_logits = torch.randn(2, 149, 200)\n",
    "get_weighted_hidden_state(hidden_states, phoneme_logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
