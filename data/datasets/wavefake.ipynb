{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b20c8a5-f2b4-4f11-8a27-522bdbcceaf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T06:32:39.626698Z",
     "iopub.status.busy": "2023-07-14T06:32:39.626117Z",
     "iopub.status.idle": "2023-07-14T06:32:39.642362Z",
     "shell.execute_reply": "2023-07-14T06:32:39.641833Z",
     "shell.execute_reply.started": "2023-07-14T06:32:39.626673Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794a47ae-cd80-4044-b333-9b27b61fb50b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T06:32:41.149705Z",
     "iopub.status.busy": "2023-07-14T06:32:41.149350Z",
     "iopub.status.idle": "2023-07-14T06:32:41.511045Z",
     "shell.execute_reply": "2023-07-14T06:32:41.510383Z",
     "shell.execute_reply.started": "2023-07-14T06:32:41.149682Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "from typing import Union\n",
    "from argparse import Namespace\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa106514-8977-493f-987e-4e01f41ae228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T06:32:42.044814Z",
     "iopub.status.busy": "2023-07-14T06:32:42.044354Z",
     "iopub.status.idle": "2023-07-14T06:32:44.763046Z",
     "shell.execute_reply": "2023-07-14T06:32:44.762353Z",
     "shell.execute_reply.started": "2023-07-14T06:32:42.044785Z"
    }
   },
   "outputs": [],
   "source": [
    "from ay2.common.audio import get_fps_len\n",
    "from ay2.tools import check_dir, read_file_paths_from_folder, to_list\n",
    "from ay2.tools.pandas import DF_spliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df4c1844-9dbc-4a83-a02a-df56efed547b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T06:32:44.764654Z",
     "iopub.status.busy": "2023-07-14T06:32:44.764252Z",
     "iopub.status.idle": "2023-07-14T06:32:44.794432Z",
     "shell.execute_reply": "2023-07-14T06:32:44.793786Z",
     "shell.execute_reply.started": "2023-07-14T06:32:44.764630Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import NamedTuple\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e272d2f8-02eb-4b6d-a081-c2a6d9c1c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .base import Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31c8c1dd-3417-47cc-a7f6-45e35b8f5914",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-07-14T08:04:13.198426Z",
     "iopub.status.busy": "2023-07-14T08:04:13.197721Z",
     "iopub.status.idle": "2023-07-14T08:04:13.232238Z",
     "shell.execute_reply": "2023-07-14T08:04:13.231270Z",
     "shell.execute_reply.started": "2023-07-14T08:04:13.198378Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "style-activity",
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "from base import Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d31842-d155-4469-89e0-ccb5c3091703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T06:32:45.506103Z",
     "iopub.status.busy": "2023-07-14T06:32:45.505730Z",
     "iopub.status.idle": "2023-07-14T06:32:45.537422Z",
     "shell.execute_reply": "2023-07-14T06:32:45.536864Z",
     "shell.execute_reply.started": "2023-07-14T06:32:45.506081Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(NamedTuple):\n",
    "    train: pd.DataFrame\n",
    "    test: pd.DataFrame\n",
    "    val: pd.DataFrame = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbf4498-f24b-4338-8ef3-30a5b827dcfd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d3f444-b543-4dbd-be0b-6ce584abfb0b",
   "metadata": {},
   "source": [
    "1. Uncompress the wavefake dataset, rename it into 'WaveFake'\n",
    "2. change the folder `WaveFake/common_voices_prompts_from_conformer_fastspeech2_pwg_ljspeech` into 'WaveFake/ljspeech_tts'\n",
    "    * Inside `WaveFake/ljspeech_tts`, there are directly 16283 audios, but the folder `WaveFake/ljspeech_tts/generated` still have 16283 audios. We delete the `generated` folder.\n",
    "3. Uncompress the LJSeech dataset, rename it into `ljspeech_real` and put it in the `WaveFake` folder.\n",
    "4. Uncompress the JSUT dataset, rename it into `jsut_real` and put it in the `WaveFake` folder.\n",
    "\n",
    "The folder sturcture of WaveFake is: \n",
    "```json\n",
    "WaveFake\n",
    "├── jsut_multi_band_melgan\n",
    "├── jsut_parallel_wavegan\n",
    "├── jsut_real\n",
    "├── ljspeech_full_band_melgan\n",
    "├── ljspeech_hifiGAN\n",
    "├── ljspeech_melgan\n",
    "├── ljspeech_melgan_large\n",
    "├── ljspeech_multi_band_melgan\n",
    "├── ljspeech_parallel_wavegan\n",
    "├── ljspeech_real\n",
    "├── ljspeech_tts\n",
    "├── ljspeech_waveglow\n",
    "└── readme.txt\n",
    "\n",
    "12 directories, 1 file\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ef67b9-94bb-4175-bcbc-cba1d2abef0c",
   "metadata": {},
   "source": [
    "\n",
    "每个文件夹下的音频数量如下：\n",
    "| trainSet   | method            |   path |\n",
    "|:-----------|:------------------|-------:|\n",
    "| jsut       | multi_band_melgan |   5000 |\n",
    "| jsut       | parallel_wavegan  |   5000 |\n",
    "| jsut       | real              |   5000 |\n",
    "| ljspeech   | full_band_melgan  |  13100 |\n",
    "| ljspeech   | hifiGAN           |  13100 |\n",
    "| ljspeech   | melgan            |  13100 |\n",
    "| ljspeech   | melgan_large      |  13100 |\n",
    "| ljspeech   | multi_band_melgan |  13100 |\n",
    "| ljspeech   | parallel_wavegan  |  13100 |\n",
    "| ljspeech   | real              |  13100 |\n",
    "| ljspeech   | tts               |  16283 |\n",
    "| ljspeech   | waveglow          |  13100 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b84077a-f40f-42ef-a5fe-a5080098f362",
   "metadata": {},
   "source": [
    "## WaveFake class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139075be-1be1-49c3-b6ea-5c08a3dcd8c8",
   "metadata": {},
   "source": [
    "`WaveFake` will read the metadata info for all the audios, and save it (csv format) in the root_path of WaveFake. The examples of the metadata are showed as:\n",
    "\n",
    "|        | path                                                                                         | trainSet   | method            |   fps |   length |   label | id               |\n",
    "|-------:|:---------------------------------------------------------------------------------------------|:-----------|:------------------|------:|---------:|--------:|:-----------------|\n",
    "|  15321 | /usr/local/ay_data/dataset/0-deepfake/WaveFake/ljspeech_tts/gen_13607.wav                    | ljspeech   | tts               | 22050 |  3.20435 |       0 | gen_13607        |\n",
    "|  91937 | /usr/local/ay_data/dataset/0-deepfake/WaveFake/ljspeech_melgan/LJ024-0083_gen.wav            | ljspeech   | melgan            | 22050 |  3.25079 |       0 | LJ024-0083       |\n",
    "|  43707 | /usr/local/ay_data/dataset/0-deepfake/WaveFake/ljspeech_waveglow/LJ018-0097.wav              | ljspeech   | waveglow          | 22050 |  5.7005  |       0 | LJ018-0097       |\n",
    "|  75366 | /usr/local/ay_data/dataset/0-deepfake/WaveFake/ljspeech_parallel_wavegan/LJ043-0150_gen.wav  | ljspeech   | parallel_wavegan  | 22050 |  4.69043 |       0 | LJ043-0150       |\n",
    "| 121075 | /usr/local/ay_data/dataset/0-deepfake/WaveFake/ljspeech_melgan_large/LJ003-0283_gen.wav      | ljspeech   | melgan_large      | 22050 |  8.85841 |       0 | LJ003-0283       |\n",
    "|   4522 | /usr/local/ay_data/dataset/0-deepfake/WaveFake/ljspeech_tts/gen_7735.wav                     | ljspeech   | tts               | 22050 |  6.33905 |       0 | gen_7735         |\n",
    "| 106158 | /usr/local/ay_data/dataset/0-deepfake/WaveFake/jsut_multi_band_melgan/BASIC5000_4225_gen.wav | jsut       | multi_band_melgan | 24000 |  8.9875  |       0 | BASIC5000_4225   |\n",
    "|   1361 | /usr/local/ay_data/dataset/0-deepfake/WaveFake/ljspeech_tts/gen_14993.wav                    | ljspeech   | tts               | 22050 |  4.51628 |       0 | gen_14993        |\n",
    "| 106225 | /usr/local/ay_data/dataset/0-deepfake/WaveFake/jsut_multi_band_melgan/BASIC5000_4962_gen.wav | jsut       | multi_band_melgan | 24000 |  2.85    |       0 | BASIC5000_4962   |\n",
    "| 125639 | /usr/local/ay_data/dataset/0-deepfake/WaveFake/ljspeech_multi_band_melgan/LJ033-0121_gen.wav | ljspeech   | multi_band_melgan | 22050 |  4.55111 |       0 | LJ033-0121       |\n",
    "|  51593 | /usr/local/ay_data/dataset/0-deepfake/WaveFake/ljspeech_waveglow/LJ031-0180.wav              | ljspeech   | waveglow          | 22050 |  7.53488 |       0 | LJ031-0180       |\n",
    "|  90079 | /usr/local/ay_data/dataset/0-deepfake/WaveFake/ljspeech_melgan/LJ021-0099_gen.wav            | ljspeech   | melgan            | 22050 |  8.71909 |       0 | LJ021-0099       |\n",
    "|  87734 | /usr/local/ay_data/dataset/0-deepfake/WaveFake/ljspeech_melgan/LJ002-0280_gen.wav            | ljspeech   | melgan            | 22050 |  9.8917  |       0 | LJ002-0280       |\n",
    "|  71944 | /usr/local/ay_data/dataset/0-deepfake/WaveFake/ljspeech_hifiGAN/LJ043-0122_generated.wav     | ljspeech   | hifiGAN           | 22050 | 10.0078  |       0 | LJ043-0122erated |\n",
    "|  16546 | /usr/local/ay_data/dataset/0-deepfake/WaveFake/ljspeech_real/wavs/LJ031-0084.wav             | ljspeech   | real              | 22050 |  7.87868 |       1 | LJ031-0084       |m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3a7cc5-8452-49ee-b666-6f40a710fa4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T11:47:08.795651Z",
     "iopub.status.busy": "2023-07-16T11:47:08.795031Z",
     "iopub.status.idle": "2023-07-16T11:47:08.808731Z",
     "shell.execute_reply": "2023-07-16T11:47:08.807855Z",
     "shell.execute_reply.started": "2023-07-16T11:47:08.795523Z"
    }
   },
   "outputs": [],
   "source": [
    "VOCODERs = [\n",
    "    \"melgan\",\n",
    "    \"parallel_wavegan\",\n",
    "    \"multi_band_melgan\",\n",
    "    \"full_band_melgan\",\n",
    "    \"hifiGAN\",\n",
    "    \"melgan_large\",\n",
    "    \"waveglow\",\n",
    "]\n",
    "TRAINSETs = [\"ljspeech\", \"jsut\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9161bc07-a00e-4b88-b7eb-8d240cd8e539",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-07-14T06:54:02.299586Z",
     "iopub.status.busy": "2023-07-14T06:54:02.298596Z",
     "iopub.status.idle": "2023-07-14T06:54:02.334662Z",
     "shell.execute_reply": "2023-07-14T06:54:02.333641Z",
     "shell.execute_reply.started": "2023-07-14T06:54:02.299539Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WaveFake(Base):\n",
    "    def __init__(self, root_path=\"/usr/local/ay_data/dataset/0-deepfake/WaveFake\"):\n",
    "        \"\"\"\n",
    "        When crate a entry of WaveFake, it will read all the metadatas from the root_path\n",
    "\n",
    "        Args:\n",
    "            root_path: the path of WaveFake dataset. Note that the path must contain \"/WaveFake/\"\n",
    "        \"\"\"\n",
    "\n",
    "        self.root_path = root_path if not root_path.endswith(\"/\") else root_path[:-2]\n",
    "        self.data = self.read_metadata(self.root_path)\n",
    "        self.data[\"vocoder_label\"] = self.data[\"method\"].apply(\n",
    "            lambda x: 0 if (x == \"real\" or x not in VOCODERs) else VOCODERs.index(x) + 1\n",
    "        )\n",
    "\n",
    "        self.train_sets = [\"ljspeech\", \"jsut\"]\n",
    "\n",
    "        # self.read_emotion_label()\n",
    "    \n",
    "    def read_metadata(self, root_path):\n",
    "        \"\"\"\n",
    "        read all the metadatas of audio files from the root_path\n",
    "        \"\"\"\n",
    "\n",
    "        data_path = os.path.join(root_path, \"dataset_info.csv\")\n",
    "        if os.path.exists(data_path):\n",
    "            return pd.read_csv(data_path)\n",
    "\n",
    "        ## Step 1. read all audio paths\n",
    "        wav_paths = read_file_paths_from_folder(root_path, exts=[\"wav\"])\n",
    "        data = pd.DataFrame()\n",
    "        data[\"path\"] = wav_paths\n",
    "\n",
    "        ## Step 2. obtain the TTS method and their corresponding train set\n",
    "        ## train set contain:  [\"ljspeech\", \"jsut\"]\n",
    "        ## TTS method contain: ['multi_band_melgan', 'parallel_wavegan', 'full_band_melgan',\n",
    "        ##                     'hifiGAN', 'melgan', 'melgan_large', 'waveglow', 'real', 'tts']\n",
    "        ##         where 'real' means that the wav is real and is from the origianl train set for training TTS.\n",
    "\n",
    "        def get_trainSet_method(path):\n",
    "            trainSet_method = path.split(\"/WaveFake/\")[1].split(\"/\")[0]\n",
    "            trainSet = trainSet_method.split(\"_\")[0]\n",
    "            method = trainSet_method.split(trainSet + \"_\")[1]\n",
    "            return [trainSet, method]\n",
    "\n",
    "        data[[\"trainSet\", \"method\"]] = data.apply(\n",
    "            lambda x: tuple(get_trainSet_method(x[\"path\"])),\n",
    "            axis=1,\n",
    "            result_type=\"expand\",\n",
    "        )\n",
    "\n",
    "        pandarallel.initialize(progress_bar=True, nb_workers=20)\n",
    "        data[[\"fps\", \"length\"]] = data.parallel_apply(\n",
    "            lambda x: tuple(get_fps_len(x[\"path\"])), axis=1, result_type=\"expand\"\n",
    "        )\n",
    "\n",
    "        # Output the nubmer of audios for each sub-folder.\n",
    "        # print(data.groupby(['trainSet', 'method']).count().reset_index().to_markdown(index=False))\n",
    "\n",
    "        ## Step 3. save the metadatas\n",
    "        data[\"label\"] = data[\"path\"].apply(\n",
    "            lambda x: 1 if \"ljspeech_real\" in x or \"jsut_real\" in x else 0\n",
    "        )\n",
    "        data[\"id\"] = data[\"path\"].apply(\n",
    "            lambda x: os.path.basename(x)\n",
    "            .replace(\".wav\", \"\")\n",
    "            .replace(\"_generated\", \"\")\n",
    "            .replace(\"_gen\", \"\")\n",
    "        )\n",
    "\n",
    "        data.to_csv(data_path, index=False)\n",
    "        return data\n",
    "\n",
    "    def _get_sub_data(self, trainset, method):\n",
    "        \"\"\"\n",
    "        Given the trainset of Vocoders and the vocoder method, return the subdata\n",
    "        Args:\n",
    "            trainSet: the dataset for training the Vocoders\n",
    "            method: the vocoder method\n",
    "        \"\"\"\n",
    "        # print(trainSet, method)\n",
    "        if isinstance(trainset, int):\n",
    "            trainset = TRAINSETs[trainset]\n",
    "        if isinstance(method, int):\n",
    "            method = VOCODERs[method]\n",
    "\n",
    "        data = self.data\n",
    "        sub_data = data[(data[\"trainSet\"] == trainset) & (data[\"method\"] == method)]\n",
    "        return sub_data.reset_index(drop=True)\n",
    "\n",
    "    def get_sub_data(self, trainset: [list, str], methods: [list, str], contain_real=True) -> pd.DataFrame:\n",
    "        trainset = to_list(trainset)\n",
    "        methods = to_list(methods)\n",
    "        if contain_real:\n",
    "            methods = methods + ['real']\n",
    "        data = []\n",
    "        for _trainset in trainset:\n",
    "            for _method in methods:\n",
    "                _data = self._get_sub_data(_trainset, _method)\n",
    "                data.append(_data)\n",
    "        data = pd.concat(data).reset_index(drop=True)\n",
    "        return data\n",
    "\n",
    "    def split_data(\n",
    "        self,\n",
    "        data: pd.DataFrame = None,\n",
    "        splits=[0.6, 0.2, 0.2],\n",
    "        refer=\"id\",\n",
    "        return_list=False,\n",
    "    ):\n",
    "        if data is None:\n",
    "            data = self.data\n",
    "        if refer is None:\n",
    "            sub_datas = DF_spliter.split_df(data, splits)\n",
    "        else:\n",
    "            sub_datas = DF_spliter.split_by_number_and_column(data, splits, refer=refer)\n",
    "\n",
    "        if return_list:\n",
    "            return sub_datas\n",
    "\n",
    "        return Namespace(\n",
    "            train=sub_datas[0],\n",
    "            test=sub_datas[-1],\n",
    "            val=None if len(splits) == 2 else sub_datas[1],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ae2e44d-23dd-42ad-a8f8-491443881260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T06:56:09.607958Z",
     "iopub.status.busy": "2023-07-14T06:56:09.607239Z",
     "iopub.status.idle": "2023-07-14T06:56:10.630573Z",
     "shell.execute_reply": "2023-07-14T06:56:10.629844Z",
     "shell.execute_reply.started": "2023-07-14T06:56:09.607912Z"
    },
    "tags": [
     "active-ipynb",
     "style-student"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = WaveFake(root_path=\"/usr/local/ay_data/dataset/0-deepfake/WaveFake\")\n",
    "data = dataset.get_sub_data(trainset=0, methods=[0, 1, 2, 3, 4, 5, 6])\n",
    "splits = [64_000, 16_000, 24_800]\n",
    "datas = dataset.split_data(data, splits)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
