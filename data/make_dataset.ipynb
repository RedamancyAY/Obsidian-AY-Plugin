{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b5f1d3c-81a1-4f8c-97f2-a9357ff39874",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T02:20:19.941247Z",
     "iopub.status.busy": "2024-11-04T02:20:19.940562Z",
     "iopub.status.idle": "2024-11-04T02:20:19.994272Z",
     "shell.execute_reply": "2024-11-04T02:20:19.992337Z",
     "shell.execute_reply.started": "2024-11-04T02:20:19.941184Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42caf32d-f8a4-495d-bc37-528c47257ce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T02:20:21.465829Z",
     "iopub.status.busy": "2024-11-04T02:20:21.464793Z",
     "iopub.status.idle": "2024-11-04T02:20:23.779615Z",
     "shell.execute_reply": "2024-11-04T02:20:23.778399Z",
     "shell.execute_reply.started": "2024-11-04T02:20:21.465723Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "from typing import NamedTuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset, default_collate\n",
    "from torchvision.transforms import Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61313dd-61d5-4c53-83e4-a406d85c0ec7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T02:20:30.266575Z",
     "iopub.status.busy": "2024-11-04T02:20:30.266232Z",
     "iopub.status.idle": "2024-11-04T02:20:39.105968Z",
     "shell.execute_reply": "2024-11-04T02:20:39.104925Z",
     "shell.execute_reply.started": "2024-11-04T02:20:30.266545Z"
    }
   },
   "outputs": [],
   "source": [
    "from ay2.datasets.audio import (\n",
    "    ASV2019LA_AudioDs,\n",
    "    ASV2021_AudioDs,\n",
    "    ASV2021LA_AudioDs,\n",
    "    Codecfake_AudioDs,\n",
    "    DECRO_AudioDs,\n",
    "    InTheWild_AudioDs,\n",
    "    LibriSeVoc_AudioDs,\n",
    "    MLAAD_AudioDs,\n",
    "    VGGSound_AudioDs,\n",
    "    WaveFake_AudioDs,\n",
    "    Codecfake_AudioDs,\n",
    "    ASVSpoof5_AudioDs\n",
    ")\n",
    "from ay2.tools import color_print\n",
    "from ay2.torch.transforms.audio import AudioRawBoost, SpecAugmentTransform_Wave\n",
    "from ay2.torchaudio.transforms import LFCC, RandomBackgroundNoise, RandomNoise, RawBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1865e9-d5be-4944-85f2-bea42076993a",
   "metadata": {
    "editable": true,
    "lines_to_end_of_cell_marker": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # from .datasets import ADD2023, LAV_DF_Audio, LibriSeVoc, WaveFake, DECRO\n",
    "    from .tools import WaveDataset\n",
    "except ImportError:\n",
    "    # from datasets import ADD2023, LAV_DF_Audio, LibriSeVoc, WaveFake, DECRO\n",
    "    from tools import WaveDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d00d727-ff90-4381-b860-a0b1a3c65f50",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Make audio splits (DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3efdf-83e4-411d-b943-4a285fe0deff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def get_emotion_labels(\n",
    "    data: pd.DataFrame,\n",
    "    emotion_df_path=\"/home/ay/data/DATA/2-datasets/1-df-audio/emotions.csv\",\n",
    "):\n",
    "    emotions = pd.read_csv(emotion_df_path)\n",
    "    emotions[\"emotion_label\"] = emotions[\"index\"]\n",
    "    emotions = emotions[[\"audio_path\", \"emotion_label\"]]\n",
    "    data = pd.merge(data, emotions, how=\"left\", on=\"audio_path\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7539c5f-879d-410f-a3d5-7429f75baecb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88800f5-a634-4e11-a72a-6f32faf87826",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def get_InTheWild_data(\n",
    "    root_path=\"/home/ay/data/DATA/2-datasets/1-df-audio/release_in_the_wild\",\n",
    "):\n",
    "    dataset = InTheWild_AudioDs(root_path=root_path)\n",
    "    return dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1079fa-61d3-4f09-8da7-04206123e30b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset = InTheWild_AudioDs(root_path=\"/home/ay/data/DATA/2-datasets/1-df-audio/release_in_the_wild\")\n",
    "# dataset.data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dffe00-730e-4f56-934b-c4129cbfcd1d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### WaveFake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024a8ac3-0ee7-4b8e-ac76-c3f36f9ec872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_WaveFake_JP(root_path=\"/home/ay/data/DATA/2-datasets/1-df-audio/WaveFake\"):\n",
    "    dataset = WaveFake_AudioDs(root_path)\n",
    "    data_train = dataset.get_sub_data(corpus=1, methods=[1, 2])\n",
    "    train, val = dataset.split_data(data_train, splits=[0.8, 0.2], return_list=True, refer=\"id\")\n",
    "    data_splits = Namespace(train=train, val=val)\n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b66f636-2721-443f-ba84-58d4e471fa3d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def make_WaveFake(cfg):\n",
    "    dataset = WaveFake_AudioDs(root_path=cfg.root_path)\n",
    "    # dataset.data = get_emotion_labels(dataset.data)\n",
    "\n",
    "    if cfg.task == \"inner_eval\":\n",
    "        color_print(\"WaveFake task: inner evaluation\")\n",
    "        data = dataset.get_sub_data(corpus=cfg.corpus, methods=cfg.methods)\n",
    "        data_splits = dataset.split_data(data, splits=cfg.splits, refer=\"id\")\n",
    "    elif cfg.task == \"cross_lang\":\n",
    "        color_print(\"WaveFake task: cross language evaluation\")\n",
    "\n",
    "        task_cfg = cfg.task_cfg\n",
    "        data_train = dataset.get_sub_data(corpus=task_cfg.train.corpus, methods=task_cfg.train.methods)\n",
    "        train, val = dataset.split_data(data_train, splits=task_cfg.train.splits, return_list=True, refer=\"id\")\n",
    "        test = dataset.get_sub_data(corpus=task_cfg.test.corpus, methods=task_cfg.test.methods)\n",
    "        data_splits = Namespace(train=train, val=val, test=test)\n",
    "    elif cfg.task == \"cross_method\":\n",
    "        color_print(\"WaveFake task: cross method\")\n",
    "\n",
    "        task_cfg = cfg.task_cfg\n",
    "        # get real data, and split it into train/val/test\n",
    "        data_real = dataset._get_sub_data(task_cfg.train.corpus, \"real\")\n",
    "        real_train, real_val, real_test = dataset.split_data(\n",
    "            data_real, splits=[0.6, 0.2, 0.2], return_list=True, refer=\"id\"\n",
    "        )\n",
    "\n",
    "        data_train = dataset.get_sub_data(\n",
    "            corpus=task_cfg.train.corpus,\n",
    "            methods=task_cfg.train.methods,\n",
    "            contain_real=False,\n",
    "        )\n",
    "        train, val = dataset.split_data(data_train, splits=task_cfg.train.splits, return_list=True, refer=\"id\")\n",
    "        test = [\n",
    "            dataset.get_sub_data(corpus=_cfg.corpus, methods=_cfg.methods, contain_real=False) for _cfg in task_cfg.test\n",
    "        ]\n",
    "        train = pd.concat([train, real_train], ignore_index=True)\n",
    "        val = pd.concat([val, real_val], ignore_index=True)\n",
    "        test = [pd.concat([_test, real_test], ignore_index=True) for _test in test]\n",
    "        data_splits = Namespace(train=train, val=val, test=test)\n",
    "\n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c8e07-5790-4f0b-b932-699edda65fae",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### LibriSeVoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f170c69-1973-44b4-9718-ec687d356a4c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def make_LibriSeVoc(cfg):\n",
    "    dataset = LibriSeVoc_AudioDs(root_path=cfg.ROOT_PATHs.LibriSeVoc)\n",
    "    # dataset.data = get_emotion_labels(dataset.data)\n",
    "\n",
    "    if cfg.task == \"inner_eval\":\n",
    "        color_print(\"LibriSeVoc task: inner evaluation\")\n",
    "\n",
    "        data = dataset.get_sub_data(methods=cfg.methods)\n",
    "        data_splits = dataset.split_data(data, splits=cfg.splits, refer=\"id\")\n",
    "    elif cfg.task == \"cross_method\":\n",
    "        color_print(\"LibriSeVoc task: cross method evaluation\")\n",
    "        task_cfg = cfg.task_cfg\n",
    "\n",
    "        # get real data, and split it into train/val/test\n",
    "        data_real = dataset.get_sub_data([], contain_real=True)\n",
    "        real_train, real_val, real_test = dataset.split_data(\n",
    "            data_real, splits=[0.6, 0.2, 0.2], return_list=True, refer=\"id\"\n",
    "        )\n",
    "\n",
    "        data_train = dataset.get_sub_data(methods=task_cfg.train.methods, contain_real=False)\n",
    "        train, val = dataset.split_data(data_train, splits=task_cfg.train.splits, return_list=True, refer=\"id\")\n",
    "        test = [dataset.get_sub_data(methods=_cfg.methods, contain_real=False) for _cfg in task_cfg.test]\n",
    "        train = pd.concat([train, real_train], ignore_index=True)\n",
    "        val = pd.concat([val, real_val], ignore_index=True)\n",
    "        test = [pd.concat([_test, real_test], ignore_index=True) for _test in test]\n",
    "\n",
    "        data_splits = Namespace(train=train, val=val, test=test)\n",
    "    elif cfg.task == \"cross_dataset\":\n",
    "        color_print(\"LibriSeVoc task: cross dataset evaluation\")\n",
    "        task_cfg = cfg.task_cfg\n",
    "        data_train = dataset.get_sub_data(methods=task_cfg.train.methods)\n",
    "        train, val = dataset.split_data(data_train, splits=task_cfg.train.splits, return_list=True, refer=\"id\")\n",
    "        test = []\n",
    "        for _cfg in task_cfg.test:\n",
    "            if _cfg.dataset.lower() == \"wavefake\":\n",
    "                dataset2 = WaveFake_AudioDs(root_path=cfg.ROOT_PATHs.WaveFake)\n",
    "                _data = dataset2.get_sub_data(corpus=_cfg.corpus, methods=_cfg.methods)\n",
    "                test.append(_data)\n",
    "        test.append(get_InTheWild_data())\n",
    "        test.append(get_DECRO_test_splits(language=\"en\"))\n",
    "        test.append(get_DECRO_test_splits(language=\"cn\"))\n",
    "        # test += get_ASV2021_test_splits()\n",
    "        data_splits = Namespace(train=train, val=val, test=test)\n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1e4b1-9a40-44b9-b228-a193b2aa6a0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T11:35:09.247018Z",
     "iopub.status.busy": "2024-01-04T11:35:09.246332Z",
     "iopub.status.idle": "2024-01-04T11:35:09.255194Z",
     "shell.execute_reply": "2024-01-04T11:35:09.253131Z",
     "shell.execute_reply.started": "2024-01-04T11:35:09.246951Z"
    },
    "lines_to_next_cell": 2
   },
   "source": [
    "### DECRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a8207-1494-47bc-9698-a54b623afef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DECRO_test_splits(root_path=\"/home/ay/data/DATA/2-datasets/1-df-audio/DECRO\", language=\"en\"):\n",
    "    dataset = DECRO_AudioDs(root_path=root_path)\n",
    "    en_splits = dataset.get_splits(language=\"en\")\n",
    "    ch_splits = dataset.get_splits(language=\"ch\")\n",
    "    if language == \"en\":\n",
    "        data = en_splits.test\n",
    "    else:\n",
    "        data = ch_splits.test\n",
    "\n",
    "    data[\"vocoder_label_org\"] = data[\"vocoder_label\"]\n",
    "    data[\"vocoder_label\"] = 0\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_DECRO_splits(root_path=\"/home/ay/data/DATA/2-datasets/1-df-audio/DECRO\"):\n",
    "    dataset = DECRO_AudioDs(root_path=root_path)\n",
    "    en_splits = dataset.get_splits(language=\"en\")\n",
    "    ch_splits = dataset.get_splits(language=\"ch\")\n",
    "    return en_splits, ch_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759c656a-c11b-4de0-8f50-09331199458a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def make_DECRO(cfg):\n",
    "    dataset = DECRO_AudioDs(root_path=cfg.root_path)\n",
    "    # dataset.data = get_emotion_labels(dataset.data)\n",
    "\n",
    "    en_splits = dataset.get_splits(language=\"en\")\n",
    "    ch_splits = dataset.get_splits(language=\"ch\")\n",
    "\n",
    "    if cfg.task == \"en->ch\":\n",
    "        color_print(\"DECRO task: en->ch\")\n",
    "        train, val, test = (\n",
    "            en_splits.train,\n",
    "            en_splits.val,\n",
    "            [en_splits.train, ch_splits.test, get_InTheWild_data()],\n",
    "        )\n",
    "    else:\n",
    "        color_print(\"DECRO task: ch->en\")\n",
    "        train, val, test = (\n",
    "            ch_splits.train,\n",
    "            ch_splits.val,\n",
    "            [ch_splits.test, en_splits.test, get_InTheWild_data()],\n",
    "        )\n",
    "    data_splits = Namespace(train=train, val=val, test=test)\n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82da1971-2cac-4905-ae1d-be183b3d3185",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### ASV 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20707505-f865-49d0-9768-4f468ebf63fc",
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "def make_ASV2019(cfg):\n",
    "    dataset = ASV2019LA_AudioDs(root_path=cfg.root_path)\n",
    "    if cfg.task == \"inner_eval\":\n",
    "        color_print(\"ASVspoof 2021 task: inner evaluation\")\n",
    "        data_splits = dataset.get_splits()\n",
    "\n",
    "    data_splits.test = [data_splits.test]\n",
    "    data_splits.test += get_ASV2021_whole_test_split(cfg=cfg)\n",
    "    data_splits.test += get_ASV2021_test_splits(cfg=cfg)\n",
    "    return data_splits\n",
    "\n",
    "\n",
    "def get_ASV2019_test_split(root_path=\"/home/ay/data/0-原始数据集/ASV2019\"):\n",
    "    dataset = ASV2019LA_AudioDs(root_path=root_path)\n",
    "    data_splits = dataset.get_splits()\n",
    "    return data_splits.test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd99ad85-835b-4afb-a813-5f4620c3800e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### ASV 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a196609-312c-4f04-9f2b-09b852ecd71d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def get_ASV2021_test_splits(root_path=\"/home/ay/ASV2021\", cfg=None):\n",
    "    dataset = ASV2021_AudioDs(root_path=root_path)\n",
    "    data_splits = dataset.get_test_splits()\n",
    "\n",
    "    \n",
    "    if cfg is None:\n",
    "        return data_splits\n",
    "\n",
    "    \n",
    "    args = eval(cfg.runtime_args)\n",
    "    if args.filter_ASV2021:\n",
    "        AA = [\"A07\", \"A08\", \"A09\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\", \"A17\", \"A18\", \"A19\"]\n",
    "        data_splits = [data.query(f\"attack not in {AA}\").reset_index(drop=True) for data in data_splits]\n",
    "\n",
    "\n",
    "    return data_splits\n",
    "\n",
    "\n",
    "def get_ASV2021_whole_test_split(root_path=\"/home/ay/ASV2021\", cfg=None):\n",
    "    dataset = ASV2021_AudioDs(root_path=root_path)\n",
    "    test = dataset.get_whole_test_split()\n",
    "    data_splits = [test]\n",
    "\n",
    "    if cfg is None:\n",
    "        return data_splits\n",
    "    \n",
    "    args = eval(cfg.runtime_args)\n",
    "    if args.filter_ASV2021:\n",
    "        AA = [\"A07\", \"A08\", \"A09\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\", \"A17\", \"A18\", \"A19\"]\n",
    "        data_splits = [data.query(f\"attack not in {AA}\").reset_index(drop=True) for data in data_splits]\n",
    "    return data_splits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d2c19-c46e-4753-8e09-21fdc3ba906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ASV2021(cfg):\n",
    "    dataset = ASV2021_AudioDs(root_path=cfg.root_path)\n",
    "    if cfg.task == \"inner_eval\":\n",
    "        color_print(\"ASVspoof 2021 DF task: inner evaluation\")\n",
    "        data_splits = dataset.get_splits()\n",
    "\n",
    "    data_splits.test += get_ASV2021_whole_test_split(root_path=cfg.root_path)\n",
    "\n",
    "    args = eval(cfg.runtime_args)\n",
    "    if args.filter_ASV2021:\n",
    "        AA = [\"A07\", \"A08\", \"A09\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\", \"A17\", \"A18\", \"A19\"]\n",
    "        data_splits.test[1:] = [data.query(f\"attack not in {AA}\").reset_index(drop=True) for data in data_splits.test[1:]]\n",
    "    \n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8043c98c-7453-47e3-b485-f6b2ed639acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ASV2021_LA(cfg):\n",
    "    dataset = ASV2021LA_AudioDs(root_path=cfg.root_path)\n",
    "    if cfg.task == \"inner_eval\":\n",
    "        color_print(\"ASVspoof 2021 LA task: inner evaluation\")\n",
    "        data_splits = dataset.get_splits()\n",
    "\n",
    "    data_splits.test = [data_splits.test]\n",
    "    data_splits.test.append(get_ASV2019_test_split())\n",
    "    data_splits.test += get_ASV2021_whole_test_split(cfg=cfg)\n",
    "    data_splits.test += get_ASV2021_test_splits(cfg=cfg)\n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca0ecaa-75e2-4882-91da-2dd0759f2872",
   "metadata": {},
   "source": [
    "### Codecfake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef9482-8634-441f-9fb9-579c451c3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Codecfake(cfg):\n",
    "    dataset = Codecfake_AudioDs(root_path=cfg.root_path)\n",
    "    color_print(\"Load dataset splits of Codecfake\")\n",
    "    data_splits = dataset.get_splits()\n",
    "\n",
    "    data_splits.test.append(get_ASV2019_test_split())\n",
    "    data_splits.test += get_ASV2021_whole_test_split(cfg=cfg)\n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd81eb14-bef1-49ad-92fd-c6683e067ae3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### VGG Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea58f36-7028-4dde-b7e2-258f8a4d5989",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def make_VGGSound(cfg):\n",
    "    dataset = VGGSound_AudioDs(root_path=cfg.root_path)\n",
    "    color_print(\"VGGSound: load splits\")\n",
    "    data_splits = dataset.get_splits()  # only train and test splits\n",
    "    data_splits.val = data_splits.test\n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc075fe-66aa-4e6a-a773-49057a3d7ced",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### MLAAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f605fa-4c18-4f8c-a1e3-e153e87fcfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_MLAAD(cfg):\n",
    "    def append_test(_data_splits):\n",
    "        _data_splits.test.append(get_InTheWild_data())\n",
    "        _data_splits.test.append(get_DECRO_test_splits(language=\"en\"))\n",
    "        _data_splits.test.append(get_DECRO_test_splits(language=\"cn\"))\n",
    "\n",
    "    dataset = MLAAD_AudioDs(root_path=cfg.root_path)\n",
    "    color_print(\"MLAAD: load splits\")\n",
    "    if cfg.task == \"cross_lang\":\n",
    "        data_splits = dataset.get_splits(language_list=[\"en\", \"de\", \"es\"])\n",
    "        append_test(data_splits)\n",
    "    elif cfg.task == \"de_es_ru\":\n",
    "        print(\"MLDDA, load DE, ES, RU subsets for training!!!!!!!\")\n",
    "        data_splits = dataset.get_splits(language_list=[\"de\", \"es\", \"ru\"])\n",
    "        append_test(data_splits)\n",
    "    elif cfg.task == \"DECRO\":\n",
    "        print(\"MLDDA, load DECRO and WaveFake subsets for training!!!!!!!\")\n",
    "        data_splits = dataset.get_splits(language_list=[])\n",
    "        append_test(data_splits)\n",
    "        en_splits, ch_splits = get_DECRO_splits()\n",
    "        jp_splits = get_WaveFake_JP()\n",
    "        data_splits.train = pd.concat([en_splits.train, ch_splits.train, jp_splits.train], ignore_index=True)\n",
    "        data_splits.val = pd.concat([en_splits.val, ch_splits.val, jp_splits.val], ignore_index=True)\n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d636c27-9e62-4247-8e23-583c8d4769fe",
   "metadata": {},
   "source": [
    "### Codecfake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a09e410a-287d-44eb-a2af-4f329ec4f7bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T02:21:58.478572Z",
     "iopub.status.busy": "2024-11-04T02:21:58.478165Z",
     "iopub.status.idle": "2024-11-04T02:21:58.533991Z",
     "shell.execute_reply": "2024-11-04T02:21:58.532065Z",
     "shell.execute_reply.started": "2024-11-04T02:21:58.478537Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_Codecfake(cfg):\n",
    "\n",
    "    dataset = Codecfake_AudioDs(root_path=cfg.root_path)\n",
    "    data_splits = dataset.get_splits()\n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be02d6b2",
   "metadata": {},
   "source": [
    "### ASVSpoof5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f2be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ASVSpoof5(cfg):\n",
    "    dataset = ASVSpoof5_AudioDs(root_path=cfg.root_path)\n",
    "    data_splits = dataset.get_splits(\n",
    "        train_val_rate_in_train_tsv=cfg.train_val_rate_in_train_tsv,\n",
    "        use_dev_as_test=cfg.use_dev_as_test, \n",
    "        use_both_dev_test_for_test=cfg.use_both_dev_test_for_test\n",
    "    )\n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a370d0-db7c-4ae5-8246-3cb50cd0c649",
   "metadata": {},
   "source": [
    "## Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740837e8-c1e4-4585-90b4-c600fd42c74a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "MAKE_DATASETS = {\n",
    "    \"WaveFake\": make_WaveFake,\n",
    "    \"LibriSeVoc\": make_LibriSeVoc,\n",
    "    \"DECRO\": make_DECRO,\n",
    "    \"ASV2021\": make_ASV2021,\n",
    "    \"ASV2021_LA\": make_ASV2021_LA,\n",
    "    \"ASV2019_LA\": make_ASV2019,\n",
    "    \"VGGSound\": make_VGGSound,\n",
    "    \"MLAAD\": make_MLAAD,\n",
    "    \"Codecfake\": make_Codecfake,\n",
    "    \"ASVSpoof5\": make_ASVSpoof5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea73119-1996-4b96-9dee-6c8a85f153f1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Build DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20eba88-536b-4127-8bf6-344b348bc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature(cfg):\n",
    "    if cfg.audio_feature == \"LFCC\":\n",
    "        return LFCC()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ad84e5-2537-4e33-aa1b-ae8ae57ecfec",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb75dcd0-5e2f-42a6-9ec6-9c6033c8fdfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T02:47:21.382320Z",
     "iopub.status.busy": "2024-10-16T02:47:21.381959Z",
     "iopub.status.idle": "2024-10-16T02:47:23.760387Z",
     "shell.execute_reply": "2024-10-16T02:47:23.759761Z",
     "shell.execute_reply.started": "2024-10-16T02:47:21.382278Z"
    }
   },
   "outputs": [],
   "source": [
    "from ay2.torchaudio.transforms import RandomAudioCompression,RandomAudioCompressionSpeedChanging\n",
    "from ay2.torchaudio.transforms.self_operation import (\n",
    "    AudioToTensor,\n",
    "    CentralAudioClip,\n",
    "    RandomAudioClip,\n",
    "    RandomPitchShift,\n",
    "    RandomSpeed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c1127-a38f-41e4-ab69-1a267cbe1205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_augmentations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a57c5-fa33-4b54-95ba-0ee0753e9a94",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def build_transforms(cfg=None, args=None):\n",
    "    # t1 = RandomNoise(snr_min_db=10.0, snr_max_db=120.0, p=1.0)\n",
    "    # # t = RawBoost(algo=[5], p=0.5)\n",
    "    # t2 = RandomSpeed(min_speed=0.5, max_speed=2.0, p=1.0)\n",
    "    # t3 = RandomPitchShift(p=1.0)\n",
    "\n",
    "    # sr = 16000\n",
    "    # num_samples=48000\n",
    "    # transforms = [\n",
    "    #     RandomResizedCrop(n_samples=num_samples),\n",
    "    #     RandomApply([PolarityInversion()], p=0.8),\n",
    "    #     RandomApply([Noise(min_snr=0.001, max_snr=0.005)], p=0.3),\n",
    "    #     RandomApply([Gain()], p=0.2),\n",
    "    #     HighLowPass(sample_rate=sr), # this augmentation will always be applied in this aumgentation chain!\n",
    "    #     RandomApply([Delay(sample_rate=sr)], p=0.5),\n",
    "    #     RandomApply([PitchShift(\n",
    "    #         n_samples=num_samples,\n",
    "    #         sample_rate=sr\n",
    "    #     )], p=0.4),\n",
    "    #     RandomApply([Reverb(sample_rate=sr)], p=0.3)\n",
    "    # ]\n",
    "\n",
    "    # return {\n",
    "    #     \"train\": transforms,\n",
    "    #     \"val\": [\n",
    "    #         CentralAudioClip(length=48000),\n",
    "    #         AudioToTensor(),\n",
    "    #     ],\n",
    "    # }\n",
    "\n",
    "    res = {\n",
    "        \"train\": [\n",
    "            # RandomSpeed(min_speed=0.5, max_speed=2.0, p=0.5),\n",
    "            # RandomAudioCompression(p=0.9),\n",
    "            # RandomSpeed(min_speed=0.5, max_speed=2.0, p=1.0),\n",
    "            RandomAudioClip(length=48000),\n",
    "            RandomNoise(snr_min_db=10.0, snr_max_db=120.0, p=1.0),\n",
    "            AudioToTensor(),\n",
    "            # RandomApply([PitchShift(n_samples=48000, sample_rate=16000)], p=0.5),\n",
    "            # RandomPitchShift(p=0.5),\n",
    "        ],\n",
    "        \"val\": [\n",
    "            CentralAudioClip(length=48000),\n",
    "            AudioToTensor(),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    if args is not None and args.cfg.startswith(\"Ours/ResNet\"):\n",
    "        if 'ASV2021' in args.cfg:\n",
    "            res[\"train\"] = [\n",
    "                RandomSpeed(min_speed=0.5, max_speed=2.0, p=1.0),\n",
    "            ] + res[\"train\"]\n",
    "        else:\n",
    "            res[\"train\"] = [\n",
    "                # RandomAudioCompression(p=0.9),\n",
    "                # RandomSpeed(min_speed=0.5, max_speed=2.0, p=1.0),\n",
    "                RandomAudioCompressionSpeedChanging(p_compression=0.9, sample_rate=16000, p_speed=1.0, min_speed=0.5, max_speed=2.0)\n",
    "            ] + res[\"train\"]\n",
    "    else:\n",
    "        res[\"train\"].append(RandomApply([PitchShift(n_samples=48000, sample_rate=16000)], p=0.5))\n",
    "        \n",
    "    \n",
    "\n",
    "    if args is not None and args.test_noise:\n",
    "        res[\"test_noise\"] = [\n",
    "            CentralAudioClip(length=48000),\n",
    "            RandomBackgroundNoise(\n",
    "                16000,\n",
    "                noise_dir=\"/home/ay/data/0-原始数据集/musan/noise\",\n",
    "                p=1.0,\n",
    "                min_snr_db=args.test_noise_level,\n",
    "                max_snr_db=args.test_noise_level,\n",
    "                noise_type=args.test_noise_type,\n",
    "            ),\n",
    "            AudioToTensor(),\n",
    "        ]\n",
    "\n",
    "    # if args.cfg.startswith('MPE_LCNN'):\n",
    "    #     from ay2.torchaudio.transforms import MPE_LFCC\n",
    "    #     for key in res:\n",
    "    #         res[key].append(MPE_LFCC())\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8d22ee-9e5f-48cc-8ec8-6ea89dca2f6b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Common Opeations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f4accf-4165-4fb7-af15-a4afea7a5ad0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def build_dataloader(data: pd.DataFrame, cfg, is_training: bool = True, args=None):\n",
    "    transforms = build_transforms(cfg.transforms, args=args)\n",
    "    transform = transforms[\"train\"] if is_training else transforms[\"val\"]\n",
    "\n",
    "    _ds = WaveDataset(\n",
    "        data,\n",
    "        sample_rate=cfg.sample_rate,\n",
    "        normalize=True,\n",
    "        transform=transform,\n",
    "        dtype=\"tensor\",\n",
    "    )\n",
    "\n",
    "    if not is_training and cfg.test_batch_size > 0:\n",
    "        batch_size = cfg.test_batch_size\n",
    "    else:\n",
    "        batch_size = cfg.batch_size\n",
    "\n",
    "    _dl = DataLoader(\n",
    "        _ds,\n",
    "        batch_size=batch_size,\n",
    "        # num_workers=cfg.num_workers,\n",
    "        num_workers=10,\n",
    "        pin_memory=True,\n",
    "        shuffle=True if is_training else False,\n",
    "        # shuffle=True,\n",
    "        prefetch_factor=2,\n",
    "        drop_last=True if is_training else bool(args.drop_last),\n",
    "    )\n",
    "    return _ds, _dl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1546f1-3d1a-4329-8eb7-adb483e9cd9b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Door"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001bf0b4-2f78-4dfc-b90c-911436def412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sample_dataset(data, column=\"label\"):\n",
    "    n_fake = len(data[data[column] == 0])\n",
    "    n_real = len(data[data[column] == 1])\n",
    "    if n_fake == n_real:\n",
    "        return data\n",
    "    if n_fake > n_real:\n",
    "        sampled = data[data[column] == 1].sample(n=n_fake - n_real, replace=True)\n",
    "        balanced_data = pd.concat([data, sampled])\n",
    "    else:\n",
    "        sampled = data[data[column] == 0].sample(n=n_real - n_fake, replace=True)\n",
    "        balanced_data = pd.concat([data, sampled])\n",
    "\n",
    "    balanced_data = balanced_data.copy().reset_index(drop=True)\n",
    "    return balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f793fc65-14a3-4beb-b611-5ec66e2e18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_audio_splits_label_distribution(audio_splits):\n",
    "    res = {}\n",
    "    for _split in [\"train\", \"val\", \"test\"]:\n",
    "        _data = getattr(audio_splits, _split)\n",
    "        res[_split] = \"\"\n",
    "        if isinstance(_data, list):\n",
    "            for _data2 in _data:\n",
    "                tmp = _data2.groupby(\"label\").count()\n",
    "                num_0 = tmp.loc[0][0] if 0 in tmp.index else 0\n",
    "                num_1 = tmp.loc[1][0] if 1 in tmp.index else 0\n",
    "                res[_split] += f\" {num_0}/{num_1}\"\n",
    "        else:\n",
    "            tmp = _data.groupby(\"label\").count()\n",
    "            num_0 = tmp.loc[0][0] if 0 in tmp.index else 0\n",
    "            num_1 = tmp.loc[1][0] if 1 in tmp.index else 0\n",
    "            res[_split] += f\" {num_0}/{num_1}\"\n",
    "\n",
    "    color_print(f\"Fake/Real label distribution in train/val/test: {res['train']}, {res['val']}, {res['test']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b1e8ee-a313-4bdc-82d1-3de2ed4a39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(cfg, args=None):\n",
    "\n",
    "    cfg.dataset_cfg.runtime_args = str(args)\n",
    "    \n",
    "    # make audio splits (pd.DataFrame)\n",
    "    audio_splits = MAKE_DATASETS[cfg.name](cfg.dataset_cfg)\n",
    "    audio_splits.train = over_sample_dataset(audio_splits.train, column=\"label\")\n",
    "\n",
    "    print_audio_splits_label_distribution(audio_splits)\n",
    "\n",
    "    # make dataset and dataloaders\n",
    "    train_ds, train_dl = build_dataloader(audio_splits.train, cfg, is_training=True, args=args)\n",
    "    train_ds2, train_dl2 = build_dataloader(audio_splits.train, cfg, is_training=False, args=args)\n",
    "    val_ds, val_dl = build_dataloader(audio_splits.val, cfg, is_training=False, args=args)\n",
    "    if isinstance(audio_splits.test, list):\n",
    "        test_ds, test_dl = [], []\n",
    "        for _test in audio_splits.test:\n",
    "            _ds, _dl = build_dataloader(_test, cfg, is_training=False, args=args)\n",
    "            test_ds.append(_ds)\n",
    "            test_dl.append(_dl)\n",
    "    else:\n",
    "        test_ds, test_dl = build_dataloader(audio_splits.test, cfg, is_training=False, args=args)\n",
    "\n",
    "    # collect all dataloaders\n",
    "    ds = Namespace(train=train_ds, val=val_ds, test=test_ds, train_wo_transform=train_ds2)\n",
    "    dl = Namespace(train=train_dl, val=val_dl, test=test_dl, train_wo_transform=train_dl2)\n",
    "\n",
    "    print(args)\n",
    "    if args is not None and args.test_noise:\n",
    "        color_print(\"!!!!Test robustness: Load audio with background noise\")\n",
    "        test_noise = build_transforms(args=args)[\"test_noise\"]\n",
    "        if isinstance(dl.test, list):\n",
    "            for _dl in dl.test:\n",
    "                _dl.dataset.transform = test_noise\n",
    "            # dl.test = dl.test[1]\n",
    "        else:\n",
    "            dl.test.transform = test_noise\n",
    "\n",
    "    return ds, dl"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
