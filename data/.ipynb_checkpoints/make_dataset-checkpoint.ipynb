{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f1d3c-81a1-4f8c-97f2-a9357ff39874",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42caf32d-f8a4-495d-bc37-528c47257ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "from typing import NamedTuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset, default_collate\n",
    "from torchvision.transforms import Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61313dd-61d5-4c53-83e4-a406d85c0ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ay2.datasets.audio import (\n",
    "    DECRO_AudioDs,\n",
    "    InTheWild_AudioDs,\n",
    "    LibriSeVoc_AudioDs,\n",
    "    WaveFake_AudioDs,\n",
    ")\n",
    "from ay2.tools import color_print\n",
    "from ay2.torch.transforms.audio import AudioRawBoost, SpecAugmentTransform_Wave\n",
    "from ay2.torchaudio.transforms import LFCC, RandomNoise, RawBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1865e9-d5be-4944-85f2-bea42076993a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # from .datasets import ADD2023, LAV_DF_Audio, LibriSeVoc, WaveFake, DECRO\n",
    "    from .tools import WaveDataset\n",
    "except ImportError:\n",
    "    # from datasets import ADD2023, LAV_DF_Audio, LibriSeVoc, WaveFake, DECRO\n",
    "    from tools import WaveDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d00d727-ff90-4381-b860-a0b1a3c65f50",
   "metadata": {},
   "source": [
    "# Make audio splits (DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3efdf-83e4-411d-b943-4a285fe0deff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion_labels(\n",
    "    data: pd.DataFrame,\n",
    "    emotion_df_path=\"/home/ay/data/DATA/2-datasets/1-df-audio/emotions.csv\",\n",
    "):\n",
    "    emotions = pd.read_csv(emotion_df_path)\n",
    "    emotions[\"emotion_label\"] = emotions[\"index\"]\n",
    "    emotions = emotions[[\"audio_path\", \"emotion_label\"]]\n",
    "    data = pd.merge(data, emotions, how=\"left\", on=\"audio_path\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7539c5f-879d-410f-a3d5-7429f75baecb",
   "metadata": {},
   "source": [
    "## Different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88800f5-a634-4e11-a72a-6f32faf87826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_InTheWild_data(\n",
    "    root_path=\"/home/ay/data/DATA/2-datasets/1-df-audio/release_in_the_wild\",\n",
    "):\n",
    "    dataset = InTheWild_AudioDs(root_path=root_path)\n",
    "    return dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1079fa-61d3-4f09-8da7-04206123e30b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset = InTheWild_AudioDs(root_path=\"/home/ay/data/DATA/2-datasets/1-df-audio/release_in_the_wild\")\n",
    "# dataset.data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dffe00-730e-4f56-934b-c4129cbfcd1d",
   "metadata": {},
   "source": [
    "### WaveFake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052ada3-9937-4c06-a4dc-6414914d4c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_WaveFake(cfg):\n",
    "    dataset = WaveFake_AudioDs(root_path=cfg.root_path)\n",
    "    # dataset.data = get_emotion_labels(dataset.data)\n",
    "\n",
    "    if cfg.task == \"inner_eval\":\n",
    "        color_print(\"WaveFake task: inner evaluation\")\n",
    "        data = dataset.get_sub_data(corpus=cfg.corpus, methods=cfg.methods)\n",
    "        data_splits = dataset.split_data(data, splits=cfg.splits, refer=\"id\")\n",
    "    elif cfg.task == \"cross_lang\":\n",
    "        color_print(\"WaveFake task: cross language evaluation\")\n",
    "\n",
    "        task_cfg = cfg.task_cfg\n",
    "        data_train = dataset.get_sub_data(\n",
    "            corpus=task_cfg.train.corpus, methods=task_cfg.train.methods\n",
    "        )\n",
    "        train, val = dataset.split_data(\n",
    "            data_train, splits=task_cfg.train.splits, return_list=True, refer=\"id\"\n",
    "        )\n",
    "        test = dataset.get_sub_data(\n",
    "            corpus=task_cfg.test.corpus, methods=task_cfg.test.methods\n",
    "        )\n",
    "        data_splits = Namespace(train=train, val=val, test=test)\n",
    "    elif cfg.task == \"cross_method\":\n",
    "        color_print(\"WaveFake task: cross method\")\n",
    "\n",
    "        task_cfg = cfg.task_cfg\n",
    "        # get real data, and split it into train/val/test\n",
    "        data_real = dataset._get_sub_data(task_cfg.train.corpus, \"real\")\n",
    "        real_train, real_val, real_test = dataset.split_data(\n",
    "            data_real, splits=[0.6, 0.2, 0.2], return_list=True, refer=\"id\"\n",
    "        )\n",
    "\n",
    "        data_train = dataset.get_sub_data(\n",
    "            corpus=task_cfg.train.corpus,\n",
    "            methods=task_cfg.train.methods,\n",
    "            contain_real=False,\n",
    "        )\n",
    "        train, val = dataset.split_data(\n",
    "            data_train, splits=task_cfg.train.splits, return_list=True, refer=\"id\"\n",
    "        )\n",
    "        test = [\n",
    "            dataset.get_sub_data(\n",
    "                corpus=_cfg.corpus, methods=_cfg.methods, contain_real=False\n",
    "            )\n",
    "            for _cfg in task_cfg.test\n",
    "        ]\n",
    "        train = pd.concat([train, real_train], ignore_index=True)\n",
    "        val = pd.concat([val, real_val], ignore_index=True)\n",
    "        test = [pd.concat([_test, real_test], ignore_index=True) for _test in test]\n",
    "        data_splits = Namespace(train=train, val=val, test=test)\n",
    "\n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c8e07-5790-4f0b-b932-699edda65fae",
   "metadata": {},
   "source": [
    "### LibriSeVoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f170c69-1973-44b4-9718-ec687d356a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_LibriSeVoc(cfg):\n",
    "    dataset = LibriSeVoc_AudioDs(root_path=cfg.ROOT_PATHs.LibriSeVoc)\n",
    "    # dataset.data = get_emotion_labels(dataset.data)\n",
    "\n",
    "    if cfg.task == \"inner_eval\":\n",
    "        color_print(\"LibriSeVoc task: inner evaluation\")\n",
    "\n",
    "        data = dataset.get_sub_data(methods=cfg.methods)\n",
    "        data_splits = dataset.split_data(data, splits=cfg.splits, refer=\"id\")\n",
    "    elif cfg.task == \"cross_method\":\n",
    "        color_print(\"LibriSeVoc task: cross method evaluation\")\n",
    "        task_cfg = cfg.task_cfg\n",
    "\n",
    "        # get real data, and split it into train/val/test\n",
    "        data_real = dataset.get_sub_data([], contain_real=True)\n",
    "        real_train, real_val, real_test = dataset.split_data(\n",
    "            data_real, splits=[0.6, 0.2, 0.2], return_list=True, refer=\"id\"\n",
    "        )\n",
    "\n",
    "        data_train = dataset.get_sub_data(\n",
    "            methods=task_cfg.train.methods, contain_real=False\n",
    "        )\n",
    "        train, val = dataset.split_data(\n",
    "            data_train, splits=task_cfg.train.splits, return_list=True, refer=\"id\"\n",
    "        )\n",
    "        test = [\n",
    "            dataset.get_sub_data(methods=_cfg.methods, contain_real=False)\n",
    "            for _cfg in task_cfg.test\n",
    "        ]\n",
    "        train = pd.concat([train, real_train], ignore_index=True)\n",
    "        val = pd.concat([val, real_val], ignore_index=True)\n",
    "        test = [pd.concat([_test, real_test], ignore_index=True) for _test in test]\n",
    "\n",
    "        data_splits = Namespace(train=train, val=val, test=test)\n",
    "    elif cfg.task == \"cross_dataset\":\n",
    "        color_print(\"LibriSeVoc task: cross dataset evaluation\")\n",
    "        task_cfg = cfg.task_cfg\n",
    "        data_train = dataset.get_sub_data(methods=task_cfg.train.methods)\n",
    "        train, val = dataset.split_data(\n",
    "            data_train, splits=task_cfg.train.splits, return_list=True, refer=\"id\"\n",
    "        )\n",
    "        test = []\n",
    "        for _cfg in task_cfg.test:\n",
    "            if _cfg.dataset.lower() == \"wavefake\":\n",
    "                dataset2 = WaveFake_AudioDs(root_path=cfg.ROOT_PATHs.WaveFake)\n",
    "                _data = dataset2.get_sub_data(corpus=_cfg.corpus, methods=_cfg.methods)\n",
    "                test.append(_data)\n",
    "        test.append(get_InTheWild_data())\n",
    "        test.append(get_DECRO_test_splits(language=\"en\"))\n",
    "        test.append(get_DECRO_test_splits(language=\"cn\"))\n",
    "        data_splits = Namespace(train=train, val=val, test=test)\n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1e4b1-9a40-44b9-b228-a193b2aa6a0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T11:35:09.247018Z",
     "iopub.status.busy": "2024-01-04T11:35:09.246332Z",
     "iopub.status.idle": "2024-01-04T11:35:09.255194Z",
     "shell.execute_reply": "2024-01-04T11:35:09.253131Z",
     "shell.execute_reply.started": "2024-01-04T11:35:09.246951Z"
    }
   },
   "source": [
    "### DECRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a8207-1494-47bc-9698-a54b623afef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DECRO_test_splits(\n",
    "    root_path=\"/home/ay/data/DATA/2-datasets/1-df-audio/DECRO\", language=\"en\"\n",
    "):\n",
    "    dataset = DECRO_AudioDs(root_path=root_path)\n",
    "    en_splits = dataset.get_splits(language=\"en\")\n",
    "    ch_splits = dataset.get_splits(language=\"ch\")\n",
    "    if language == \"en\":\n",
    "        data = en_splits.test\n",
    "    else:\n",
    "        data = ch_splits.test\n",
    "\n",
    "    data[\"vocoder_label\"] = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759c656a-c11b-4de0-8f50-09331199458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DECRO(cfg):\n",
    "    dataset = DECRO_AudioDs(root_path=cfg.root_path)\n",
    "    # dataset.data = get_emotion_labels(dataset.data)\n",
    "\n",
    "    en_splits = dataset.get_splits(language=\"en\")\n",
    "    ch_splits = dataset.get_splits(language=\"ch\")\n",
    "\n",
    "    if cfg.task == \"en->ch\":\n",
    "        color_print(\"DECRO task: en->ch\")\n",
    "        train, val, test = (\n",
    "            en_splits.train,\n",
    "            en_splits.val,\n",
    "            [en_splits.train, ch_splits.test, get_InTheWild_data()],\n",
    "        )\n",
    "    else:\n",
    "        color_print(\"DECRO task: ch->en\")\n",
    "        train, val, test = (\n",
    "            ch_splits.train,\n",
    "            ch_splits.val,\n",
    "            [ch_splits.test, en_splits.test, get_InTheWild_data()],\n",
    "        )\n",
    "    data_splits = Namespace(train=train, val=val, test=test)\n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb9fc29-9735-4acd-a752-79b2522d800f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6a370d0-db7c-4ae5-8246-3cb50cd0c649",
   "metadata": {},
   "source": [
    "## Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740837e8-c1e4-4585-90b4-c600fd42c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAKE_DATASETS = {\n",
    "    \"WaveFake\": make_WaveFake,\n",
    "    \"LibriSeVoc\": make_LibriSeVoc,\n",
    "    \"DECRO\": make_DECRO,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea73119-1996-4b96-9dee-6c8a85f153f1",
   "metadata": {},
   "source": [
    "# Build DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20eba88-536b-4127-8bf6-344b348bc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature(cfg):\n",
    "    if cfg.audio_feature == \"LFCC\":\n",
    "        return LFCC()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ad84e5-2537-4e33-aa1b-ae8ae57ecfec",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb75dcd0-5e2f-42a6-9ec6-9c6033c8fdfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T07:26:53.944413Z",
     "iopub.status.busy": "2024-03-13T07:26:53.937587Z",
     "iopub.status.idle": "2024-03-13T07:26:53.953468Z",
     "shell.execute_reply": "2024-03-13T07:26:53.952628Z",
     "shell.execute_reply.started": "2024-03-13T07:26:53.944336Z"
    }
   },
   "outputs": [],
   "source": [
    "from ay2.torchaudio.transforms.self_operation import (\n",
    "    AudioToTensor,\n",
    "    CentralAudioClip,\n",
    "    RandomAudioClip,\n",
    "    RandomPitchShift,\n",
    "    RandomSpeed,\n",
    ")\n",
    "from ay2.torchaudio.transforms import RandomAudioCompression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c1127-a38f-41e4-ab69-1a267cbe1205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_augmentations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a57c5-fa33-4b54-95ba-0ee0753e9a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transforms(cfg):\n",
    "    # t1 = RandomNoise(snr_min_db=10.0, snr_max_db=120.0, p=1.0)\n",
    "    # # t = RawBoost(algo=[5], p=0.5)\n",
    "    # t2 = RandomSpeed(min_speed=0.5, max_speed=2.0, p=1.0)\n",
    "    # t3 = RandomPitchShift(p=1.0)\n",
    "\n",
    "    # sr = 16000\n",
    "    # num_samples=48000\n",
    "    # transforms = [\n",
    "    #     RandomResizedCrop(n_samples=num_samples),\n",
    "    #     RandomApply([PolarityInversion()], p=0.8),\n",
    "    #     RandomApply([Noise(min_snr=0.001, max_snr=0.005)], p=0.3),\n",
    "    #     RandomApply([Gain()], p=0.2),\n",
    "    #     HighLowPass(sample_rate=sr), # this augmentation will always be applied in this aumgentation chain!\n",
    "    #     RandomApply([Delay(sample_rate=sr)], p=0.5),\n",
    "    #     RandomApply([PitchShift(\n",
    "    #         n_samples=num_samples,\n",
    "    #         sample_rate=sr\n",
    "    #     )], p=0.4),\n",
    "    #     RandomApply([Reverb(sample_rate=sr)], p=0.3)\n",
    "    # ]\n",
    "\n",
    "    # return {\n",
    "    #     \"train\": transforms,\n",
    "    #     \"val\": [\n",
    "    #         CentralAudioClip(length=48000),\n",
    "    #         AudioToTensor(),\n",
    "    #     ],\n",
    "    # }\n",
    "\n",
    "    return {\n",
    "        \"train\": [\n",
    "            # RandomSpeed(min_speed=0.5, max_speed=2.0, p=0.5),\n",
    "            RandomAudioCompression(p=0.9),\n",
    "            RandomSpeed(min_speed=0.5, max_speed=2.0, p=1.0),\n",
    "            RandomAudioClip(length=48000),\n",
    "            RandomNoise(snr_min_db=10.0, snr_max_db=120.0, p=1.0),\n",
    "            AudioToTensor(),\n",
    "            # RandomApply([PitchShift(n_samples=48000, sample_rate=16000)], p=0.5),\n",
    "            # RandomPitchShift(p=0.5),\n",
    "        ],\n",
    "        \"val\": [\n",
    "            CentralAudioClip(length=48000),\n",
    "            AudioToTensor(),\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8d22ee-9e5f-48cc-8ec8-6ea89dca2f6b",
   "metadata": {},
   "source": [
    "## Common Opeations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f4accf-4165-4fb7-af15-a4afea7a5ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(data: pd.DataFrame, cfg, is_training: bool = True):\n",
    "    transforms = build_transforms(cfg.transforms)\n",
    "    transform = transforms[\"train\"] if is_training else transforms[\"val\"]\n",
    "\n",
    "    _ds = WaveDataset(\n",
    "        data,\n",
    "        sample_rate=cfg.sample_rate,\n",
    "        normalize=True,\n",
    "        transform=transform,\n",
    "        dtype=\"tensor\",\n",
    "    )\n",
    "\n",
    "    if not is_training and cfg.test_batch_size > 0:\n",
    "        batch_size = cfg.test_batch_size\n",
    "    else:\n",
    "        batch_size = cfg.batch_size\n",
    "    \n",
    "    _dl = DataLoader(\n",
    "        _ds,\n",
    "        batch_size=batch_size,\n",
    "        # num_workers=cfg.num_workers,\n",
    "        num_workers=20,\n",
    "        pin_memory=True,\n",
    "        shuffle=True if is_training else False,\n",
    "        # shuffle=True,\n",
    "        prefetch_factor=2,\n",
    "        drop_last=True if is_training else False,\n",
    "    )\n",
    "    return _ds, _dl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1546f1-3d1a-4329-8eb7-adb483e9cd9b",
   "metadata": {},
   "source": [
    "## Door"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001bf0b4-2f78-4dfc-b90c-911436def412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sample_dataset(data, column=\"label\"):\n",
    "    n_fake = len(data[data[column] == 0])\n",
    "    n_real = len(data[data[column] == 1])\n",
    "    if n_fake == n_real:\n",
    "        return data\n",
    "    if n_fake > n_real:\n",
    "        sampled = data[data[column] == 1].sample(n=n_fake - n_real, replace=True)\n",
    "        balanced_data = pd.concat([data, sampled])\n",
    "    else:\n",
    "        sampled = data[data[column] == 0].sample(n=n_real - n_fake, replace=True)\n",
    "        balanced_data = pd.concat([data, sampled])\n",
    "\n",
    "    balanced_data = balanced_data.copy().reset_index(drop=True)\n",
    "    return balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f793fc65-14a3-4beb-b611-5ec66e2e18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_audio_splits_label_distribution(audio_splits):\n",
    "    res = {}\n",
    "    for _split in [\"train\", \"val\", \"test\"]:\n",
    "        _data = getattr(audio_splits, _split)\n",
    "        res[_split] = \"\"\n",
    "        if isinstance(_data, list):\n",
    "            for _data2 in _data:\n",
    "                tmp = _data2.groupby(\"label\")[\"audio_path\"].count()\n",
    "                res[_split] += f\" {tmp[0]}/{tmp[1]}\"\n",
    "        else:\n",
    "            tmp = _data.groupby(\"label\")[\"audio_path\"].count()\n",
    "            res[_split] += f\" {tmp[0]}/{tmp[1]}\"\n",
    "    color_print(\n",
    "        f\"Fake/Real label distribution in train/val/test: {res['train']}, {res['val']}, {res['test']}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b1e8ee-a313-4bdc-82d1-3de2ed4a39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(cfg):\n",
    "    # make audio splits (pd.DataFrame)\n",
    "    audio_splits = MAKE_DATASETS[cfg.name](cfg.dataset_cfg)\n",
    "    audio_splits.train = over_sample_dataset(audio_splits.train, column=\"label\")\n",
    "\n",
    "    print_audio_splits_label_distribution(audio_splits)\n",
    "\n",
    "    # make dataset and dataloaders\n",
    "    train_ds, train_dl = build_dataloader(audio_splits.train, cfg, is_training=True)\n",
    "    train_ds2, train_dl2 = build_dataloader(audio_splits.train, cfg, is_training=False)\n",
    "    val_ds, val_dl = build_dataloader(audio_splits.val, cfg, is_training=False)\n",
    "    if isinstance(audio_splits.test, list):\n",
    "        test_ds, test_dl = [], []\n",
    "        for _test in audio_splits.test:\n",
    "            _ds, _dl = build_dataloader(_test, cfg, is_training=False)\n",
    "            test_ds.append(_ds)\n",
    "            test_dl.append(_dl)\n",
    "    else:\n",
    "        test_ds, test_dl = build_dataloader(audio_splits.test, cfg, is_training=False)\n",
    "\n",
    "    # collect all dataloaders\n",
    "    ds = Namespace(train=train_ds, val=val_ds, test=test_ds, train_wo_transform=train_ds2)\n",
    "    dl = Namespace(train=train_dl, val=val_dl, test=test_dl, train_wo_transform=train_dl2)\n",
    "    return ds, dl"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
