

# %%
import os

import pandas as pd
from IPython.display import HTML, display
import logging

# Configure basic logging settings
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# %%
ROOT_PATH = "/home/ay/data/DATA/1-model_save/00-Deepfake/1-df-audio"


# %%
def read_test_result(model, task, version=0, file_name="test", root_path=ROOT_PATH):
    """Reads test results from a CSV file generated by model training.
    
    We assume that the CSV file should be the following format:
    ```
        {root_path}/{model}/{task}/version_{version}
    ```

    Args:
        model (str): Name of the model directory under root_path.
        task (str): Task name subdirectory under the model directory.
        version (int, optional): Experiment version number. Defaults to 0.
        file_name (str, optional): Base name of the CSV file without extension. 
            Defaults to "test".
        root_path (str, optional): Root directory containing all experiment results. 
            Defaults to ROOT_PATH.

    Returns:
        Optional[pd.DataFrame]: A DataFrame containing all columns from the CSV file
            with additional 'model', 'task', 'version', 'column', and 'id' columns, or None if the
            file is not found.

    Raises:
        FileNotFoundError: If the specified CSV file does not exist.
        PermissionError: If there is no read permission for the file.
        pd.errors.ParserError: If the CSV file is malformed and cannot be parsed.
        KeyError: If any of the expected metric columns are missing from the DataFrame.

    Example:
        >>> import pandas as pd
        >>> results = read_test_result(model = 'LCNN', task = 'ASVSpoof5', version = 0, root_path = ROOT_PATH)
        >>> print(results)
                epoch	step	test-acc	test-auc	test-eer	test-loss	model	task	    version
            0	0	    0	    0.361135	0.884168	0.147843	4.014615	LCNN	ASVSpoof5	0
            1	0	    0	    0.227331	0.666488	0.385411	6.600376	LCNN	ASVSpoof5	0
            2	0	    0	    0.250282	0.713465	0.345602	6.156854	LCNN	ASVSpoof5	0

    Note:
        This function relies on pandas for DataFrame operations and the os module 
        for file path handling.
    """
    save_path = f"{root_path}/{model}/{task}/version_{version}"
    csv_path = os.path.join(save_path, f"{file_name}.csv")

    try:
        if not os.path.exists(csv_path):
            raise FileNotFoundError(f"The file {csv_path} does not exist.")
        
        data = pd.read_csv(csv_path)
        data['model'] = model
        data['task'] = task
        data['version'] = version
        data['column'] = range(len(data))
        data['id'] = model if version == 0 else f"{model}-{version}"
        return data
    
    except FileNotFoundError as e:
        # print(f"Warning: The file {csv_path} was not found.")
        print(f"Skipping {model}, {task}, version {version}: File not found - {e}")
        raise
    except PermissionError:
        print(f"Permission denied when accessing the file {csv_path}.")
        raise
    except pd.errors.ParserError as e:
        print(f"Error parsing CSV file {csv_path}: {str(e)}")
        raise


# %%
# read_test_result(model = 'LCNN', task = 'ASVSpoof5', version = 0, root_path = ROOT_PATH)

# %%
def read_test_results(
    models: list, task: str, versions: list, root_path: str = ROOT_PATH
) -> pd.DataFrame:
    """Reads test results for multiple model-task-version combinations and returns a concatenated DataFrame.

    This function iterates through each combination of model, task, and version,
    reads the corresponding CSV files using `read_test_result`, collects all DataFrames,
    and concatenates them into a single DataFrame with a reset index.

    Args:
        models (list): A list of model names.
        task (str): the deepfake detection task
        versions (list): A list where each element is either an integer or a list
            of integers, representing versions for each model-task pair.
        root_path (str, optional): The root directory containing the results.
            Defaults to ROOT_PATH.

    Returns:
        pd.DataFrame: A concatenated DataFrame containing all test results from the
            specified models, tasks, and versions with reset index.

    Raises:
        ValueError: If the lengths of `models`, `tasks`, and `versions` do not match.
        FileNotFoundError: If any specified CSV file does not exist.
        PermissionError: If there is no read permission for a file.
        pd.errors.ParserError: If any CSV file is malformed and cannot be parsed.

    Example:
        >>> import pandas as pd
        >>> models = ['model1', 'model2']
        >>> task = "task"
        >>> versions = [1, 2]
        >>> results_df = read_test_results(models, tasks, versions)
        >>> print(results_df.head())
            model   task  version  metric1  metric2
        0    model1  task        1     0.85     0.90
        1    model1  task        1     0.88     0.91
        2    model2  task        2     0.82     0.89
        3    model2  task        2     0.84     0.87
    """

    # Validate input lengths to ensure they are compatible for zipping
    if not (len(models) == len(versions)):
        raise ValueError("Length of models, and versions must be the same.")

    results = []

    # Iterate through each model-task-version combination
    for model, version in zip(models, versions):
        # Convert version to a list if it's not already one
        version_list = version if isinstance(version, list) else [version]
        if len(set(version_list)) != len(version_list):
            raise ValueError(
                "Versions must be unique for each model-task pair.,"
                f"but got {version_list} for {model}-{task}"
            )

        try:
            # Attempt to read results for each version
            for v in version_list:
                data = read_test_result(model, task, v, root_path=root_path)
                if data is not None:  # Only append if data was successfully read
                    results.append(data)
        except Exception as e:
            continue  # Skip to the next combination if an error occurs

    if not results:
        print("Warning!!! No valid data found to concatenate.")
        res =  pd.DataFrame()  # Return an empty DataFrame if no data is collected
        return res
    try:
        # Concatenate all collected DataFrames
        concatenated_df = pd.concat(results, ignore_index=True)
        return concatenated_df
    except Exception as e:
        print(f"Failed to concatenate DataFrames: {e}")
        raise  # Re-raise to notify of unexpected errors during concatenation


# %%
# models = ['LCNN', 'AASIST']
# tasks = ['ASVSpoof5', 'ASVSpoof5']
# versions = [0, 0]
# res = read_test_results(models, tasks, versions, root_path=ROOT_PATH)

# %%
def concat_metrics(data, metrics, decimals=2):
    """
    Concatenates specified metrics into a single string column with formatted values.

    Args:
        data (DataFrame): DataFrame containing the data to be processed.
        metrics (list of str): List of column names in `data` to be used as metrics.
        decimals (int, optional): Number of decimal places to round each metric value. Defaults to 2.

    Returns:
        DataFrame: The input DataFrame with an additional 'res' column containing formatted metric values.

    Example:
        >>> import pandas as pd
        >>> data = pd.DataFrame({
        ...     'metric1': [0.1234, 0.5678], 
        ...     'metric2': [0.8765, 0.2345]
        ... })
        >>> metrics = ['metric1', 'metric2']
        >>> concat_metrics(data, metrics)
                  metric1  metric2       res
        0         0.1234   0.8765  12.34/87.65
        1         0.5678   0.2345  56.78/23.45

    中文:
    将指定的度量标准合并到单列字符串中，并格式化数值。

    参数:
        data (DataFrame): 包含要处理数据的 DataFrame。
        metrics (list of str): `data` 中用于作为指标的列名列表。
        decimals (int, 可选): 每个度量值的小数位数。默认为 2。

    返回:
        DataFrame: 输入的 DataFrame，添加了一个 'res' 列，包含格式化的度量值。

    示例:
        >>> import pandas as pd
        >>> data = pd.DataFrame({
        ...     'metric1': [0.1234, 0.5678], 
        ...     'metric2': [0.8765, 0.2345]
        ... })
        >>> metrics = ['metric1', 'metric2']
        >>> concat_metrics(data, metrics)
                  metric1  metric2       res
        0         0.1234   0.8765  12.34/87.65
        1         0.5678   0.2345  56.78/23.45
    """
    return data.apply(
        lambda x: "/".join(
            [str(f"%.{decimals}f" % (x[metric] * 100)) for metric in metrics]
        ),
        axis=1,
    )

# %%
# data = res
# data['res'] = concat_metrics(data, ['test-acc', 'test-auc', 'test-eer'], decimals=4)
# x = data.pivot(index='id', columns='column', values='res').reset_index()
# x
