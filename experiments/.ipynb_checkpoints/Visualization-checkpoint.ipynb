{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f57a74f-8c55-4d51-b6f5-d38385571193",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:32:34.906375Z",
     "iopub.status.busy": "2024-07-24T13:32:34.905660Z",
     "iopub.status.idle": "2024-07-24T13:32:34.955881Z",
     "shell.execute_reply": "2024-07-24T13:32:34.954561Z",
     "shell.execute_reply.started": "2024-07-24T13:32:34.906314Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f848bd9-8d33-4a82-9f81-3ab0df678880",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:32:34.959610Z",
     "iopub.status.busy": "2024-07-24T13:32:34.958730Z",
     "iopub.status.idle": "2024-07-24T13:32:34.987901Z",
     "shell.execute_reply": "2024-07-24T13:32:34.986673Z",
     "shell.execute_reply.started": "2024-07-24T13:32:34.959553Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e66cc9-48a7-4ee9-8bd8-e195cb9be798",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9efac8-6a6b-4b90-8511-62ed5212c9fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:32:35.008371Z",
     "iopub.status.busy": "2024-07-24T13:32:35.007947Z",
     "iopub.status.idle": "2024-07-24T13:32:37.922756Z",
     "shell.execute_reply": "2024-07-24T13:32:37.922053Z",
     "shell.execute_reply.started": "2024-07-24T13:32:35.008322Z"
    }
   },
   "outputs": [],
   "source": [
    "from phoneme_model import load_phoneme_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c24ea9-51dd-4f04-b3b5-9c30bc5d5a3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:32:37.923783Z",
     "iopub.status.busy": "2024-07-24T13:32:37.923544Z",
     "iopub.status.idle": "2024-07-24T13:32:37.947718Z",
     "shell.execute_reply": "2024-07-24T13:32:37.946858Z",
     "shell.execute_reply.started": "2024-07-24T13:32:37.923767Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_path = \"/home/ay/data/best-epoch=17-val-per=0.312388.ckpt\"\n",
    "# pretrained_path=\"/home/ay/data/DATA/1-model_save/01-phoneme/phoneme_recongition/version_0/checkpoints/best-epoch=28-val-per=0.278449.ckpt\"\n",
    "pretrained_path=\"/home/ay/data/DATA/1-model_save/01-phoneme/phoneme_recongition/version_4/checkpoints/best-epoch=57-val-per=0.268208.ckpt\"\n",
    "# pretrained_path=\"/home/ay/data/DATA/1-model_save/01-phoneme/phoneme_recongition/version_5/checkpoints/best-epoch=49-val-per=0.273750.ckpt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538cc53d-98d7-4c16-b2d2-e5e4ec819341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:32:37.948495Z",
     "iopub.status.busy": "2024-07-24T13:32:37.948337Z",
     "iopub.status.idle": "2024-07-24T13:32:43.215516Z",
     "shell.execute_reply": "2024-07-24T13:32:43.214533Z",
     "shell.execute_reply.started": "2024-07-24T13:32:37.948479Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ay/anaconda3/envs/torch/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = load_phoneme_model(pretrained_path=pretrained_path).cuda(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76049313-7bba-4709-844e-7dbed65002a9",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a00bb1bb-5e7b-4da3-ba2c-2a93a8459055",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:32:43.220054Z",
     "iopub.status.busy": "2024-07-24T13:32:43.219856Z",
     "iopub.status.idle": "2024-07-24T13:32:43.258951Z",
     "shell.execute_reply": "2024-07-24T13:32:43.258088Z",
     "shell.execute_reply.started": "2024-07-24T13:32:43.220033Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e874208-49e6-4acd-986e-f659288d4b3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:32:43.259981Z",
     "iopub.status.busy": "2024-07-24T13:32:43.259791Z",
     "iopub.status.idle": "2024-07-24T13:32:43.662771Z",
     "shell.execute_reply": "2024-07-24T13:32:43.661929Z",
     "shell.execute_reply.started": "2024-07-24T13:32:43.259961Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler, default_collate, random_split\n",
    "\n",
    "try:\n",
    "    from .data.tools import WaveDataset\n",
    "except ImportError:\n",
    "    from data.tools import WaveDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9bf5ca0-ac8e-48dc-b086-0759622fcfd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:32:43.663759Z",
     "iopub.status.busy": "2024-07-24T13:32:43.663482Z",
     "iopub.status.idle": "2024-07-24T13:32:43.702201Z",
     "shell.execute_reply": "2024-07-24T13:32:43.701390Z",
     "shell.execute_reply.started": "2024-07-24T13:32:43.663742Z"
    }
   },
   "outputs": [],
   "source": [
    "from ay2.datasets.audio import MLAAD_AudioDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "556ad4a8-bf2d-4ad2-b904-76fb076951f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:32:44.575356Z",
     "iopub.status.busy": "2024-07-24T13:32:44.575038Z",
     "iopub.status.idle": "2024-07-24T13:32:44.606609Z",
     "shell.execute_reply": "2024-07-24T13:32:44.605684Z",
     "shell.execute_reply.started": "2024-07-24T13:32:44.575335Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_MLAAD_subset(root_path:str = \"/home/ay/data/0-原始数据集/MLADD\", language:str='en', n_audios=1000):\n",
    "\n",
    "    ds = MLAAD_AudioDs(root_path=root_path)\n",
    "    if isinstance(language, str):\n",
    "        data = ds.data.query(f'language == {language}').sample(n_audios)\n",
    "    else:\n",
    "        data = ds.data.query(f'language in {language}').sample(n_audios)\n",
    "        \n",
    "    _ds = WaveDataset(\n",
    "        data,\n",
    "        sample_rate=16000,\n",
    "        normalize=True,\n",
    "        transform=None,\n",
    "        dtype=\"tensor\",\n",
    "    )\n",
    "    print(f\"read {len(_ds)} audios for the language {language} in {root_path}\")\n",
    "    return _ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "403e3222-6627-4e29-8dfb-3ede5f32ee2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:38:22.701993Z",
     "iopub.status.busy": "2024-07-24T13:38:22.701564Z",
     "iopub.status.idle": "2024-07-24T13:38:24.216012Z",
     "shell.execute_reply": "2024-07-24T13:38:24.214927Z",
     "shell.execute_reply.started": "2024-07-24T13:38:22.701970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 3000 audios for the language ['en', 'es', 'de'] in /home/ay/data/0-原始数据集/MLADD\n",
      "read 1000 audios for the language ['de'] in /home/ay/data/0-原始数据集/MLADD\n"
     ]
    }
   ],
   "source": [
    "_ds = load_MLAAD_subset(language=['en', 'es', 'de'], n_audios=3000)\n",
    "_ds = load_MLAAD_subset(language=['de'], n_audios=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fddf014-fc96-4adb-8475-94595a7d4855",
   "metadata": {},
   "source": [
    "# Compute weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9454957-b210-4a7f-9243-1aa5217dc9b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:36:50.354984Z",
     "iopub.status.busy": "2024-07-24T13:36:50.354696Z",
     "iopub.status.idle": "2024-07-24T13:36:50.407450Z",
     "shell.execute_reply": "2024-07-24T13:36:50.406539Z",
     "shell.execute_reply.started": "2024-07-24T13:36:50.354957Z"
    }
   },
   "outputs": [],
   "source": [
    "from ay2.visualization.tsne import plot_tSNE_res, tSNE_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "335f732f-0575-46a3-b189-2da5facab5cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:36:50.946435Z",
     "iopub.status.busy": "2024-07-24T13:36:50.946215Z",
     "iopub.status.idle": "2024-07-24T13:36:50.991180Z",
     "shell.execute_reply": "2024-07-24T13:36:50.990080Z",
     "shell.execute_reply.started": "2024-07-24T13:36:50.946415Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_weights(logits):\n",
    "    predict_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    numbers = predict_ids\n",
    "    # Initialize weights list\n",
    "    weights = [0] * len(numbers)\n",
    "    # Identify sequences and assign weights\n",
    "    current_sequence_length = 1\n",
    "    for i in range(1, len(numbers)):\n",
    "        if numbers[i] == numbers[i - 1]:\n",
    "            current_sequence_length += 1\n",
    "        else:\n",
    "            for j in range(i - current_sequence_length, i):\n",
    "                weights[j] = current_sequence_length\n",
    "            current_sequence_length = 1\n",
    "\n",
    "    # Handle the last sequence\n",
    "    for j in range(len(numbers) - current_sequence_length, len(numbers)):\n",
    "        weights[j] = current_sequence_length\n",
    "    weights_tensor = torch.tensor(weights, dtype=torch.float32)\n",
    "    weights_tensor = weights_tensor / torch.sum(weights_tensor)\n",
    "    return weights_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3db4487d-c276-4781-b3e0-c86661927a49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:40:22.873421Z",
     "iopub.status.busy": "2024-07-24T13:40:22.871990Z",
     "iopub.status.idle": "2024-07-24T13:40:22.969870Z",
     "shell.execute_reply": "2024-07-24T13:40:22.968819Z",
     "shell.execute_reply.started": "2024-07-24T13:40:22.873346Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weighted_hidden_state(model, x):\n",
    "    model_res = model.model.model(x, output_hidden_states=True)\n",
    "    logits = model_res.logits[0]\n",
    "    hidden_state = model_res.hidden_states[-1][0]\n",
    "    # print(logits.shape, hidden_state.shape)\n",
    "\n",
    "    weights = get_weights(logits).to(x.device)\n",
    "    _h = hidden_state * weights[:, None]\n",
    "    _h = torch.sum(_h, dim=0)\n",
    "    # print(weights.shape, _h.shape)\n",
    "    return _h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9deb9cf-fb60-448d-aa09-2e442a3d497a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:41:04.706436Z",
     "iopub.status.busy": "2024-07-24T13:41:04.705999Z",
     "iopub.status.idle": "2024-07-24T13:41:04.745739Z",
     "shell.execute_reply": "2024-07-24T13:41:04.745010Z",
     "shell.execute_reply.started": "2024-07-24T13:41:04.706413Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_hidden_states_labels(model, _ds):\n",
    "    hidden_states = []\n",
    "    labels = []\n",
    "    for i in tqdm(range(len(_ds))):\n",
    "        item = _ds[i]\n",
    "        x = item[\"audio\"].cuda(1)\n",
    "    \n",
    "        # if x.size(1) > 64000:\n",
    "        # x = x[:, :64000]\n",
    "        with torch.no_grad():\n",
    "            # hidden_state = model.model.model(x, output_hidden_states=True).hidden_states[-1][0]\n",
    "            # hidden_state = torch.mean(hidden_state, dim=0)\n",
    "            hidden_state = get_weighted_hidden_state(model, x)\n",
    "        hidden_states.append(hidden_state)\n",
    "        labels.append(item[\"label\"])\n",
    "    \n",
    "    hidden_states = torch.stack(hidden_states).detach().cpu()\n",
    "    return hidden_states, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "816cf2e8-3487-44ae-982d-76b679f7be72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:37:25.746645Z",
     "iopub.status.busy": "2024-07-24T13:37:25.746506Z",
     "iopub.status.idle": "2024-07-24T13:37:25.775366Z",
     "shell.execute_reply": "2024-07-24T13:37:25.774604Z",
     "shell.execute_reply.started": "2024-07-24T13:37:25.746630Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_subpart(_index, label):\n",
    "    if labels[_index] == label:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ac8a5-74eb-452e-8111-8fc04ba9d31d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:41:44.927000Z",
     "iopub.status.busy": "2024-07-24T13:41:44.926799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 1000 audios for the language ['en'] in /home/ay/data/0-原始数据集/MLADD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▍                                       | 34/1000 [00:01<00:32, 29.69it/s]"
     ]
    }
   ],
   "source": [
    "for language in ['en', 'de', 'es']:\n",
    "    _ds = load_MLAAD_subset(language=[language], n_audios=1000)\n",
    "    hidden_states, labels = get_hidden_states_labels(model, _ds)\n",
    "\n",
    "    result = tSNE_cluster(hidden_states)\n",
    "    plot_tSNE_res(\n",
    "        result, point_labels=[0, 1], index_func=get_subpart, markers=[\"o\", \"^\"], colors=[\"red\", \"blue\"]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
