{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ee2b34-9a0a-4943-8d48-2c85de31917c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:32:22.805090Z",
     "iopub.status.busy": "2024-11-26T06:32:22.804455Z",
     "iopub.status.idle": "2024-11-26T06:32:22.842772Z",
     "shell.execute_reply": "2024-11-26T06:32:22.840853Z",
     "shell.execute_reply.started": "2024-11-26T06:32:22.805033Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8febe9cc-20fd-43ca-b5a2-7c1d39534e49",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a9d0b6-87a9-43b6-a3ca-e41eef960d9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:36:11.104046Z",
     "iopub.status.busy": "2024-11-26T06:36:11.102976Z",
     "iopub.status.idle": "2024-11-26T06:36:11.700735Z",
     "shell.execute_reply": "2024-11-26T06:36:11.699798Z",
     "shell.execute_reply.started": "2024-11-26T06:36:11.103946Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np  # for numerical computations\n",
    "import matplotlib.pyplot as plt  # for plotting (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b2a8f2e-1566-4f9d-81ed-2899b2918873",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:36:15.883904Z",
     "iopub.status.busy": "2024-11-26T06:36:15.883370Z",
     "iopub.status.idle": "2024-11-26T06:36:15.922975Z",
     "shell.execute_reply": "2024-11-26T06:36:15.922110Z",
     "shell.execute_reply.started": "2024-11-26T06:36:15.883866Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "from typing import Any, NamedTuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e69f416e-d28f-415d-8c5f-5a33725c26eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:36:16.650189Z",
     "iopub.status.busy": "2024-11-26T06:36:16.649661Z",
     "iopub.status.idle": "2024-11-26T06:36:16.679187Z",
     "shell.execute_reply": "2024-11-26T06:36:16.677995Z",
     "shell.execute_reply.started": "2024-11-26T06:36:16.650159Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import joblib\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "001b3b2f-2a1a-4550-8859-d0134fa090bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:36:17.402758Z",
     "iopub.status.busy": "2024-11-26T06:36:17.402226Z",
     "iopub.status.idle": "2024-11-26T06:36:17.586213Z",
     "shell.execute_reply": "2024-11-26T06:36:17.585061Z",
     "shell.execute_reply.started": "2024-11-26T06:36:17.402711Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b515c-685c-4e0c-82ec-9d8d84e52867",
   "metadata": {},
   "source": [
    "# KMeansTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f158f2",
   "metadata": {},
   "source": [
    "使用WavLM模型和LibriSpeech 960h训练数据训练Kmeans模型后，我们可以用它将音频表示聚类成不同的units。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37cf397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d71150",
   "metadata": {},
   "source": [
    "为了更好地融合进Speech tokenizer，我们将Kmeans进行封装，使其既能处理单个输入，也能处理**批量输入**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51b3ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansTokenizer:\n",
    "    \"\"\"\n",
    "    Tokenizer based on kmeans clustering. This class can deal with batch input!!\n",
    "    \n",
    "    Args:\n",
    "        vocab_size (int, optional): the size of the vocabulary (number of clusters). Defaults to 200.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size:int=200):\n",
    "        \n",
    "        self.model = self.load_kmeans_model(n_cluster=vocab_size)\n",
    "        \n",
    "    def load_kmeans_model(self, n_cluster=200):\n",
    "        \"\"\"load kmeans model from file\n",
    "\n",
    "        Args:\n",
    "            n_cluster (int, optional): the size of the vocabulary (number of clusters). Defaults to 200.\n",
    "\n",
    "        Returns:\n",
    "            kmeans_model: the MinibatchKMeans model\n",
    "        \"\"\"\n",
    "        dataset_root_path = \"/home/ay/data2/datasets/Lib\"\n",
    "        kmeans_path = os.path.join(dataset_root_path, f\"kmeans_model-{n_cluster}.pkl\")\n",
    "        kmeans_model = joblib.load(kmeans_path)\n",
    "        return kmeans_model\n",
    "\n",
    "    def extract_unique_units(self, arr):\n",
    "        \"\"\"extract unique units from the input array\n",
    "\n",
    "        Args:\n",
    "            arr (np.ndarray): the input array\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: the unique units\n",
    "        \"\"\"\n",
    "        return torch.unique_consecutive(torch.from_numpy(arr)).numpy()\n",
    "\n",
    "\n",
    "    def predict_batch_units(self, batch_input: np.ndarray):\n",
    "        \"\"\"predict units using kmeans model for batch input\n",
    "\n",
    "        Args:\n",
    "            batch_input (np.ndarray): the batch input with shape of (B, L, C)\n",
    "\n",
    "        Raises:\n",
    "            ValueError: the input shape is not supported\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: the predicted units with shape of (B, L)\n",
    "        \"\"\"\n",
    "        if isinstance(batch_input, torch.Tensor):\n",
    "            batch_input = batch_input.detach().cpu().numpy()\n",
    "        \n",
    "        assert batch_input.ndim == 3, \"input shape should be (B, L, C)\"\n",
    "        \n",
    "        batch_size = batch_input.shape[0]\n",
    "        _input = rearrange(batch_input, 'b l c -> (b l) c')\n",
    "        units = self.model.predict(_input)\n",
    "        batch_units = rearrange(units, '(b l) -> b l', b=batch_size)\n",
    "        # print(batch_units.shape)\n",
    "        unique_units = [self.extract_unique_units(u) for u in batch_units]\n",
    "        return unique_units, batch_units\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        if x.ndim == 3:\n",
    "            return self.predict_batch_units(x)\n",
    "        else:\n",
    "            return self.model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077dbc49",
   "metadata": {},
   "source": [
    "# SpeechEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d374ad4",
   "metadata": {},
   "source": [
    "SpeechEncode contains two modules:\n",
    "1. Audio feature extraction model, using WavLM here\n",
    "2. Tokenizer, using Kmeans here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f2a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSpeechEncoder(nn.Module):\n",
    "    def __init__(self, dense_model_name=\"wavlm\", quantizer_name=\"kmeans\", vocab_size=200):\n",
    "        super().__init__()\n",
    "        self.load_SpeechEncoder(dense_model_name, quantizer_name=quantizer_name, vocab_size=vocab_size)\n",
    "\n",
    "    def load_SpeechEncoder(self, dense_model_name, quantizer_name=\"kmeans\", vocab_size=500):\n",
    "        \n",
    "        if dense_model_name == \"wavlm\":\n",
    "            from transformers import WavLMModel\n",
    "            model = WavLMModel.from_pretrained(\"microsoft/wavlm-base\")\n",
    "            model.lm_head = nn.Identity()\n",
    "        elif dense_model_name == \"wav2vec2\":\n",
    "            raise NotImplementedError\n",
    "        self.model = model\n",
    "        \n",
    "        if quantizer_name == \"kmeans\":\n",
    "            self.quantizer_model = KMeansTokenizer(vocab_size=vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encode_speech(x)\n",
    "\n",
    "    def encode_speech(self, x:torch.Tensor, attention_mask=None):\n",
    "        # res is a dict with keys ('dense', 'units', 'durations').\n",
    "        # It can also contain 'f0' if SpeechEncoder was initialized\n",
    "        # with need_f0=True flag.\n",
    "        \"\"\"\n",
    "        Return:\n",
    "            a dict with {\n",
    "                \"units\" : a list [ (L1), (L2), (L3) ], each element is a unit id list, with no repetition,\n",
    "                \"dense\" : a tensor with shape (B, T, 768)\n",
    "                \"original_units\": unit id lists with shape (B, T)\n",
    "            }\n",
    "        \"\"\"\n",
    "        \n",
    "        assert x.ndim == 2 or (x.ndim == 3 and x.size(1) == 1), 'Input shape must be (B, L) or (B, 1, L)'\n",
    "        \n",
    "        if x.ndim == 3: # change shape from (B, 1, L) to (B, L) \n",
    "            x = x[:, 0, :]\n",
    "        \n",
    "        res = {}\n",
    "        feats = self.model(x, output_hidden_states=True, attention_mask=attention_mask)\n",
    "        res['dense'] = feats.last_hidden_state # (B, T, C)\n",
    "        \n",
    "        \n",
    "        # list of (B, T, C). Note that the last_hidden_state is the same as \n",
    "        # the last element of hidden_states\n",
    "        res['hidden_states'] = feats.hidden_states\n",
    "        \n",
    "        res['units'], res['original_units'] = self.quantizer_model.predict_batch_units(res['dense'])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c99313",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ay/anaconda3/envs/torch/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at microsoft/wavlm-base were not used when initializing WavLMModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing WavLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing WavLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of WavLMModel were not initialized from the model checkpoint at microsoft/wavlm-base and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 149)\n",
      "dict_keys(['dense', 'hidden_states', 'units', 'original_units'])\n"
     ]
    }
   ],
   "source": [
    "model = CustomSpeechEncoder()\n",
    "audio = torch.randn(4, 1, 48000)\n",
    "res = model(audio)\n",
    "print(res.keys())"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
